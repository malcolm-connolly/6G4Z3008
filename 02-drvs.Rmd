# Discrete Random Variables {#drv}

In most practical situations in which we encounter uncertainty, the random outcome of interest is a numerical quantity. This could be the number of minutes you end up waiting for that bus, how much you win on the lottery this week, or even the number of times you try to catch a fly with chopsticks before you eventually manage to do so.

## Random Variables

In this chapter you will learn the concept of a discrete random variable. 

::: {.example}
Suppose we roll two dice and find the sum of the numbers on the two dice. Let $X$ be the sum of the numbers on the two dice. We know the sample space here is:
$$\Omega = \{ (n_1,n_2) : n_1,n_2 \in \mathbb{N}, \ 1 \leq n_1 , n_2 \leq 6 \},$$
Given an outcome $(n_1,n_2)$, the 'variable' $X$ takes a particular whole numbered value from $x=2, \dots , 12$. We have seen that these particular values are not equally likely.
:::


::: {.definition}
A ***random variable*** $X$ is a set function which maps the potential outcomes of a statistical experiment to (some subset of) the real number line. 

A random variable is written with a capital letter (here $X$), and the particular values it takes are written with a lowercase of the same letter (here $x$). The probability that $X$ takes a particular value is written $\text{P}(X=x)$.
:::

Just as with data analysis there is a difference between _discrete_ and _continuous_ random variables. One can think of _discrete_ random variables arising from a process which involves counting and can take integer values. The _continuous_ random variables can be thought of as arising from a measuring process.

::: {.example}
Let $R = $ result of spinning a roulette wheel. The roulette wheel can take particular values 
$$\Omega = \{0,1,2, \dots,36\}.$$
In number ranges from 1 to 10 and 19 to 28, odd numbers are red and even are black. In ranges from 11 to 18 and 29 to 36, odd numbers are black and even are red. There is a green pocket numbered 0 (zero). Then $R$ is a discrete random variable, as it takes only particular discrete values.

Let $T =$ the time spent waiting for a bus. Here $T$ could be any positive number from when you arrive at the bus stop (if it were time after the timetabled arrival time, it could be negative for an early bus). Then $T$ is a continuous random variable.
:::

We will consider discrete random variables first, but will study both types in this course. 

## Discrete probability distributions

In order to understand how a random variable is likely to behave, and thus be able to predict its possible future values, we clearly need to consider the probability with which it will take on particular values. This set of probability values is known as a probability distribution. We will develop the theory with some examples. 

:::{.definition}
The ***distribution*** function, also known as a ***probability mass function***, of a random variable $X$ is the function that outputs the probability of $X$ attaining any particular value. That is,

$$f(x) = \text{P}(X=x)$$
In some texts, or if there are two variables in play, we may also write the variable in subscript  $f_X(x)$  to be clear to which mass function we are referring.
:::

::: {.example name="discrete uniform distribution"}
Consider rolling a fair die and let the discrete random variable $X$ be the score observed on the die. We know that the probability of getting any of the particular values in the set $\{1,2, \dots 6\}$  is $\frac{1}{6}$ and this is the probability distribution. We may tabulate the values as follows 

|    $x$    | 1 | 2 | 3 | 4 | 5 | 6 |
|:-----------:+:---+:---+:---+:---+:---+:---|
| $\text{P}(X=x)$  | $\frac{1}{6}$  | $\frac{1}{6}$ |  $\frac{1}{6}$  | $\frac{1}{6}$ | $\frac{1}{6}$  | $\frac{1}{6}$ |
:::

Alternatively we may use a formula:
\begin{equation*}
  f(x)=\begin{cases}
    \frac{1}{6}, & \text{if } x = 1, 2, \dots , 6.\\
    0 & \text{otherwise}.
  \end{cases}
\end{equation*}

Or a graph:

```{r uniformdice, fig.align="center",out.width = "75%", fig.cap="Probability mass function for a fair die", echo=FALSE}
knitr::include_graphics("./figures/uni_pdf.jpg")
```

Clearly the graph is a very useful way to visualise how the probability is distributed. You can also see why this is called a discrete _uniform_ distribution - it's because the values are all the same.

Some questions to consider:

- Suppose your die had $n$ sides, where $n$ is some whole number greater than $1$, and the faces numbered $1,2,\dots n$. What does the distribution look like now?

- Can you represent the distribution in each of the three ways above?

::: {.example name="Urn problem"}
An urn contains five balls numbered $1$ to $5$. Two balls are drawn simultaneously. 

1. Let $X$ be the larger of the two numbers.

2. Let $Y$ be the sum of the two numbers.

Find the probability distributions of $X$ and $Y$.

_solution_ 

1. We proceed as follows by enumerating all the possibilities and noting that there are $^5C_2=10$ ways of drawing the balls from the urn. Note here that as the balls are drawn simultaneously, order does not matter here. 

To find the distribution of $X$ one can list the outcomes systematically by the largest value.

| $x$ |         |         |         |         | $\text{P}(X=x)$ | 
|:---:+:-------:+:-------:+:-------:+:-------:+:---------------:|
| 2   | $(1,2)$ |         |         |         | $\frac{1}{10}$  |
| 3   | $(1,3)$ | $(2,3)$ |         |         | $\frac{2}{10}$  |
| 4   | $(1,4)$ | $(2,4)$ | $(3,4)$ |         | $\frac{3}{10}$  |
| 5   | $(1,5)$ | $(2,5)$ | $(3,5)$ | $(4,5)$ | $\frac{4}{10}$  |


2. To find the distribution of $Y$ one can list the outcomes systematically by the sum.

| $y$ | | | $\text{P}(Y=y)$ | 
|:---:|:-:|:-:|:-:|
| 3 | (1,2) | | $\frac{1}{10}$ |
| 4 | (1,3) | | $\frac{1}{10}$ |
| 5 | (1,4) | (2,3) | $\frac{2}{10}$ |
| 6 | (1,5) | (2,4) | $\frac{2}{10}$ |
| 7 | (2,5) | (3,4) | $\frac{2}{10}$|
| 8 | (3,5) | | $\frac{1}{10}$ |
| 9 | (4,5) | | $\frac{1}{10}$ |


In either case you should check that each individual probability is between $0$ and $1$ and that over all possible particular values the sum is $1$.
:::


::: {.example name="a geometric distribution" #archer}
An archer hits a target rather randomly. Let's suppose that each time he takes aim $\text{P}(\text{Hit})=\frac{1}{4}$, and so the complement $\text{P}(\text{Miss})=\frac{3}{4}$. Let $Y$ be the number of attempts required until he hits the target. Find the distribution of $Y$.
:::


_solution_ 

We can consider the number of attempts separately.

$Y=1$, first attempt is a hit, so $\text{P}(Y=1)=\frac{1}{4}.$

$Y=2$, first attempt is a miss, second is a hit, so 
$$\text{P}(Y=2)=\frac{3}{4}\times \frac{1}{4} = \frac{3}{16}.$$

$Y=3$, first attempt is a miss, second is a miss, and third is a hit so 
$$\text{P}(Y=3)=\frac{3}{4}\times \frac{3}{4}\times \frac{1}{4} = \frac{9}{64}.$$
$Y=4$, the sequence is miss, miss, miss then hit:
$$\text{P}(Y=3)=\frac{3}{4}\times \frac{3}{4}\times \frac{3}{4}\times \frac{1}{4} = \frac{27}{256}.$$
And so on.

Notice that for the archer to hit the target on the $y^{\text{th}}$ attempt, he must have missed on each of the previous $y-1$ attempts, and so there is a formula for the mass function as follows.

\begin{equation*}
  f(Y=y)=\begin{cases}
    \left( \frac{3}{4} \right)^{y-1}\frac{1}{4} \ , & \text{if } y = 1, 2, 3, \dots \\
    \ 0 \ & \text{otherwise}.
  \end{cases}
\end{equation*}

Clearly these probabilities are quickly getting very small - you may recognise these terms as being in a geometric sequence with common ration $\frac{3}{4}$. 

A graph of this distribution looks like:

```{r geomdriving, fig.align="center",out.width="75%", fig.cap="A geometric distribution", echo=FALSE}
knitr::include_graphics("./figures/geo_pdf.jpg")
```

The choice of $\frac{1}{4}$ is infact arbitrary. In general you can have 'success' probability $\pi$ and 'failure' probability $1-\pi$.

:::{.definition}
A random variable $X$ representing the number of independent trials until the first success follows a geometric distribution with success probability $\pi$, written as $X \thicksim \text{Geom}(\pi)$, defined by the probability mass function

\begin{equation*}
  f(x)=\begin{cases}
    \left( 1-\pi \right)^{x-1}\pi , & x = 1, 2, 3, \dots \\
    \ 0 \ & \text{otherwise}.
  \end{cases}
\end{equation*}

:::

Of course the trials for the archer are arguably not independent - why?



## Properties of probability mass functions

For a random variable $X$ with probability distribution $f(x)$ we have the following two properties:

1. The probability of any particular value is between  $0$ and $1$. That is, 
$$ 0 \leq f(x) \leq 1, \ \forall x$$

2. The probabilities sum to unity. That is,

$$ \sum_{x} f(x)= 1$$

Probability distributions can be represented in a variety of different ways. In practice we use tables of distributions or use computer functions to evaluate them.

In R we can use the following functions to evaluate the probabilities from example \@ref(exm:archer).

```{r geoprobs, fig.cap="using the geometric distribution function in R"}

y <- dgeom(x = 1:4, #these are the particular values 1,2,3 and 4
           prob = 1/4 ) #This is the probability of success
y
#You can output these as fractions using the MASS library
MASS::fractions(y)


```

The important function is $\texttt{dgeom()}$, the $\texttt{d}$  stands for distribution and $\texttt{geom}$ for the geometric distribution.

Another way to represent a probability distribution is as a cumulative sum.

:::{.definition name="Cumulative distribution function"}
Given a random variable $X$ and its probability mass function $f(x)$, the cumulative distribution function (abbreviated CDF) denoted with a capital letter $F(x)$ is defined as the sum of the probabilities less than or equal to the value $x$. That is,

$$ F(x) = \text{P}(X\leq x) = \sum_{t\leq x}f(t)$$
:::

:::{.example name="another urn problem"}
Consider the setup previously where two balls numbered $1$ through $5$ are drawn and the maximum of two numbers is taken.
We found the probability distribution to be, 


| $x$ |  $\text{P}(X=x)$  | 
|:---:+:-----------------:|
| 2   |  $\frac{1}{10}$   |
| 3   | $\frac{2}{10}$    |
| 4   |  $\frac{3}{10}$   |
| 5   |   $\frac{4}{10}$  |

Work out the CDF $F(x)$.

_solution_

If $x<2$ we have $F(x)=0$.
If $2\leq x < 3$ we have $F(x) = \frac{1}{10}$.
If $3\leq x < 4$ we have $F(x) = \frac{1}{10} + \frac{2}{10}$.
If $4\leq x < 5$ we have $$F(x) = \frac{1}{10} + \frac{2}{10} + \frac{3}{10}.$$
If $5\leq x$ we have $$F(x) = \frac{1}{10} + \frac{2}{10} + \frac{3}{10} + \frac{4}{10}.$$

Altogether,

\begin{equation*}
  F(x)=\begin{cases}
  0  \ \ \ \ \ \ \ \ \ \ \   x<2 \\
  \frac{1}{10} \  \  2\leq x < 3 \\
  \frac{3}{10} \ \  3\leq x < 4 \\
  \frac{6}{10} \ \ \ 4\leq x < 5 \\
  1 \ \ \  \ \ \  5\leq x
  \end{cases}
\end{equation*}

:::

:::{.example}
The CDF of a geometric distribution is given by
$$F(x) = 1- (1-\pi)^{x}.$$
:::


_solution_ 

$$F(x) = \sum_{t\leq x}f(t)$$
Sum from $t=1$ to $t=x$.

$$  = \pi + \pi(1-\pi) + \pi(1-\pi)^2 + \dots +  \pi(1-\pi)^{x-1} $$
You might recognise a geometric series here, with $a=\pi$ and $r=(1-\pi)$, so this can be collected as:

$$F(x) = \frac{\pi (1-(1-\pi)^x)}{1-(1-\pi)} $$
Evaluating the denominator and cancelling gives the result.


The CDF is more useful than the mass function since if we are given the CDF we can calculate the mass function directly as the difference. 

$$f(x) = F(x)-F(x-1)$$

:::{.example}
Calculate $f(4)$ given the CDF

\begin{equation*}
  F(x)=\begin{cases}
  0  \ \ \ \ \ \ \ \ \ \ \   x<2 \\
  \frac{1}{10} \  \  2\leq x < 3 \\
  \frac{3}{10} \ \  3\leq x < 4 \\
  \frac{6}{10} \ \ \ 4\leq x < 5 \\
  1 \ \ \  \ \ \  5\leq x
  \end{cases}
\end{equation*}

_solution_

$f(4) = F(4)-F(3) = \frac{6}{10}-\frac{3}{10} = \frac{3}{10}$
:::

Due to the fact that the mass function can be calculated from the CDF, statistical tables often prioritise tabulating the CDF for various different types of distribution.

We finish this section with an example of how this theory may be used in applied calculations.

:::{.example}
Assuming the archer's attempts to hit a target follows a geometric distribution with success parameter $\frac{1}{4}$ calculate the probability that he

1. Hits on the $10^{\text{th}}$ attempt.

2. Takes fewer than $4$ attempts to hit the target.

3. Takes at least $8$ attempts to hit the target.

4. Takes between $4$ and $8$ attempts inclusive. 
:::


_solution_ 

Let $Y$ be the number of attempts to hit the target. We know that 

$$f(y) = \left( \frac{3}{4} \right) ^{y-1}\frac{1}{4}$$ 

and

$$ F(y) = 1- \left(1-\frac{1}{4}\right)^y = 1-\left( \frac{3}{4}\right)^y.$$

1. $\text{P}(Y=10) = f(10) = \left( \frac{3}{4}\right)^9\times \frac{1}{4} = 0.0188$ ($3$ s.f.).

2. $\text{P}(Y<4) = \text{P}(Y\leq 3) = F(3) =1 - \left( \frac{3}{4}\right)^3 = 0.578$, ($3$ s.f.).

3. Using the complement, $\text{P}(Y\geq 8) = 1 - \text{P}(Y\leq 7)$. Now using the CDF:

$$1-F(7) = 1- \left( 1-\left(\frac{3}{4}\right)^7\right) = 0.134.$$

4. Rewrite the required range as a difference of two CDF values as follows:

$$\text{P}(4\leq Y\leq 8) = \text{P}(Y\leq 8) - \text{P}(Y\leq 3)$$

$$ = F(8) - F(3)$$

$$ = \left[ 1-\left(\frac{3}{4}\right)^8\right] -  \left[ 1-\left(\frac{3}{4}\right)^3\right]$$
$$ = 0.322$$
You should be careful when evaluating the CDF to ensure that you have the correct values in the given inequality. A small diagram or list can be invaluable here.

## Mean, variance and moments

The mean and variance of a random variable essentially mirror the definitions of mean and variance for samples.The mean or expected value is the _average_ value of the variable if it were observed repeatedly. The variance indicates the likely spread of values of the variable.

:::{.example}
If you toss a coin $2$ times how many heads would you expect to turn up?

_solution_

Your would expect $1$ intuitively. Let $X$ be the number of heads. 
The outcomes are $(T,T),(H,T),(T,H),(H,H)$. The average number of heads is then

$$ \frac{0+1+1+2}{4} = 1$$
We can relate this to the probability of each number of heads. We have,

$$\text{P}(X=0) = \frac{1}{4}$$
$$\text{P}(X=1) = \frac{2}{4}$$
$$\text{P}(X=2) = \frac{1}{4}$$

The sum of the possible $x$ values weighted by the probability is:
$$0\times \frac{1}{4} + 1\times \frac{2}{4} + 2\times \frac{1}{4} = 1.$$

:::

:::{.definition}
The ***expectation***, or ***expected value*** of a random variable $X$ is defined as the sum of the possible values of the random variable weighted by the probability of that value.

$$ \text{E}[X] = \sum_x x\times\text{P}(X=x)$$
This is just a number once it is calculated is called the ***mean***, and so is written as a constant $\text{E}[X]=\mu$ to omit the random quantity $X$.

The expected value of any function of a discrete random variable $g(X)$ is defined similarly by
$$ \text{E}[X] = \sum_x g(x)\times\text{P}(X=x)$$

:::





:::{.definition}
The ***variance*** of a random variable $X$ is defined as:

$$ \text{Var}[X] = \text{E}[(X-\mu)^2]$$

:::


The following is a very useful in practice for actually computing the variance.

:::{.theorem}
Given a random variable $X$ we have that the variance is equal to the difference between the expectation of $X^2$ and the squared expectation of $X$. That is,

$$ \text{Var}[X]=\text{E}[X^2]-\text{E}[X]^2 $$
:::

We omit the proof for now and see some examples, leaving this for the interested reader.


:::{.proof}
The expectation is a sum, so behaves linearly. By definition,

$$\text{Var}[X] = \text{E}[(X-\mu)^2]$$
Expanding out the bracket on the inside gives,
$$ = \text{E}[X^2 - 2\mu X +\mu^2] $$
Using linearity,

$$= \text{E}[X^2]-2\mu\text{E}[X]+\mu^2.$$
$$= \text{E}[X^2]-2\mu^2+\mu^2.$$
Hence the result.
:::

:::{.example}
A discrete random variable $X$ representing the score on a loaded die has the following probability mass function.

|    $x$    | 1 | 2 | 3 | 4 | 5 | 6 |
|:-----------:+:---+:---+:---+:---+:---+:---|
| $\text{P}(X=x)$  | $\frac{1}{21}$  | $\frac{2}{21}$ |  $\frac{3}{21}$  | $\frac{4}{21}$ | $\frac{5}{21}$  | $\frac{6}{21}$ |

Calculate:

a) $\text{E}[X]$

b) $\text{E}[X^2]$

c) $\text{Var}[X]$

d) $\text{E}[e^X]$

:::

_solution_

a) Using the definition of expectation:

$$ \text{E}[X] = 1\times \frac{1}{21}+2\times \frac{2}{21}+3\times \frac{3}{21}+4\times \frac{4}{21}+5\times \frac{5}{21}+6\times \frac{6}{21},$$
$$ = 4.33 \ \ \ (3 \ \text{s. f.})$$
Compared to a fair die, the mean of the loaded die is higher.

b) 
$$ \text{E}[X^2] = 1^2\times \frac{1}{21}+2^2\times \frac{2}{21}+3^2\times \frac{3}{21}+4^2\times \frac{4}{21}+5^2\times \frac{5}{21}+6^2\times \frac{6}{21},$$

$$ = 21$$

3. The variance is then,

$$\text{Var}[X]=\text{E}[X^2]-\mu^2 = 21-(4.33\dots)^2= 2.22 \ \ \ (3 \ \text{s. f.})$$
4. $e^X$ is just a function of $X$. 

$$ \text{E}[X] = e^1\times \frac{1}{21}+e^2\times \frac{2}{21}+e^3\times \frac{3}{21}+e^4\times \frac{4}{21}+e^5\times \frac{5}{21}+e^6\times \frac{6}{21},$$

$$ = 164.622 \ (3 \ \text{d. p.}) $$

:::{.example name="expected profit"}
Consider the following game. A spinning wheel is divided into three equal sections numbered $1$, $2$ and $3$. You pay £$1$ to play the game, and you have to guess the number that will show when the wheel is spun. If you guess correctly, you get £$2$. If you do not then you get nothing. What is the expected profit from playing the game?

_solution_

The profit is the winnings minus the stake. Let the profit be the random variable $X$. The distribution of $X$ is:

|    $x$    | -1 | 1 | 
|:-----------:+:---+:---+:---+:---+:---+:---|
| $\text{P}(X=x)$  | $\frac{2}{3}$  | $\frac{1}{3}$ |

$$\text{E}[X] = -1 \times \frac{2}{3} + 1 \times \frac{1}{3} = -\frac{1}{3}$$
So we would expect on average to make a loss playing this game. For any gambling game to be profitable for the house, it is necessary that the expectation of the players winnings be negative. 
:::

:::{.example}
Let $X$ be a random variable whose value is a constant, that is the particular values it can take are all the same, $x=a$. Show that $\text{E}[X]=a$ and $\text{Var}[X]=0$

_solution_

$$\text{E}[X]=\sum_{x}x\times\text{P}(X=x)= \sum a\times\text{P}(X=a)=a\times \sum \text{P}(X=a) = a \times 1 = a$$

For the variance,

$$ \text{Var}[X] = \text{E}[(X-\mu)^2]=\text{E}[(a-a)^2]=0 $$
:::

We will now proceed to find the mean and variance of a Geometric distribution. We will need a fact about series first.

:::{.proposition}
Suppose $|r|<1$ and recall the infinite geometric series is given by the following formula:

$$g(r) = \sum_{k=0}^{\infty}ar^{k} = \frac{a}{1-r}$$
For a convergent series such as this we can differentiate term by term with respect to $r$, and equate this to what we would get from differentiating the RHS likewise. Doing so results in the following two formulae:

$$g'(r) = \sum_{k=0}^{\infty}akr^{k-1} = \frac{a}{(1-r)^2}$$

$$g''(r) = \sum_{k=0}^{\infty}ak(k-1)r^{k-2} = \frac{2a}{(1-r)^3}$$
:::


:::{.theorem}
Let $X$ be a random variable which follows a geometric distribution, $X \thicksim \text{Geom}(\pi)$, then we have:

$$\text{E}[X] = \frac{1}{\pi}$$
and 
$$ \text{Var}[X]=\frac{1-\pi}{\pi^2}$$
:::

:::{.proof}
By definition,
$$\text{E}[X] = \sum_{x=1}^{\infty}x(1-\pi)^{x-1}\pi$$
$$ = \pi + 2\pi(1-\pi) + 3\pi(1-\pi)^2+4\pi(1-\pi)^3+ \dots $$
The latter sum can be seen as $g'(1-\pi)$, with $a=\pi$. Using the RHS result from the previous proposition we have,
$$\text{E}[X] = \frac{\pi}{[1-(1-\pi)]^2} = \frac{1}{\pi}$$
For the variance we first find the expectation of a function of $X$ called a factorial moment.

$$\text{E}[X(X-1)] = \sum_{x=1}^{\infty}x(x-1)\pi(1-\pi)^{x-1}$$
$$ = (1-\pi)\sum_{x=2}^{\infty}x(x-1)\pi(1-\pi)^{x-2}$$
The infinite series turns out to be $g''(1-\pi)$ with $a=\pi$. Substituting this in gives, 

$$\text{E}[X(X-1)]=(1-\pi)\frac{2\pi}{[1-(1-\pi)]^3} = \frac{2(1-\pi)}{\pi^2}.$$
Now we can use this to find the variance as follows,

$$\text{Var}[X] = \text{E}[X^2]-\text{E}[X]^2 $$
$$ = \text{E}[X(X-1)]+\text{E}[X]-\text{E}[X]^2 $$
$$ = \frac{2(1-\pi)}{\pi^2} + \frac{1}{\pi} - \frac{1}{\pi^2} $$
$$ = \frac{1-\pi}{\pi^2}$$
as required.

:::

If you are given two random variables $X$ and $Y$ a _linear combination_ means an expression of the form $aX+bY$.  

:::{.theorem name="Linear Combinations"}
For any random variables $X$ and $Y$ and constants $a$ and $b$ we have that the expectation of a linear combination is a linear combination of the expectations.

$$\text{E}[aX\pm bY] = a\text{E}[X]\pm b\text{E}[Y]$$
However the variance is a nonlinear sum of the variances.  
$$\text{Var}[aX\pm bY] = a^2\text{Var}[X]+b^2\text{Var}[Y] $$
:::

:::{.proof}
This is omitted, but follows from properties of summations and mass functions.
:::

:::{.example}
Recall the loaded die had mass function given by,

|    $x$    | 1 | 2 | 3 | 4 | 5 | 6 |
|:-----------:+:---+:---+:---+:---+:---+:---|
| $\text{P}(X=x)$  | $\frac{1}{21}$  | $\frac{2}{21}$ |  $\frac{3}{21}$  | $\frac{4}{21}$ | $\frac{5}{21}$  | $\frac{6}{21}$ |


Suppose you win $W$ is an amount depending on the number that you roll on the loaded die.

If $W = 3X-10$ find $\text{E}[W]$ and $\text{Var}[W]$

_solution_

$$\text{E}[W] = 3\times (4.333\dots) -10 = £3$$

$$\text{Var}[W] = 3^2\times(2.22\dots) = 19.99\dots = 20.0 \  (3 \ \text{s.f.})$$

:::

## Exercises Week 3 
:::{.exercise}
An urn contains two yellow balls and three red balls. Three balls are drawn at random from the urn without replacement.

a) Draw a tree diagram to represent the sample space for this experiment and find the probabilities of each outcome. 

b) Let the random variable $X$ denote the number of red balls drawn.
 i) Write down the probability distribtion of $X$. 
 ii) Find the mean and variance of $X$.
:::



:::{.exercise}
Let $X$ be the value observed from rolling an $8$-sided die

a) What is the probability distribution of $X$. 

b) Draw a graph of the probability distribution.

c) Find the mean and variance of $X$.

d) Find the expected value of:
  i) $3X+5$
  ii) $\ln(X)$
:::


:::{.exercise}
A game consists of tossing a coin until the first head appears. The score recorded is the number of tosses required.

a) If the random variable $Y$ is the number of tosses, what is the distribution of $Y$? 

b) Write down the first $6$ values of the probability distribution, and draw a sketch.

c) Find the mean and variance of $Y$.

:::


:::{.exercise}
Two fair dice are rolled and the _total_ score observed. 

a) Write down the probability distribution of the total score.

b) Find the mean and variance of the total score. 
:::

:::{.exercise}
Two fair dice are rolled and the _maximum_ score observed. 

a) Write down the probability distribution of the maximum score.

b) Find the mean and variance of the maximum score. 
:::

:::{.exercise}
A fair coin is tossed three times. Let $X$ be the number of heads in the tosses minus the number of tails.
a) Find the probability distribution of $X$

b) Find the mean and variance of $X$.
:::

:::{.exercise}
The game of simple _Chuck-a-luck_ is played by a single player against the house. The game is conducted as follows:

The player chooses any number between $1$ and $6$ inclusive and places a bet of £$1$. The banker then rolls $2$ fair dice. If the player's number occurs $1$ or $2$ times, he wins £$1$ or £$2$ respectively. If the player's numberdoes not appear on any of the dice, he loses his £$1$ stake. Let the random variable $X$ denote the player's winnings in the game. 

a) Find the probability mass function of $X$.

b) Find the expected value of the winnings, $\text{E}[X]$.
:::

:::{.exercise}
The random variable $X$ has the following probability mass function:

| $x$ | 1 | 2 | 3 | 4 | 5 |
|:---:+:-:+:-:+:-:+:-:+:-:|
| $\text{P}(X=x)$ | $7c$ | $5c$ | $4c$ | $3c$ | $c$ |

a) Find the value of $c$ which makes this a valid probability mass function.

b) Find $\text{E}[X]$ and $\text{Var}[X]$.
:::

:::{.exercise}
The random variable $X$ has the following probability mass function:

| $y$ | 2 | 3 | 5 | 7 | 11 |
|:---:+:-:+:-:+:-:+:-:+:-:|
| $\text{P}(Y=y)$ | $\frac{1}{6}$ | $\frac{1}{3}$ | $\frac{1}{4}$ | $a$ | $b$ |

and $\text{E}[Y]=\frac{14}{3}$

a) Find the values of $a$ and $b$.

b) Find $\text{Var}[Y]$.
:::

:::{.exercise}
A fair six-sided die has '$1$' on one face, '$2$' on two faces and '$3$' on the remaining three faces.

a) Let $Y$ denote the score on a single roll of the die. Tabulate the mass function and calculate the mean and variance of $Y$.

b) Let $X$ be the total score on two rolls of the die. Tabulate the mass function and calculate the mean and variance of $X$.
:::


:::{.exercise}
An urn contains $n$ balls numbered $1$ to $n$ from which two balls are drawn simultaneously. Find the probability distribution of $X$, the larger of the two numbers drawn. Calculate the expected value of $X$.
:::

:::{.exercise}
$A$ and $B$ play a game that involves each rolling a fair die simultaneously. Let $X$ be the absolute difference in their scores. 

a) Tabulate the probability mass function of $X$.

b) Find the mean and variance of $X$.

c) If the value of $X$ is $1$ or $2$ then $A$ wins. If $X$ is $3$,$4$ or $5$ then $B$ wins. If $X$ is zero then they roll again. Find the probability that $A$ wins on the first go. Find the probability that $A$ wins on the second go. Find the probability that $A$ wins on the $r^{\text{th}}$ go. 

d) Find the probability that $A$ wins. 
:::

:::{.exercise}
A discrete random variable has the following mass function

\begin{equation*}
  f(y)=\begin{cases}
    \pi \ \ \ \ \ \ \ \ \ \  y = 1 \\
    1-\pi \ \  \ y = 0 .
  \end{cases}
\end{equation*}

Where $0<\pi<1$.This is known as the Bernoulli distribution.Find $\text{E}[Y]$ and $\text{Var}[Y]$
:::

### Exercises for feedback


:::{.exercise}
Scrabble tiles for the letters of the word EXERCISES are in a bag. 

a) A random tile is drawn, what is the probability that it is the letter is E? 

b) Given that the letter that is drawn from the bag is a vowel, what is the probability that it is an E? 

c) Explain how the two questions are different in your own words, and compare the size of the probabilities in either part. 
:::

:::{.exercise}
There are $40$ students in a Maths class, and each are given a number $1$ to $40$. Separately the numbers $1-40$ are placed in a hat and mixed randomly. The teacher will give three random students a prize. Three numbers are selected from the hat without replacement. Before the numbers are drawn the teacher guesses three numbers and writes them on the board.

- Work out the probability of the teacher matching $0$, $1$, $2$ or $3$ of the numbers that are drawn from the hat.

On a different occasion, the teacher has $5$ students in his tutor group. He wants to give two prizes to the Maths students, and one to his tutor group. He will draw two numbers from his hat, and separately he will draw one of the numbers $1-5$ from his shoe (he only has one hat). Again he writes his prediction on the board before the selection.

- Work out the probability of the teacher predicting $0$, $1$ or $2$ Maths students, but not getting the tutee correct, and the probability of predicting $0$, $1$ or $2$ Maths students and getting the tutee correct.
:::


:::{.exercise}
A fairground game is played with $5$ dice. The player pays £1 to play, and for every $6$ that appears on the dice the player is rewarded with £$6$. 

a) Work out the probabilities of getting $0$,$1$,$2$,$\dots$,$5$ sixes when rolling the five dice.

b) If $X$ is the profit of for the player of this game, work out the expected profit $\text{E}[X]$.

c) Work out also the variance $\text{Var}[X]$.

d) Explain if you think this is a good game or not.
:::






