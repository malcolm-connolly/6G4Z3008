<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Hypothesis testing | Probability Theory and Statistics</title>
  <meta name="description" content="These are the course notes for the first year BSc Mathematics course ‘Introduction to Probability Theory and Statistics’ at Manchester Metropolitan University" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Hypothesis testing | Probability Theory and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="These are the course notes for the first year BSc Mathematics course ‘Introduction to Probability Theory and Statistics’ at Manchester Metropolitan University" />
  <meta name="github-repo" content="6G4Z3008" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Hypothesis testing | Probability Theory and Statistics" />
  
  <meta name="twitter:description" content="These are the course notes for the first year BSc Mathematics course ‘Introduction to Probability Theory and Statistics’ at Manchester Metropolitan University" />
  

<meta name="author" content="Malcolm Connolly" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="cards.ico" type="image/x-icon" />
<link rel="prev" href="sampling-and-confidence-intervals.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="logo.svg"></a></li>
<li><a href="https://moodle.mmu.ac.uk/course/view.php?id=157842" target="blank" > 6G4Z3008 course notes </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Probability</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#frequentist-perspective"><i class="fa fa-check"></i><b>1.1</b> Frequentist perspective</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#naive-probability"><i class="fa fa-check"></i><b>1.2</b> Naive probability</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#complements-and-mutual-exclusivity"><i class="fa fa-check"></i><b>1.3</b> Complements and mutual exclusivity</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#outcomes-and-counting"><i class="fa fa-check"></i><b>1.4</b> Outcomes and counting</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#factorials"><i class="fa fa-check"></i><b>1.4.1</b> Factorials</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#permutations"><i class="fa fa-check"></i><b>1.4.2</b> Permutations</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#combinations"><i class="fa fa-check"></i><b>1.4.3</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#exercises-week-1"><i class="fa fa-check"></i><b>1.5</b> Exercises Week 1</a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#tutorial-exercises"><i class="fa fa-check"></i><b>1.5.1</b> Tutorial exercises</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#exercises-for-feedback"><i class="fa fa-check"></i><b>1.5.2</b> Exercises for feedback</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="cond.html"><a href="cond.html"><i class="fa fa-check"></i><b>2</b> Conditional Probability</a><ul>
<li class="chapter" data-level="2.1" data-path="cond.html"><a href="cond.html#independence"><i class="fa fa-check"></i><b>2.1</b> Independence</a></li>
<li class="chapter" data-level="2.2" data-path="cond.html"><a href="cond.html#conditional-probability"><i class="fa fa-check"></i><b>2.2</b> Conditional Probability</a></li>
<li class="chapter" data-level="2.3" data-path="cond.html"><a href="cond.html#bayes-theorem"><i class="fa fa-check"></i><b>2.3</b> Bayes Theorem</a></li>
<li class="chapter" data-level="2.4" data-path="cond.html"><a href="cond.html#exercises-week-2"><i class="fa fa-check"></i><b>2.4</b> Exercises Week 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="drv.html"><a href="drv.html"><i class="fa fa-check"></i><b>3</b> Discrete Random Variables</a><ul>
<li class="chapter" data-level="3.1" data-path="drv.html"><a href="drv.html#random-variables"><i class="fa fa-check"></i><b>3.1</b> Random Variables</a></li>
<li class="chapter" data-level="3.2" data-path="drv.html"><a href="drv.html#discrete-probability-distributions"><i class="fa fa-check"></i><b>3.2</b> Discrete probability distributions</a></li>
<li class="chapter" data-level="3.3" data-path="drv.html"><a href="drv.html#properties-of-probability-mass-functions"><i class="fa fa-check"></i><b>3.3</b> Properties of probability mass functions</a></li>
<li class="chapter" data-level="3.4" data-path="drv.html"><a href="drv.html#mean-variance-and-moments"><i class="fa fa-check"></i><b>3.4</b> Mean, variance and moments</a></li>
<li class="chapter" data-level="3.5" data-path="drv.html"><a href="drv.html#exercises-week-3"><i class="fa fa-check"></i><b>3.5</b> Exercises Week 3</a><ul>
<li class="chapter" data-level="3.5.1" data-path="drv.html"><a href="drv.html#exercises-for-feedback-1"><i class="fa fa-check"></i><b>3.5.1</b> Exercises for feedback</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="binpois.html"><a href="binpois.html"><i class="fa fa-check"></i><b>4</b> Special discrete random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="binpois.html"><a href="binpois.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.1</b> The Binomial Distribution</a></li>
<li class="chapter" data-level="4.2" data-path="binpois.html"><a href="binpois.html#the-binomial-mass-function"><i class="fa fa-check"></i><b>4.2</b> The binomial mass function</a></li>
<li class="chapter" data-level="4.3" data-path="binpois.html"><a href="binpois.html#mean-and-variance"><i class="fa fa-check"></i><b>4.3</b> Mean and variance</a></li>
<li class="chapter" data-level="4.4" data-path="binpois.html"><a href="binpois.html#the-poisson-distribution"><i class="fa fa-check"></i><b>4.4</b> The Poisson distribution</a><ul>
<li class="chapter" data-level="4.4.1" data-path="binpois.html"><a href="binpois.html#further-properties"><i class="fa fa-check"></i><b>4.4.1</b> Further properties</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="binpois.html"><a href="binpois.html#mean-and-variance-1"><i class="fa fa-check"></i><b>4.5</b> Mean and Variance</a></li>
<li class="chapter" data-level="4.6" data-path="binpois.html"><a href="binpois.html#deriving-the-poisson-mass-function"><i class="fa fa-check"></i><b>4.6</b> Deriving the Poisson mass function</a></li>
<li class="chapter" data-level="4.7" data-path="binpois.html"><a href="binpois.html#exercises-week-4"><i class="fa fa-check"></i><b>4.7</b> Exercises week 4</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cont.html"><a href="cont.html"><i class="fa fa-check"></i><b>5</b> Continuous random variables</a><ul>
<li class="chapter" data-level="5.1" data-path="cont.html"><a href="cont.html#relation-to-histograms"><i class="fa fa-check"></i><b>5.1</b> Relation to histograms</a></li>
<li class="chapter" data-level="5.2" data-path="cont.html"><a href="cont.html#two-students"><i class="fa fa-check"></i><b>5.2</b> Two students</a></li>
<li class="chapter" data-level="5.3" data-path="cont.html"><a href="cont.html#the-probability-density-function"><i class="fa fa-check"></i><b>5.3</b> The probability density function</a></li>
<li class="chapter" data-level="5.4" data-path="cont.html"><a href="cont.html#expectation-and-variance"><i class="fa fa-check"></i><b>5.4</b> Expectation and variance</a></li>
<li class="chapter" data-level="5.5" data-path="cont.html"><a href="cont.html#mode"><i class="fa fa-check"></i><b>5.5</b> Mode</a></li>
<li class="chapter" data-level="5.6" data-path="cont.html"><a href="cont.html#cdf"><i class="fa fa-check"></i><b>5.6</b> CDF</a></li>
<li class="chapter" data-level="5.7" data-path="cont.html"><a href="cont.html#median-quartiles-and-percentiles"><i class="fa fa-check"></i><b>5.7</b> median, quartiles and percentiles</a></li>
<li class="chapter" data-level="5.8" data-path="cont.html"><a href="cont.html#uniform-distribution"><i class="fa fa-check"></i><b>5.8</b> Uniform distribution</a></li>
<li class="chapter" data-level="5.9" data-path="cont.html"><a href="cont.html#exponential-distribution"><i class="fa fa-check"></i><b>5.9</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.10" data-path="cont.html"><a href="cont.html#exercises-week-5"><i class="fa fa-check"></i><b>5.10</b> Exercises week 5</a><ul>
<li class="chapter" data-level="5.10.1" data-path="cont.html"><a href="cont.html#exercises-for-feedback-week-5"><i class="fa fa-check"></i><b>5.10.1</b> Exercises for feedback week 5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="norm.html"><a href="norm.html"><i class="fa fa-check"></i><b>6</b> Normal distribution</a><ul>
<li class="chapter" data-level="6.1" data-path="norm.html"><a href="norm.html#relation-to-data"><i class="fa fa-check"></i><b>6.1</b> Relation to data</a></li>
<li class="chapter" data-level="6.2" data-path="norm.html"><a href="norm.html#cauchy-density"><i class="fa fa-check"></i><b>6.2</b> Cauchy density</a></li>
<li class="chapter" data-level="6.3" data-path="norm.html"><a href="norm.html#normal-density"><i class="fa fa-check"></i><b>6.3</b> Normal density</a></li>
<li class="chapter" data-level="6.4" data-path="norm.html"><a href="norm.html#standard-normal"><i class="fa fa-check"></i><b>6.4</b> Standard normal</a></li>
<li class="chapter" data-level="6.5" data-path="norm.html"><a href="norm.html#evaluating-the-standard-normal-distribution"><i class="fa fa-check"></i><b>6.5</b> Evaluating the standard normal distribution</a></li>
<li class="chapter" data-level="6.6" data-path="norm.html"><a href="norm.html#standardising"><i class="fa fa-check"></i><b>6.6</b> Standardising</a></li>
<li class="chapter" data-level="6.7" data-path="norm.html"><a href="norm.html#inverse-cdf"><i class="fa fa-check"></i><b>6.7</b> Inverse CDF</a></li>
<li class="chapter" data-level="6.8" data-path="norm.html"><a href="norm.html#sampling-total"><i class="fa fa-check"></i><b>6.8</b> Sampling Total</a></li>
<li class="chapter" data-level="6.9" data-path="norm.html"><a href="norm.html#sampling-distribution-of-the-mean"><i class="fa fa-check"></i><b>6.9</b> Sampling distribution of the mean</a></li>
<li class="chapter" data-level="6.10" data-path="norm.html"><a href="norm.html#exercises-week-6"><i class="fa fa-check"></i><b>6.10</b> Exercises week 6</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html"><i class="fa fa-check"></i><b>7</b> Sampling and confidence intervals</a><ul>
<li class="chapter" data-level="7.1" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#confidence-intervals"><i class="fa fa-check"></i><b>7.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="7.2" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#unknown-variance"><i class="fa fa-check"></i><b>7.2</b> Unknown variance</a><ul>
<li class="chapter" data-level="7.2.1" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#estimating-the-variance"><i class="fa fa-check"></i><b>7.2.1</b> Estimating the variance</a></li>
<li class="chapter" data-level="7.2.2" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#the-t-distribution"><i class="fa fa-check"></i><b>7.2.2</b> The t distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#required-sample-sizes"><i class="fa fa-check"></i><b>7.3</b> Required sample sizes</a></li>
<li class="chapter" data-level="7.4" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#interval-for-a-population-variance"><i class="fa fa-check"></i><b>7.4</b> Interval for a population variance</a></li>
<li class="chapter" data-level="7.5" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#interval-for-a-proportion"><i class="fa fa-check"></i><b>7.5</b> Interval for a proportion</a><ul>
<li class="chapter" data-level="7.5.1" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#approximating-the-binomial-distribution."><i class="fa fa-check"></i><b>7.5.1</b> Approximating the binomial distribution.</a></li>
<li class="chapter" data-level="7.5.2" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#proportions"><i class="fa fa-check"></i><b>7.5.2</b> Proportions</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#summary"><i class="fa fa-check"></i><b>7.6</b> Summary</a></li>
<li class="chapter" data-level="7.7" data-path="sampling-and-confidence-intervals.html"><a href="sampling-and-confidence-intervals.html#exercises-week-7"><i class="fa fa-check"></i><b>7.7</b> Exercises week 7</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="8.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-sample-tests"><i class="fa fa-check"></i><b>8.1</b> One sample tests</a><ul>
<li class="chapter" data-level="8.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-mean-known-variance"><i class="fa fa-check"></i><b>8.1.1</b> test for mean (known variance)</a></li>
<li class="chapter" data-level="8.1.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-mean-unknown-variance"><i class="fa fa-check"></i><b>8.1.2</b> test for mean (unknown variance)</a></li>
<li class="chapter" data-level="8.1.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-variance"><i class="fa fa-check"></i><b>8.1.3</b> test for variance</a></li>
<li class="chapter" data-level="8.1.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#p-value-approach"><i class="fa fa-check"></i><b>8.1.4</b> p-value approach</a></li>
<li class="chapter" data-level="8.1.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#types-of-error"><i class="fa fa-check"></i><b>8.1.5</b> types of error</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#two-sample-tests"><i class="fa fa-check"></i><b>8.2</b> Two sample tests</a><ul>
<li class="chapter" data-level="8.2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#known-variance"><i class="fa fa-check"></i><b>8.2.1</b> known variance</a></li>
<li class="chapter" data-level="8.2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#unknown-equal-variance"><i class="fa fa-check"></i><b>8.2.2</b> unknown equal variance</a></li>
<li class="chapter" data-level="8.2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#testing-for-equal-variance"><i class="fa fa-check"></i><b>8.2.3</b> testing for equal variance</a></li>
<li class="chapter" data-level="8.2.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#unknown-unequal-variances-non-examinable"><i class="fa fa-check"></i><b>8.2.4</b> unknown unequal variances (non-examinable)</a></li>
<li class="chapter" data-level="8.2.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#summary-1"><i class="fa fa-check"></i><b>8.2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-week-8"><i class="fa fa-check"></i><b>8.3</b> Exercises week 8</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probability Theory and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 8</span> Hypothesis testing<a href="hypothesis-testing.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This week we will introduce the main method of statistical inference - the hypothesis test. We will formulate hypothesis tests, interpret and report the results of hypothesis tests for a mean and variance.</p>
<p>We will also understand how to test comparisons between population parameters.</p>
<div id="one-sample-tests" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.1</span> One sample tests<a href="hypothesis-testing.html#one-sample-tests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The operation of a hypothesis tests can be summarised in the following steps:</p>
<ol style="list-style-type: decimal">
<li><p>Summarise competing ideas about population parameters in terms of two hypotheses, called <strong><em>null</em></strong> and <strong><em>alternative</em></strong> hypotheses. The null hypothesis represents your default position, and the alternative is what you wish to test.</p></li>
<li><p>Choose a suitable test statistic, which assuming the null hypothesis should have a known distribution. Calculate the value of this test statistic, comparing it to a critical value of the known distribution. Or calculate the probability of the test statistic at least as extreme as that observed in the sample (p-value).</p></li>
<li><p>On the basis of this probability, decide whether there is evidence to reject the null hypothesis.</p></li>
</ol>
<p>Because of step (2) the conclusion of a hypothesis test is never <span class="math inline">\(100\%\)</span> true. Statistical inference does not involve black and white absolute truths, but is rather more subtle.</p>
<div id="test-for-mean-known-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.1</span> test for mean (known variance)<a href="hypothesis-testing.html#test-for-mean-known-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section we will test hypotheses about the population mean <span class="math inline">\(\mu\)</span> of a normal distribution.</p>
<p>How we implement the test depends on the hypotheses that we are testing.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Example 8.1  </strong></span>Each year trainees throughout the country sit a test. Over a period of time it has been established that the number of marks can be modelled by a normal distribution with mean <span class="math inline">\(70\)</span> and standard deviation <span class="math inline">\(6\)</span> marks.</p>
<p>This year it was thought that trainees from Greater Manchester performed better than expected.</p>
<p>A random sample of <span class="math inline">\(25\)</span> trainees from Manchester had an average mark of <span class="math inline">\(\bar{x}=73.2\)</span>.</p>
<p>Does this provide evidence, at the <span class="math inline">\(5\%\)</span> significance level, that the trainees from Greater Manchester did better than the national average?</p>
</div>
<p><em>solution</em></p>
<ol style="list-style-type: decimal">
<li><em>State your hypotheses</em></li>
</ol>
<p><span class="math display">\[\text{H}_0: \ \mu = 70 \\  \text{H}_A: \ \mu &gt; 70\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><em>Choose test statistic</em></li>
</ol>
<p>Here the statistic is <span class="math inline">\(\bar{X}\)</span> and recall <span class="math inline">\(\bar{X}\sim\text{N}(\mu,6^2/25)\)</span>. Assuming <span class="math inline">\(\text{H}_{0}\)</span>, then <span class="math inline">\(\mu=70\)</span>. So we have the distribution: <span class="math display">\[\bar{X}\sim\text{N}(70,1.44)\]</span></p>
<p>We calculate the standardised value of the observed sample mean</p>
<p><span class="math display">\[\frac{\bar{x} - 70}{\sigma /\sqrt{ n}}=\frac{73.2 - 70}{1.2} = 2.67\]</span>
And compare this to the <span class="math inline">\(z\)</span>-value with <span class="math inline">\(5\%\)</span> in the upper tail, which you can find in the inverse normal tables. (Why the upper tail? Because <span class="math inline">\(H_{A}\)</span> has a <span class="math inline">\(&gt;\)</span> in). See picture below.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:crit1"></span>
<img src="figures/criticalregion.JPG" alt="critical region" width="75%" />
<p class="caption">
Figure 8.1: critical region
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li><em>Decision</em>
Now <span class="math inline">\(2.6667 &gt; 1.6449\)</span>, this value of the sample mean is in the critical region. The interpretation is that a value as extreme as this or worse is sufficiently unlikely (<span class="math inline">\(&lt;5\%\)</span>), so we are able to reject <span class="math inline">\(\text{H}_{0}\)</span>.</li>
</ol>
<p>It is important that the sample is random, as otherwise this invalidates the conclusion. For example if these <span class="math inline">\(25\)</span> were particularly high attainers, then it would not be representative of the distribution, and <span class="math inline">\(\bar{x}\)</span> may have been smaller in a representative sample.</p>
<p>In the example above we compare positive values, and the critical region is in the left tail of the distribution.</p>
<div class="definition">
<p><span id="def:unlabeled-div-2" class="definition"><strong>Definition 8.1  </strong></span>We say a hypothesis test is <strong><em>left-tailed</em></strong> if it is of the form:
<span class="math display">\[\text{H}_A: \ \mu &gt; \mu_0\]</span>
A hypothesis is <strong><em>right-tailed</em></strong> if it is of the form:</p>
<p><span class="math display">\[\text{H}_A: \ \mu &lt; \mu_0\]</span></p>
<p>And <strong><em>two-tailed</em></strong> if it is of the form:
<span class="math display">\[\text{H}_A: \ \mu \neq \mu_0\]</span></p>
</div>
<p>This is a table for the decision process</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(\text{H}_{A}\)</span></th>
<th align="center">Reject <span class="math inline">\(H_{0}\)</span> if</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(H_{A}: \mu &gt; \mu_0\)</span></td>
<td align="center"><span class="math inline">\(Z&gt;z_{\alpha}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(H_{A}: \mu &gt; \mu_0\)</span></td>
<td align="center"><span class="math inline">\(Z&lt;-z_{\alpha}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(H_{A}: \mu \neq \mu_0\)</span></td>
<td align="center"><span class="math inline">\(|Z|&gt;z_{\frac{1}{2}\alpha}\)</span></td>
</tr>
</tbody>
</table>
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>Example 8.2  </strong></span>In the testing example suppose the sample mean had been <span class="math inline">\(\bar{x}=69.5\)</span>, and we wished to test at the <span class="math inline">\(5\%\)</span> level if the mean is different from <span class="math inline">\(70\)</span>. That is:</p>
<p><span class="math display">\[\text{H}_0: \ \mu = 70 \\  \text{H}_A: \ \mu \neq 70\]</span>
<em>solution</em></p>
<p>We calculate the test statistic as before:</p>
<p><span class="math display">\[\frac{\bar{x}-\mu_0}{\sigma / \sqrt{n}} =\frac{69.5-70}{1.2}=-0.4167  \]</span>
The alternative hypothesis <span class="math inline">\(\neq\)</span> includes left <span class="math inline">\(&gt;\)</span> and right <span class="math inline">\(&lt;\)</span> tails. Now <span class="math inline">\(5\%\)</span> is in both tails, so <span class="math inline">\(5\% / 2 =2.5\%\)</span> in either tail.</p>
<p>Using tables we find that <span class="math inline">\(z_{2.5\%} = 1.960\)</span>. We would reject if the test statistic were greater than <span class="math inline">\(1.96\)</span> or if the test statistic were smaller than <span class="math inline">\(-1.96\)</span>. Equivalently we would reject <span class="math inline">\(\text{H}_0\)</span> if the modulus exceeds 1.96, that is <span class="math display">\[|\text{ test statistic}|&gt;1.96.\]</span></p>
<p>Here
<span class="math display">\[|-0.4167| = 0.4167 \ngtr 1.96,\]</span>
so there is insufficient evidence to reject <span class="math inline">\(text{H}_0\)</span>.</p>
</div>
<p>Recall the interpretation of this conclusion is never definitive. We never accept the null hypothesis, but rather fail to reject it. It may be that with further data we pass the threshold of the critical value and are able to reject the null hypothesis.</p>
<p>A two-sided alternative hypothesis is similar to a confidence interval.</p>
<p>If a confidence interval with confidence level <span class="math inline">\(c\%\)</span> excludes the population value of interest, then the null hypothesis that teh population parameter takes this value will be rejected at the <span class="math inline">\(100(1-c)\%\)</span> level.</p>
<div class="example">
<p><span id="exm:unlabeled-div-4" class="example"><strong>Example 8.3  </strong></span>Suppose a <span class="math inline">\(95\%\)</span> confidence interval for the mean <span class="math inline">\(\mu\)</span> is <span class="math inline">\((83.0,85.1)\)</span>, then the null hypothesis that <span class="math inline">\(\mu=85.2\)</span> will be rejected at the <span class="math inline">\(5\%\)</span> level since the interval excludes <span class="math inline">\(85.2\)</span>. Indeed any hypothesised value outside the interval will be rejected at the <span class="math inline">\(5\%\)</span> level.</p>
</div>
</div>
<div id="test-for-mean-unknown-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.2</span> test for mean (unknown variance)<a href="hypothesis-testing.html#test-for-mean-unknown-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When the population variance (<span class="math inline">\(\sigma^2\)</span>), or equivalently the population standard deviation <span class="math inline">\(\sigma\)</span>, is <em>unknown</em> we must estimate it from the sample.</p>
<p>For small samples the distribution of the test statistic follows a <span class="math inline">\(t\)</span>-distribution.</p>
<p>If the null hypothesis is given by <span class="math inline">\(\text{H}_0: \mu = \mu_0\)</span>, the test statistic is given by</p>
<p><span class="math display">\[T = \frac{\bar{x}-\mu_0}{s/\sqrt{n}}\sim t_{n-1}\]</span>
The decision rules are essentially the same but with <span class="math inline">\(z_\alpha\)</span> and <span class="math inline">\(z_{\alpha/2}\)</span> replaced by the same quantiles of the t-distribution <span class="math inline">\(t_{n-1,\alpha}\)</span> and <span class="math inline">\(t_{n-1,\alpha}\)</span>, respectively. Further <span class="math inline">\(\sigma\)</span> is estimated by <span class="math inline">\(s\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(\text{H}_{A}\)</span></th>
<th align="center">Reject <span class="math inline">\(H_{0}\)</span> if</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(H_{A}: \mu &gt; \mu_0\)</span></td>
<td align="center"><span class="math inline">\(T&gt;t_{\alpha}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(H_{A}: \mu &gt; \mu_0\)</span></td>
<td align="center"><span class="math inline">\(T&lt;-t_{\alpha}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(H_{A}: \mu \neq \mu_0\)</span></td>
<td align="center"><span class="math inline">\(|T|&gt;t_{\frac{1}{2}\alpha}\)</span></td>
</tr>
</tbody>
</table>
<p>Where <span class="math inline">\(t_{\alpha}\)</span> and <span class="math inline">\(t_{\alpha/2}\)</span> are obtained from <span class="math inline">\(t\)</span>-tables with degrees of freedom <span class="math inline">\(\nu = n-1\)</span>, and the sample variance is given by, for example,</p>
<p><span class="math display">\[s^2 =\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2.\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-5" class="example"><strong>Example 8.4  </strong></span>A shopkeeper sells jars of jam. The weights of the jars of jam are normally distributed with a mean of <span class="math inline">\(150\)</span>g. A customer complains that the mean weight of a pack of<span class="math inline">\(8\)</span> jars she had bought was only <span class="math inline">\(147\)</span>g. An estimate for the standard deviation of the weights of the <span class="math inline">\(8\)</span> jars of jam calculated from the <span class="math inline">\(8\)</span> observations was <span class="math inline">\(2\)</span>g.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Test at the <span class="math inline">\(5\%\)</span> significance level whether <span class="math inline">\(147\)</span>g is significantly less than the quoted mean.</p></li>
<li><p>Discuss whether the customer has cause for complaint.</p></li>
</ol>
<p><em>solution</em></p>
<ol style="list-style-type: lower-alpha">
<li></li>
</ol>
<p><span class="math display">\[H_{0}: \mu = 150 \\ \text{H}_A: \mu&lt;150\]</span></p>
<p>Significance level <span class="math inline">\(=0.05\)</span>, left-tailed test.</p>
<p>Degrees of freedom <span class="math inline">\(\nu = 8-1 = 7\)</span>.</p>
<p>From tables <span class="math inline">\(t_{7, \ 5\%} = -1.895\)</span></p>
<p>We reject <span class="math inline">\(H_0\)</span> if the statistic is less than <span class="math inline">\(-1.895\)</span></p>
<p><span class="math display">\[T =\frac{\bar{x}-\mu}{s/\sqrt{n}}=\frac{147-150}{2/\sqrt{8}}=-4.2426 \]</span>
Now <span class="math inline">\(-4.2426 &lt; -1.895\)</span>, the result is significant and <span class="math inline">\(H_0\)</span> is rejected.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>There is evidence to suggest that the mean weight is less than <span class="math inline">\(150\)</span>g, supporting the customer complaint. However one pack is not a random sample, so it could be a bad batch not that all the jars are being under-filled.</li>
</ol>
</div>
<p>The distribution of <span class="math inline">\(T\)</span> is only a <span class="math inline">\(t\)</span>-distribution when we assume a normally distributed population.</p>
<p>If the sample is large and so the degrees of freedom are increased, we still need to estimate and calculate <span class="math inline">\(s\)</span>, but often a <span class="math inline">\(z\)</span>-value can be used in practice. Strictly speaking a <span class="math inline">\(t\)</span>-value should be used in place of a <span class="math inline">\(z\)</span>-value whenever <span class="math inline">\(s\)</span> is used in place of <span class="math inline">\(\sigma\)</span> and not just because <span class="math inline">\(n\)</span> is small.</p>
</div>
<div id="test-for-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.3</span> test for variance<a href="hypothesis-testing.html#test-for-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you have a random sample of observations from a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> where both are unknown, the sample variance is given by (for example) the formula</p>
<p><span class="math display">\[S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2\]</span></p>
<p>Recall it can be shown that</p>
<p><span class="math display">\[\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}\]</span></p>
<p>To test against the null hypothesis that the variance is some particular value, that is
<span class="math display">\[\text{H}_0: \sigma^2 = \sigma_0^2\]</span>
We can just compare the expression <span class="math inline">\(\frac{(n-1)S^2}{\sigma^2}\)</span>, with the hypothesised population variance, to the relevant quantile of some chi-squared distribution. This gives the following decision rules:</p>
<table>
<colgroup>
<col width="45%" />
<col width="54%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(\text{H}_{A}\)</span></th>
<th align="center">Reject <span class="math inline">\(H_{0}\)</span> if</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(H_{A}: \sigma^2 &gt; \sigma^2_0\)</span></td>
<td align="center"><span class="math inline">\(\frac{(n-1)S^2}{\sigma^2}&gt;\chi^2_{\alpha, \ n-1}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(H_{A}: \sigma^2 \neq \sigma^2_0\)</span></td>
<td align="center"><span class="math inline">\(\frac{(n-1)S^2}{\sigma^2}&lt;\chi^2_{1-\frac{1}{2}\alpha, \ n-1}\)</span> or <span class="math inline">\(\frac{(n-1)S^2}{\sigma^2}&gt;\chi^2_{\frac{1}{2}\alpha, \ n-1}\)</span></td>
</tr>
</tbody>
</table>
<div class="example">
<p><span id="exm:unlabeled-div-6" class="example"><strong>Example 8.5  </strong></span>A bus company is trying to improve their reliability, and so the consistency with respect to the schedule is monitored. The company wants the arrival time to have standard deviation <span class="math inline">\(2\)</span> minutes or less. A sample of <span class="math inline">\(10\)</span> arrival times shows a sample variance of <span class="math inline">\(5\)</span>. Using a <span class="math inline">\(5\%\)</span> signifiance level, does the data suggest that the variance in arrival times is meeting the company standard?</p>
<p><em>solution</em>
Our hypotheses are:
<span class="math display">\[\text{H}_0: \sigma^2=4 \ \ \ , \ \ \ \text{H}_A: \sigma^2 &gt;4\]</span>
The test statistic is:
<span class="math display">\[\frac{(n-1)S^2}{\sigma^2}=\frac{9\times5}{4} = 11.25\]</span>
Our critical value is
<span class="math display">\[\chi^2_{\alpha,n-1}=\chi^2_{0.05,9}=16.92\]</span>
Since <span class="math inline">\(11.25\ngtr16.92\)</span> we have insufficient evidence to reject <span class="math inline">\(\text{H}_0\)</span>. Therefore we are unable to conclude that the variance in bus arrival times is not meeting the company standard.</p>
</div>
</div>
<div id="p-value-approach" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.4</span> p-value approach<a href="hypothesis-testing.html#p-value-approach" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are two ways of looking at the comparison involved to reject a null hypothesis, via the critical region or via p-values. The critical region is rather blunt and uninformative - we either reject or do not reject the null. However, the p-value allows us to quantify the weight of evidence against the null hypothesis given by the sample data. For many tests exact p-values can be calculated in R.</p>
<div class="definition">
<p><span id="def:unlabeled-div-7" class="definition"><strong>Definition 8.2  </strong></span>A <strong><em>p-value</em></strong> is the probability of a observing the value of a statistic at least as extreme as that of the particular value of that statistic in the observed sample.</p>
<p>For example if a sample gives sample mean <span class="math inline">\(\bar{x}=101.3\)</span> then the p-value would be <span class="math display">\[p  =\text{P}(\bar{X}\geq101.3)\]</span>.</p>
</div>
<p>We will illustrate an example with a right tailed test.</p>
<div class="example">
<p><span id="exm:unlabeled-div-8" class="example"><strong>Example 8.6  </strong></span>Suppose we want to test the following:
<span class="math display">\[\text{H}_0:\mu = 26.3 \ \ \ , \ \ \ \text{H}_A: \mu &gt;26.3\]</span>
Where:
| <span class="math inline">\(n\)</span> | <span class="math inline">\(\bar{x}\)</span>| <span class="math inline">\(\sigma\)</span> | <span class="math inline">\(\alpha\)</span>|
|:—:|:——–:|:——–:|:——-:|
| 10 | 27 | 1.2 | <span class="math inline">\(5\%\)</span> |</p>
<ol style="list-style-type: lower-alpha">
<li><p>Perform the test</p></li>
<li><p>Calculate the p-value</p></li>
</ol>
<p>Here we can work out the <span class="math inline">\(z\)</span>-value tobe <span class="math inline">\(1.6449\)</span>. The statistic is</p>
<p><span class="math display">\[\frac{27 - 26.3}{1.2/\sqrt{10}} = 1.845\]</span>
And we would reject <span class="math inline">\(\text{H}_0\)</span> as <span class="math inline">\(1.845 &gt; 1.6449\)</span>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li></li>
</ol>
<p>We know under the null hypothesis that <span class="math inline">\(\bar{X} \sim \text{N}(26.3, 1.2^2/10)\)</span>.</p>
<p>The p-value is the probability of observing a particular value at least as extreme as <span class="math inline">\(\bar{x}=27\)</span>.</p>
<p>You could use the distribution of <span class="math inline">\(\bar{X}\)</span> directly or the already standardised value above and find <span class="math display">\[p = \text{P}(\bar{X} &gt;27) = \text{P}(Z&gt;1.845) = 0.0325 \]</span></p>
</div>
<p>In the example above the p-value is <span class="math inline">\(0.0325\)</span> and the significance level was <span class="math inline">\(5\%\)</span>. The p-value can be compared to the significance level directly to conclude a hypothesis test. If the p-value is lower than the significance level, then we can reject the null hypothesis.</p>
<p>The statistic is <em>greater</em> than the critical value only when the p-value (tail probability) is <em>less</em> than the significance level. See the following picture:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pval"></span>
<img src="figures/p-value.JPG" alt="critical region" width="75%" />
<p class="caption">
Figure 8.2: critical region
</p>
</div>
<p>For tests involving the t-distribution or the chi-squared distribution, the p-value is in practice obtained via software such as R, and we will see this in labs this week.</p>
<p>Usually the p-value is compared to <span class="math inline">\(5\%\)</span> however, there are standard interpretations of p-values which quantify the evidence against <span class="math inline">\(\text{H}_0\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="center">p-value range</th>
<th align="center">interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(p&gt;0.1\)</span></td>
<td align="center">No evidence against H<span class="math inline">\(_0\)</span>, or data consistent with H<span class="math inline">\(_0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(0.05 &lt; p &lt; 0.1\)</span></td>
<td align="center">Weak evidence against H<span class="math inline">\(_0\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(0.01 &lt; p &lt; 0.05\)</span></td>
<td align="center">Some evidence against H<span class="math inline">\(_0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(0.001 &lt; p &lt; 0.01\)</span></td>
<td align="center">Strong evidence against H<span class="math inline">\(_0\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(0.001 &lt; p &lt; 0.01\)</span></td>
<td align="center">very strong evidence against H<span class="math inline">\(_0\)</span></td>
</tr>
</tbody>
</table>
<p>In formal reports if a significant effect is found, quantify the effect with a confidence interval. Phrasing of conclusions is important, always set in context (without jargon e.g. H<span class="math inline">\(_0\)</span>).</p>
</div>
<div id="types-of-error" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.5</span> types of error<a href="hypothesis-testing.html#types-of-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Any decision relying on imperfect information has to allow for the fact that there is uncertainty so the decision cannot be certain. There are two types of systematic uncertainty that arise from hypothesis testing, or types of error.</p>
<div class="example">
<p><span id="exm:unlabeled-div-9" class="example"><strong>Example 8.7  </strong></span>Suppose a man is in court accused of murder. The decision that the judge or jury come to is separate from the truth of the guilt or innocence of the man.</p>
<p><span class="math display">\[\ \ \ \ \text{H}_0: \text{the man is innocent} \\ \text{H}_1: \text{the man is guilty}\]</span>
The trial process is like an hypothesis test in which the evidence presented is equivalent to the data. The possible decisions are summarised in the table below:</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Innocent</th>
<th align="center">Not innocent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Accept innocence</td>
<td align="center"></td>
<td align="center">x</td>
</tr>
<tr class="even">
<td align="center">Reject innocence</td>
<td align="center">x</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>It would be undesirable to sentence an innocent man, or to find set a guilty man loose.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-10" class="definition"><strong>Definition 8.3  </strong></span>There are two types of error which are systematic to hypotheis testing.</p>
<p>A <strong><em>type I error</em></strong> is to reject the null hypothesis when it is, in fact true.</p>
<p>A <strong><em>type II error</em></strong> is to accept the null hypothesis when it is in fact false.</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">H<span class="math inline">\(_0\)</span> true</th>
<th align="center">H<span class="math inline">\(_0\)</span> false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Accept <span class="math inline">\(H_0\)</span></td>
<td align="center"></td>
<td align="center">II</td>
</tr>
<tr class="even">
<td align="center">Reject <span class="math inline">\(H_0\)</span></td>
<td align="center">I</td>
<td align="center"></td>
</tr>
</tbody>
</table>
</div>
<p>The probabilities of each type of error are important, we would seek to minimise both if possible.</p>
<div class="definition">
<p><span id="def:unlabeled-div-11" class="definition"><strong>Definition 8.4  </strong></span>The <strong><em>significance level</em></strong> of the test is the probability of type I error.
<span class="math display">\[\text{P}(\text{Type I error}) = \text{P}(\text{H}_0 \text{ rejected} | \text{H}_0 \text{ is true})\]</span>
If you are given the significance level for example <span class="math inline">\(5\%\)</span>, then this is the probability of type I error. However this may not always be stated in a question and you may have to work it out.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-12" class="example"><strong>Example 8.8  </strong></span>A random variable has a normal distribution with mean µ and standard deviation <span class="math inline">\(3\)</span>.
The null hypothesis <span class="math inline">\(\mu=20\)</span> is to be tested against the alternative hypothesis <span class="math inline">\(\mu&gt;20\)</span> using a random sample of <span class="math inline">\(25\)</span>.
It is decided that the null hypothesis will be rejected if the sample mean is greater than <span class="math inline">\(21.4\)</span>.
Calculate the probability of making a type I error.</p>
<p><em>solution</em></p>
<p><span class="math display">\[\text{P}(\text{Type I error}) = \text{P}(\text{H}_0 \text{ rejected} | \text{H}_0 \text{ is true})\]</span>
<span class="math display">\[=\text{P}(\bar{X} &gt; 21.4 \ | \ \mu = 20)\]</span>
This can be obtained, for example by standardising from tables,
<span class="math display">\[=\text{P}\left(\frac{\bar{X}-20}{3/\sqrt{25}}&gt;\frac{21.4-20}{3/\sqrt{25}} \right)\]</span>
<span class="math display">\[=\text{P}(Z&gt;2.33) = 9.9\times 10^{-3} \approx 1\%\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-13" class="example"><strong>Example 8.9  </strong></span>The weight of jam in a jar, measured in grams, is distributed normally with a mean of <span class="math inline">\(150\)</span>g and a standard deviation of <span class="math inline">\(6\)</span>g. The production process occasionally leads to a change in the mean weight of jam per jar but the standard deviation remains unaltered. The manager monitors the production process and for every new batch takes a random sample of <span class="math inline">\(25\)</span> jars and weighs their contents to see if there has been any <em>reduction</em> in the mean weight of jam per jar.
Find the critical values for the test statistic <span class="math inline">\(\bar{X}\)</span>, the mean weight of jam in a sample of <span class="math inline">\(25\)</span> jars, using</p>
<ol style="list-style-type: lower-alpha">
<li><p>5% level of significance</p></li>
<li><p>1% level of significance</p></li>
<li><p>Given that the true value of µ for the new batch is in fact 147g. Find the probability of a type II error for each of the above critical regions</p></li>
</ol>
<p><em>solution</em>
a) <span class="math inline">\(z_{5\%} = -1.6449\)</span>, so we would reject <span class="math inline">\(H_0\)</span> if</p>
<p><span class="math display">\[\frac{\bar{x}-150}{6/\sqrt{25}}&lt;-1.6449 \]</span>
Rearranging this inequality gives <span class="math inline">\(\bar{x} &lt; 148.03\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(z_{1\%} = -2.326\)</span> , rearranging a similar inequality gives <span class="math inline">\(\bar{x} &lt; 147.208\ldots\)</span></p></li>
<li><p>Here you use the distribution <span class="math inline">\(\bar{X}\sim\text{N}(147, 6^2/\sqrt{25})\)</span>. Type II error is where we do not reject <span class="math inline">\(H_0\)</span> so we reverse the inequalities from the regions above and evaluate the probabilities:</p></li>
</ol>
<p><span class="math display">\[\text{P}(\bar{x} \geq 148.03 | \ \mu = 147) = 0.195 \approx 20\%\]</span></p>
<p><span class="math display">\[\text{P}(\bar{x} \geq 147.2 | \ \mu = 147) = 0.4309\ldots \approx 43\%\]</span></p>
</div>
<p>When we reduce the P(Type I error) from 5% to 1%, P(Type II error) increased from <span class="math inline">\(\approx 20\%\)</span> to <span class="math inline">\(43\%\)</span>. So just reducing the probability of one type of error is not a cure-all.</p>
<!-- ### test for population proportion -->
</div>
</div>
<div id="two-sample-tests" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.2</span> Two sample tests<a href="hypothesis-testing.html#two-sample-tests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We may wish to use hypothesis testing to compare two populations. The two populations may be the distributions of heights of males and females separately. Or we may wish to compare average the weights of babies born in one region to another.</p>
<p>Supposing we have two distributions <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we write the population parameters with a subscript to indicate to which distribution they correspond. The basic setup is as follows</p>
<table>
<thead>
<tr class="header">
<th align="center">Parameter</th>
<th align="center">Population 1</th>
<th align="center">Population 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Mean</td>
<td align="center"><span class="math inline">\(\mu_X\)</span></td>
<td align="center"><span class="math inline">\(\mu_Y\)</span></td>
</tr>
<tr class="even">
<td align="center">Variance</td>
<td align="center"><span class="math inline">\(\sigma^2_X\)</span></td>
<td align="center"><span class="math inline">\(\sigma^2_Y\)</span></td>
</tr>
</tbody>
</table>
<p>The main hypotheses of interest are whether or not the means are different. That is:</p>
<p><span class="math display">\[\text{H}_0: \mu_X = \mu_Y \ \ \ \ \ \ , \ \ \ \ \ \text{H}_A:\mu_X \neq \mu_Y\]</span></p>
<p>Though one-sided alternatives, or specified differences can also be used.</p>
<p>We will assume both populations are normally distributed and consider three different situations:</p>
<ol style="list-style-type: lower-alpha">
<li><p>The population variances are known</p></li>
<li><p>The population variances are unknown, but known to be or are assumed to be equal.</p></li>
<li><p>The population variances are unknown and cannot be assumed to be equal.</p></li>
</ol>
<div id="known-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.1</span> known variance<a href="hypothesis-testing.html#known-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assume we have a random sample <span class="math inline">\(x_1,x_2,\ldots,x_{n_1}\)</span> of <span class="math inline">\(n_1\)</span> observations from the first population, and another random sample <span class="math inline">\(y_1,y_2,\ldots, y_{n_2}\)</span> of <span class="math inline">\(n_2\)</span> observations from the second population.</p>
<p>The test statistic here is <span class="math inline">\(\bar{X}-\bar{Y}\)</span>.</p>
<p>Recall that the sampling distribution of the mean takes the form:
<span class="math display">\[\bar{X} \sim \text{N}(\mu_X, \sigma^2_X / n_1) \ \ \ \ \ \ , \ \ \ \ \bar{Y} \sim \text{N}(\mu_Y, \sigma^2_Y / n_2)\]</span>
Then, as the difference of normal distributions is again normal, with linearity of the expectation and variance the sum of the variances we have:</p>
<p><span class="math display">\[\bar{X}-\bar{Y} \sim \text{N}\left(\mu_X-\mu_Y , \frac{\sigma_X^2}{n_1} + \frac{\sigma_Y^2}{n_2}\right)\]</span>
The test statistic is the standardised value of this statistic:</p>
<p><span class="math display">\[Z = \frac{\bar{X} - \bar{Y} - (\mu_X-\mu_Y)}{\sqrt{\frac{\sigma_X^2}{n_1} + \frac{\sigma_Y^2}{n_2}}}\]</span>
<span class="math display">\[\sim\text{N}(0,1).\]</span>
Now under the null hypothesis <span class="math inline">\(\mu_X-\mu_Y = 0\)</span>, so this simplifies to:</p>
<p><span class="math display">\[\frac{\bar{X} - \bar{Y}}{\sqrt{\frac{\sigma_X^2}{n_1} + \frac{\sigma_Y^2}{n_2}}}\]</span>
And we have the same decision rules as before.</p>
<div class="example">
<p><span id="exm:unlabeled-div-14" class="example"><strong>Example 8.10  </strong></span>The weights of boys and girls of a particular age are known to be normally distributed with standard deviations <span class="math inline">\(5\)</span>kg and <span class="math inline">\(8\)</span>kg respectively. In a particular school, a random sample of <span class="math inline">\(25\)</span> boys had mean weight <span class="math inline">\(48\)</span>kg and a random sample of <span class="math inline">\(30\)</span> girls had mean weight <span class="math inline">\(45\)</span>kg.</p>
<p>Test, at the <span class="math inline">\(5\%\)</span> significance level, whether there is evidence that the mean weight of the boys is greater than that of the girls.</p>
<p><em>solution</em></p>
<p><span class="math display">\[\text{H}_0: \mu_B = \mu_G \ \ \ \ \ \ , \ \ \ \ \ \text{H}_A:\mu_B &gt; \mu_G\]</span></p>
<p>We have
<span class="math display">\[\frac{\bar{B}-\bar{G}}{\sqrt{\frac{\sigma_B^2}{n_1} + \frac{\sigma_G^2}{n_2}}}= \frac{48-45}{\sqrt{\frac{5^2}{25}+\frac{8^2}{30}}}= 1.69747\ldots \]</span>
The critical value is <span class="math inline">\(1.6449\)</span>
Hence here we reject the null hypothesis and conclude there is sufficient evidence to say that the boys weigh more than the girls on average.</p>
</div>
</div>
<div id="unknown-equal-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.2</span> unknown equal variance<a href="hypothesis-testing.html#unknown-equal-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section we know or can assume that the variances are equal. We may know outright that the variances are equal, even if they are unknown. For example, if I take a sample of men’s heights from Manchester and compare to a sample of men’s heights in London. It may be that there are average height differences, but as both are UK adult men they come from the same containing population, can be assumed to be just as variable as each other.</p>
<p>In this case we do not know <span class="math inline">\(\sigma_X^2\)</span> or <span class="math inline">\(\sigma_Y^2\)</span>, so we will have to estimate each of these from actual data. We can estimate each by</p>
<p><span class="math display">\[s_x^2 = \frac{1}{n_1}\sum_{i=1}^n(x_i-\bar{x})^2 \ \ \ \ , \ \ \ \ s_y^2 = \frac{1}{n_2}\sum_{j=1}^n(y_j-\bar{y})^2 \]</span></p>
<p>But now we have two estimates for the unknown population variances <span class="math inline">\(\sigma_x^2, \ \sigma_y^2\)</span>. But we know, or can assume, these are equal to a common population variance <span class="math inline">\(\sigma_x^2=\sigma_y^2=\sigma^2\)</span>. The solution to this is to ‘pool’ the variance using the formula:</p>
<p><span class="math display">\[s_p^2  = \frac{(n_1-1)s_x^2+(n_2-1)s_y^2}{n_1+n_2-2}\]</span>
The test statistic is then calculated as,</p>
<p><span class="math display">\[T = \frac{\bar{X}-\bar{Y}}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t_{n_1+n_2-2} \]</span>
which follows a t distribution on <span class="math inline">\(n_1+n_2-2\)</span> degrees of freedom.</p>
<div class="example">
<p><span id="exm:unlabeled-div-15" class="example"><strong>Example 8.11  </strong></span>The heights (measured to the nearest centimetre) of a random sample of six policement from a certain force in Wales were found to be
<span class="math display">\[176, \ 180, \ 179, \ 181, \ 183, \ 179.\]</span>
The heights of a random sample of <span class="math inline">\(11\)</span> policemen from Scotland gave the following data</p>
<p><span class="math display">\[\sum y =1991  \ \ \ \ , \ \ \ \sum(y-\bar{y})^2 = 54\]</span>
a) Test at the <span class="math inline">\(5\%\)</span> level the hypothesis that the Welsh policemen are shorter than the Scottish policemen.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>What assumptions are necessary for part (a)?</li>
</ol>
</div>
<p><em>solution</em></p>
<p>The hypotheses are
<span class="math display">\[\text{H}_0: \mu_{x} = \mu_{y} \ \ \ \ , \ \ \ \text{H}_A: \mu_{x}&lt; \mu_{y}\]</span>
From the question:</p>
<p><span class="math display">\[\bar{x}=179.66667, \ \ s^2_x =5.46667 \]</span></p>
<p><span class="math display">\[\bar{y}= 1991/11 = 181, \ \ \ s^2_y = 54/10 = 5.4 \]</span>
We observe that 5.4 and 5.47 are approximately equal, so it is reasonable to pool these.</p>
<p><span class="math display">\[s^2_p = \frac{(6-1)\times5.46667 +(11-1)\times5.4 }{6+11-2} =5.422\ldots\]</span>
Giving a pooled standard deviation of <span class="math inline">\(\sqrt{5.422} = 2.329\)</span>.
(you want to work a bit more accurately than the accuracy of the critical value you will be comparing to)</p>
<p>Now evaluating the test statistic:</p>
<p><span class="math display">\[\frac{179.66 - 181}{2.329\sqrt{\frac{1}{6}+\frac{1}{11}}} =  -1.128\]</span>
We compare this to <span class="math inline">\(t_{15, 0.05} = 1.7531\)</span></p>
<p>Comparison: <span class="math inline">\(|-1.128|\ngtr 1.7531\)</span></p>
<p>There is insufficient evidence based on these samples to conclude that the population of Welsh officers are shorter than the population of Scottish officers.</p>
</div>
<div id="testing-for-equal-variance" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.3</span> testing for equal variance<a href="hypothesis-testing.html#testing-for-equal-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this situation we have two sample variances <span class="math inline">\(S^2_x\)</span> and <span class="math inline">\(S^2_y\)</span>, and we want to determine by means of a hypothesis test if these are equal or not. Of course the conclusion is not definite, but in practice this informs whether we will pool the variances or not.</p>
<p>The null hypothesis is that the variances are equal, with the usual alternatives.</p>
<p><span class="math display">\[\text{H}_0: \sigma^2_x = \sigma^2_y\ \]</span></p>
<p>First a recap. We know that when scaled, sample variances follow a <span class="math inline">\(\chi^2\)</span>-distribution. That is,</p>
<p><span class="math display">\[\frac{(n_1-1)S^2_x}{\sigma^2_x}\sim \chi^2_{n_1-1} \ \ \ , \ \ \  \frac{(n_2-1)S^2_y}{\sigma^2_y}\sim \chi^2_{n_2-1}\]</span></p>
<p>There is another distribution we must define, and this will be the last for the statistical tables.</p>
<div class="definition">
<p><span id="def:unlabeled-div-16" class="definition"><strong>Definition 8.5  </strong></span>Let <span class="math inline">\(X\sim \chi^2_n\)</span> and <span class="math inline">\(Y\sim \chi^2_m\)</span> then the following ratio defines an F-distribution with degrees of freedom <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span>. That is:</p>
<p><span class="math display">\[\frac{\left(\frac{X}{n}\right)}{\left(\frac{Y}{m}\right)}\sim \text{F}_{n,m}\]</span></p>
</div>
<p>In our situation this tells us that under the null hypothesis we have</p>
<p><span class="math display">\[\frac{S^2_x}{S^2_y}\sim \text{F}_{n_1 - 1,n_2-1} \]</span>
:::{.example}
A manufacturer of wooden furniture stores some of its wood outside and some inside a special
store. It is believed that the wood stored inside should have less variable hardness properties than that stored outside. Some <span class="math inline">\(25\)</span> pieces of wood stored outside was taken and compared to <span class="math inline">\(21\)</span> similar pieces taken from the inside store, with the following results:</p>
<table>
<thead>
<tr class="header">
<th align="center">Value</th>
<th align="center">Outside</th>
<th align="center">Inside</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">sample size</td>
<td align="center">25</td>
<td align="center">21</td>
</tr>
<tr class="even">
<td align="center">Mean hardness</td>
<td align="center">110</td>
<td align="center">122</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\sum(x-\bar{x})^2\)</span></td>
<td align="center">5190</td>
<td align="center">3972</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li><p>Test at the <span class="math inline">\(5\%\)</span> significance level whether the manufacturer’s belief is correct.</p></li>
<li><p>State two assumptions necessary to carry out this test.</p></li>
</ol>
<p><em>solution</em></p>
<ol style="list-style-type: lower-alpha">
<li>We wish to test</li>
</ol>
<p><span class="math display">\[\text{H}_0: \sigma^2_x=\sigma^2_y \ \ \ , \ \ \ \text{H}_A: \sigma^2_x&gt;\sigma^2_y\]</span>
Working out the sample variances gives</p>
<p><span class="math display">\[s^2_x = \frac{5190}{25}=216.25, \ \ \ s^2_y = \frac{3972}{20} = 198.6\]</span>
The test statistic is then</p>
<p><span class="math display">\[216.25/198.6 = 1.089,\]</span>
which we compare to <span class="math inline">\(\text{F}_{24,20} = 2.08\)</span>.</p>
<p>Now, <span class="math inline">\(1.089 &lt; 2.08\)</span> so there is insufficient evidence to reject <span class="math inline">\(\text{H}_0\)</span>. So the wood from outside is just as variable as the wood inside.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>The assumption is that both populations are normal, and that the samples are independent and random.
:::</li>
</ol>
</div>
<div id="unknown-unequal-variances-non-examinable" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.4</span> unknown unequal variances (non-examinable)<a href="hypothesis-testing.html#unknown-unequal-variances-non-examinable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we want to carry out a <span class="math inline">\(2\)</span> sample <span class="math inline">\(t\)</span>-test without assuming equal population variances we can use <span class="math display">\[T = \frac{\bar{X} - \bar{Y}}{\sqrt{\frac{S_X^2}{n_1} + \frac{S_Y^2}{n_2}}}\]</span></p>
<p>However the distribution of this quantity is in general not of a convenient closed-form (analytic). As such it is actually a famous an unsolved problem generally, called the Behrens–Fisher problem. However it is approximately a <span class="math inline">\(t_\nu\)</span>-distribution with degrees of freedom <span class="math inline">\(\nu\)</span> given by the integer part of the following expression.</p>
<p><span class="math display">\[\frac{\left[\frac{S^2_x}{n_1}+\frac{S^2_y}{n_2} \right]^2}{\frac{1}{(n_1-1)}\left[\frac{S_x^2}{n_1}\right]^2+\frac{1}{(n_2-1)}\left[\frac{S_y^2}{n_2}\right]^2} \]</span></p>
<p>The above expression is known as the Welch approximation.</p>
<div class="example">
<p><span id="exm:unlabeled-div-17" class="example"><strong>Example 8.12  </strong></span>A market inspector randomly samples the produce on two market stalls. A sample of <span class="math inline">\(80\)</span> apples from Rufus Russett’s stall had masses (in grams) having sample mean <span class="math inline">\(74.2\)</span> and sample variance <span class="math inline">\(43.23\)</span>.
An independent random sample of <span class="math inline">\(100\)</span> apples sold my Granny Smith had a sample mean of <span class="math inline">\(68.6\)</span> and a sample variance of <span class="math inline">\(43.34\)</span>.</p>
<p>Test at the <span class="math inline">\(5\%\)</span> significance level if there is evidence that the apples on Smith’s stall have a lower average mass than Russett’s stall.</p>
</div>
<p><em>solution</em></p>
<p>We are testing
<span class="math display">\[\text{H}_0: \mu_x = \mu_y \ \ \ , \ \ \text{H}_A:\mu_x&gt;\mu_y\]</span>
The test statistic is</p>
<p><span class="math display">\[ \frac{74.2 - 68.8}{\sqrt{\frac{24.21}{80}+\frac{43.23}{100}}} = 6.299\]</span>
We want to compare this to <span class="math inline">\(t_\nu\)</span>. Let’s evaluate the degrees of freedom here:</p>
<p><span class="math display">\[\frac{\left[\frac{24.21}{80}+\frac{43.23}{100} \right]^2}{\frac{1}{79}\left[\frac{24.21}{80}\right]^2+\frac{1}{99}\left[\frac{43.23}{100}\right]^2} = 177.26 \]</span>
The integer value of this is <span class="math inline">\(177\)</span>, so we would check the critical value of a <span class="math inline">\(t_177\)</span> distribution.</p>
<p>However <span class="math inline">\(177\)</span> is a large number of degrees of freedom, so we use <span class="math inline">\(t_{\infty}=1.6448\)</span> or <span class="math inline">\(z\)</span>-value essentially, and the null is overwhelmingly rejected, as <span class="math inline">\(6.299 &gt;1.6448\)</span>.</p>
</div>
<div id="summary-1" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.5</span> Summary<a href="hypothesis-testing.html#summary-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>A hypothesis test is a decision process about population parameters.</li>
</ul>
<p>One sample tests we have learned about include:</p>
<ul>
<li><p>one sample <span class="math inline">\(z\)</span>-test for the mean, known variance
<span class="math display">\[ \frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}}\sim \text{N}(0,1) \]</span></p></li>
<li><p>one sample <span class="math inline">\(t\)</span>-test, for the mean, unknown variance
<span class="math display">\[T = \frac{\bar{x}-\mu_0}{s/\sqrt{n}}\sim t_{n-1}\]</span></p></li>
<li><p>one sample test for variance</p></li>
</ul>
<p><span class="math display">\[\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1} \]</span></p>
<p>There are two types of systematic errors that occur when we test hypotheses, we typically limit the <em>type I</em> error by setting the significance level.</p>
<p>We can compare two independent samples with:</p>
<ul>
<li>two sample <span class="math inline">\(z\)</span>-test (known variances)</li>
</ul>
<p><span class="math display">\[\frac{\bar{X} - \bar{Y}}{\sqrt{\frac{\sigma_X^2}{n_1} + \frac{\sigma_Y^2}{n_2}}}\sim \text{N}(0,1)\]</span></p>
<ul>
<li>two sample <span class="math inline">\(t\)</span>-test (unknown equal variances) require pooled variance estimate:</li>
</ul>
<p><span class="math display">\[T = \frac{\bar{X}-\bar{Y}}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t_{n_1+n_2-2}\]</span>
<span class="math display">\[s_p = \frac{(n_1-1)s_x^2+(n_2-1)s_y^2}{n_1+n_2-2}\]</span></p>
<p>We can often assume the variances are equal. There is also a test for equality of variances.</p>
</div>
</div>
<div id="exercises-week-8" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.3</span> Exercises week 8<a href="hypothesis-testing.html#exercises-week-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="exercise">
<p><span id="exr:unlabeled-div-18" class="exercise"><strong>Exercise 8.1  </strong></span>Jars of honey are filled by a machine. Over the lifetime of the machine, it has been found the quantity of honey has mean <span class="math inline">\(460.3\)</span>g and standard deviation <span class="math inline">\(3.2\)</span>g. It is believed that the machine has been altered so that the mean may have changed. <span class="math inline">\(60\)</span> jars are taken and the mean quantity of honey per jar is found to be <span class="math inline">\(461.2\)</span>g</p>
<ol style="list-style-type: lower-alpha">
<li><p>State suitable null and alternative hypotheses</p></li>
<li><p>Carry out a test using a <span class="math inline">\(5\%\)</span> level of significance.</p></li>
<li><p>State two assumptions required for this test, and give an example of how each may not hold true.</p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-19" class="exercise"><strong>Exercise 8.2  </strong></span>The distance driven by a long distance lorry driver in a week is a normally distributed variable with mean <span class="math inline">\(1130\)</span>km and standard deviation <span class="math inline">\(106\)</span>km. New driving regulations are introduced and, in the first <span class="math inline">\(20\)</span> weeks he drives a total of <span class="math inline">\(21900\)</span>km. Assuming the standard deviation has not changed since the new regulations, test at the <span class="math inline">\(10\%\)</span> level of significance whether the mean weekly distance has reduced. State clearly your null and alternative hypotheses.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-20" class="exercise"><strong>Exercise 8.3  </strong></span>After a nuclear accident,government scientists measured radiation levelsat <span class="math inline">\(20\)</span> randomly chosen sites in a small area. The measuring instrument used is calibrated so as to measure the ratio of present radiation to the previous known average radiation in that area. The measurements are summarised by</p>
<p><span class="math display">\[\sum x = 22.8 \ \ , \ \ \sum x^2 = 27.55\]</span>
Making suitable assumptions test, at the <span class="math inline">\(5\%\)</span> level, the hypothesis that there has been no increase in the radiation level.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-21" class="exercise"><strong>Exercise 8.4  </strong></span>Bottles of wine are supposed to contain <span class="math inline">\(75\)</span>cl of wine. An inspector takes a sample of six bottles and determines the volumes of their contents, correct to the nearest half millilitre. Her results are:</p>
<p><span class="math display">\[747.0, \ \  ,751.5, \ \ 752.0, \  \ 747.5, \ \ 748.0, \ \ 748.0 \]</span>
Determine whether these results provide evidence at the <span class="math inline">\(5\%\)</span> significance level that the population mean is less than <span class="math inline">\(75\)</span>cl.</p>
<p>What assumption about the distribution of the volumes is necessary?</p>
<p>What distribution about the sample is necessary?</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-22" class="exercise"><strong>Exercise 8.5  </strong></span>It is given that <span class="math inline">\(X\sim\text{N}(\mu,16)\)</span>. It is desired to test the null hypothesis <span class="math inline">\(\mu=12\)</span> against the alternative <span class="math inline">\(\mu&gt;12\)</span>, with the probability of type I error being <span class="math inline">\(1\%\)</span>. A random sample of <span class="math inline">\(15\)</span> observations of <span class="math inline">\(X\)</span> is taken and the sample mean <span class="math inline">\(\bar{X}\)</span> is taken to be the test statistic.</p>
<ol style="list-style-type: lower-alpha">
<li>Find the range of values for <span class="math inline">\(\bar{X}\)</span> that would lead to</li>
</ol>
<ol style="list-style-type: lower-roman">
<li>rejecting the null hypothesis</li>
<li>not rejecting the null hypothesis</li>
</ol>
<ol start="2" style="list-style-type: lower-alpha">
<li>Given that <span class="math inline">\(\mu = 15\)</span>, calculate the probability of type II error.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-23" class="exercise"><strong>Exercise 8.6  </strong></span>The mean of a random sample of <span class="math inline">\(10\)</span> observations from a population distributed as <span class="math inline">\(\text{N}(\mu_1,25)\)</span> is <span class="math inline">\(97.3\)</span>. The mean of a random sample of <span class="math inline">\(15\)</span> observations from a population distributed as <span class="math inline">\(\text{N}(\mu_2,36)\)</span> is <span class="math inline">\(101.2\)</span>. Test at the <span class="math inline">\(5\%\)</span> level</p>
<ol style="list-style-type: lower-roman">
<li><p>Whether <span class="math inline">\(\mu_1 &lt; \mu_2\)</span></p></li>
<li><p>Whether <span class="math inline">\(\mu_1\neq\mu_2\)</span></p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-24" class="exercise"><strong>Exercise 8.7  </strong></span>A machine assesses the life of a ball-point pen by measuring the length of a continuous line drawn using the pen. A random sample of <span class="math inline">\(80\)</span> pens from brand A have a total writing length of <span class="math inline">\(96.84\)</span>km. A random sample of <span class="math inline">\(75\)</span> ens of brand B have a total writing length of <span class="math inline">\(93.75\)</span>km.
Given that the standard deviation of the writing length of a single pen is <span class="math inline">\(0.15\)</span>km for both brands,test at the <span class="math inline">\(5\%\)</span> level, whether writing lengths of the two brands differ significantly.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-25" class="exercise"><strong>Exercise 8.8  </strong></span>A random sample of <span class="math inline">\(10\)</span> yellow grapefruit is weighed and the average weight is found to be <span class="math inline">\(\bar{x}=201.4\)</span>g. The value of an unbiased estimate for the population variance is <span class="math inline">\(s^2_x=234.1\)</span>. The corresponding figures for a random sample of <span class="math inline">\(8\)</span> pink grapefruit are <span class="math inline">\(\bar{y}=221.8\)</span>g and <span class="math inline">\(s^2_y=281.9\)</span>. Determine at the <span class="math inline">\(1\%\)</span> level of significance, whether there is a difference in the mean weights of the two kinds of grapefruit.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-26" class="exercise"><strong>Exercise 8.9  </strong></span>The volume of beer in a random sample of <span class="math inline">\(7\)</span> pints bought at ‘The Sensible Statistician’ are measured in litres and the results are summarised by:
<span class="math display">\[\sum x = 4.15, \ \ \sum x^2 = 2.4638\]</span>
The results for a random sample of <span class="math inline">\(5\)</span> pints from ‘The Mad Mathematician’ are summarised by:
<span class="math display">\[\sum y = 2.79 , \ \ \sum y^2 = 1.5585\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Assuming the population variances are equal, find a pooled estimate of the common variance.</p></li>
<li><p>Test at the <span class="math inline">\(5\%\)</span> significance level whether there is more beer in a pint from ‘The Sensible Statistician’ than ‘The Mad Mathematician’.</p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-27" class="exercise"><strong>Exercise 8.10  </strong></span>A machine saws logs of wood into lengths that are supposed to have a standard deviation of <span class="math inline">\(3\)</span>cm. If the machine goes wrong then the standard deviation increases. A random sample of <span class="math inline">\(10\)</span> logs have lengths in cm as follows:</p>
<p><span class="math display">\[997, \ \ , 1004, \ \ 1009, \ \ 999, \ \ 1006, \ \, 1014, \ \ 998, \ \ 999, \ \ 1001, \ \ 1000 \]</span></p>
<p>Determine whether there is evidence at the <span class="math inline">\(1\%\)</span> significance level that the machine has gone wrong.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-28" class="exercise"><strong>Exercise 8.11  </strong></span>The following observations are taken from a normal distribution that is believed to have unit variance.
<span class="math display">\[16.2, \ \ 14.4, \ \ 17.9, \ \ 11.6, \ \ 18.3, \ \ 15.5, \ \ 17.2, \ \ 16.6\]</span></p>
<p>Determine whether there is evidence that the population variance is not equal to 1.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-29" class="exercise"><strong>Exercise 8.12  </strong></span>The cellulose contents of the leaves of a tree are determined from random samples of leaves taken from two different locations. The results are shown below:</p>
<p>Location 1:
<span class="math display">\[15.4, \ \ 13.9, \ \ 15.1, \ \ 14.8, \ \ 14.4, \ \ 14.8, \ \ 15.0, \ \  13.9, \ \ 15.4, \ \ 14.6, \ \ 14.8 \]</span>
Location 2:
<span class="math display">\[13.8, \ \ 14.4, \ \ 13.0, \ \ 15.3, \ \ 14.7, \ \ 14.3, \ \ 14.1, \ \ 12.9, \ \ 14.9 \]</span>
Let the population variances for the two locations be denoted <span class="math inline">\(\sigma_1^2\)</span> and <span class="math inline">\(\sigma_2^2\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Obtain unbiased estimates for <span class="math inline">\(\sigma_1^2\)</span> and <span class="math inline">\(\sigma_2^2\)</span>.</p></li>
<li><p>Test the hypothesis that <span class="math inline">\(\sigma_1^2=\sigma_2^2\)</span>.</p></li>
</ol>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sampling-and-confidence-intervals.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["6G4Z3008-notes.pdf", "6G4Z3008-notes.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
