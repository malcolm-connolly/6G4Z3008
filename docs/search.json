[{"path":"index.html","id":"intro","chapter":"1 Introduction to Probability","heading":"1 Introduction to Probability","text":"things happen entirely predictable. example, one drops ball height, know hit ground. Things happen like can decribed deterministic. may heard people talk things written stars, fate, destiny. opinion things pre-determined called determinism.However, even determinist, live uncertainty. everyday lives can think examples things happen predict; bus may late, may rain, one might win lottery. one living uncertainty, reasonable quantify uncertainty act assuming outcomes pre-determined. outcome pre-determined called random.Mathematics random phenomena called Probability Theory. people intuitive idea meant probability chance. Unfortunately Probability Theory subject endless examples seemingly simple questions turn complicated severely counter-intuitive answers.","code":""},{"path":"index.html","id":"frequentist-perspective","chapter":"1 Introduction to Probability","heading":"1.1 Frequentist perspective","text":"need start terminology.Definition 1.1  experiment procedure happens random least two different outcomes. example rolling die observing score statistical experiment. experiment repeatable repetition called run.calculating number times event occurs divided number runs one can estimate theoretical probability. idea relative cumulative frequency outcomes tend actual probability long run. perspective probability called Frequentist, incredibly useful practice.\nFigure 1.1: result simulating rolling die 6000 times, counting many times 6 occures. cumulative relative frequency tends theoretical 1/6 (red).\nrecreate plot like labs.Example 1.1  Suppose toss \\(10\\) coins \\(10\\) times results recorded table , draw graph relative frequency.cumulative relative frequencies calculated cumulative number flips divided cumulative number heads:course learn R programming. R free open-source software language suitable many probability statistical calculations. following R code make list two outcomes Heads Tails create sample \\(10\\) random outcomes.Definition 1.2  statistical experiment \\(n\\) runs, outcome \\(\\) happens cumulative number times depending \\(n\\) can call \\(a_n\\), frequentist probability outcome \\(\\), written \\(P()\\), limit:\\[P() = \\lim_{n\\\\infty} \\frac{a_n}{n}\\]possible repeatedly run experiment, frequentist methods useful finding approximation true theoretical probability.simple, consider following questions. probability life planets? probability Conservatives win next general election?events like flipping coin, possible find frequentist interpretation probability.","code":"\noutcomes <- c(\"Heads\",\"Tails\")\nsample(outcomes, 10, replace=TRUE)##  [1] \"Tails\" \"Heads\" \"Tails\" \"Tails\" \"Tails\" \"Heads\" \"Tails\" \"Heads\" \"Tails\"\n## [10] \"Tails\""},{"path":"index.html","id":"naive-probability","chapter":"1 Introduction to Probability","heading":"1.2 Naive probability","text":"may time resources many thousands runs. Therefore also need able evaluate theoretical probability directly exactly.Definition 1.3  sample space set whose elements outcomes experiment. sample space denoted greek letter \\(\\Omega\\).Example 1.2  pick person random street ask month birthday,\ncan let\n\\[\\Omega = \\{\\text{Jan}, \\ \\text{Feb}, \\ \\text{Mar},  \\ \\text{Apr}, \\ \\text{May}, \\ \\text{Jun}, \\ \\text{Jul}, \\ \\text{Aug}, \\ \\text{Sep}, \\ \\text{Oct}, \\ \\text{Nov}, \\ \\text{Dec} \\}.\\]Definition 1.4  event subset sample space \\(\\Omega\\).Example 1.3  example 1.2, let \\(\\text{L}\\) event month long month (.e. 31 days). \n\\[\\text{L} = \\{\\text{Jan}, \\ \\text{Mar}, \\ \\text{May},  \\ \\text{Jul}, \\ \\text{Aug},  \\ \\text{Oct}, \\ \\text{Dec} \\}.\\]Let \\(R\\) event letter r name month written fully. ,\\[\\text{R} = \\{\\text{Jan}, \\ \\text{Feb}, \\ \\text{Mar}, \\ \\text{Apr},  \\ \\text{Sep}, \\ \\text{Oct}, \\ \\text{Nov}, \\  \\text{Dec} \\}\\]Definition 1.5  Naively probability event \\(\\) number elements set \\(\\) divided size sample space \\(\\Omega\\).,\\(\\text{P} () = \\frac{||}{|\\Omega|}\\).example 1.3 :\\[\\text{P}(R) = \\frac{|R|}{|\\Omega|} = \\frac{8}{12} = \\frac{2}{3},\\],\\[\\text{P}(L) = \\frac{|L|}{|\\Omega|} =\\frac{7}{12}.\\]Example 1.4  (Coin Tossing) Toss fair coin twice record possible outcomes. Let\n\\[= \\{\\text{exactly one coin Heads}\\}\\]\n\n\\[B = \\{\\text{neither coin Heads}\\}\\]sample space \\(\\Omega = \\{HH, HT, TH, TT\\}\\).Events \\(\\) \\(B\\) correspond :\\[= \\{HT, TH\\}\\]\n\n\\[B = \\{ TT \\}\\]\nHence \\(\\text{P}() = \\frac{2}{4} = \\frac{1}{2}\\), \\(\\text{P}(B)=\\frac{1}{4}\\).Example 1.5  (Two dice) Two dice thrown, probability total number dots :equal \\(7\\)equal \\(3\\)greater \\(5\\)even numbersolutionThe sample space \\(\\Omega = \\{ (n_1,n_2) : n_1 , n_2 \\\\{1,2,3,4,5,6 \\} \\}\\). However, sums equally likely, best seen table.\\(\\frac{6}{36}\\)\\(\\frac{2}{36}\\)\\(\\frac{26}{36}\\)\\(\\frac{18}{36}\\)infinite sets problem naive definition 1.5. Consider following:Example 1.6  Suppose random unit vector rotated origin anticlockwise, making angle \\(\\theta\\) positive \\(x\\)-axis. probability angle acute?continuum infinitely many angles. naive definition says \\(\\frac{\\infty}{\\infty}\\), absurd.Intuitively, answer \\(\\frac{1}{4}\\).","code":""},{"path":"index.html","id":"complements-and-mutual-exclusivity","chapter":"1 Introduction to Probability","heading":"1.3 Complements and mutual exclusivity","text":"case, events subsets sample space \\(\\Omega\\) follow rules set theory, important know set notation, definitions results. recap important definitions.Definition 1.6  union \\(\\) \\(B\\) written:\\[\\cup B = \\{ x \\\\Omega :  x \\\\ \\text{} \\ x\\B \\}.\\]\nMathematics inclusive, means need say ``’’ included union.Definition 1.7  intersection \\(\\) \\(B\\) written:\n\\[\\cap B = \\{ x \\\\Omega:  x \\\\ \\text{} \\ x\\B \\}.\\]Definition 1.8  empty set \\(\\varnothing\\) set elements. sets \\(\\) \\(B\\) called disjoint elements common, ,\\(\\cap B = \\varnothing.\\)Probability Theory disjoint events called mutually exclusive.Definition 1.9  complement event \\(\\) event \\(^{c} = \\{x \\\\Omega : x\\notin \\}.\\)\nNote \\(\\cap ^{c} = \\varnothing\\). words means: event mutually exclusive complement.Example 1.7  Suppose event throwing die. event one throws even number. complement one throws odd number.Example 1.8  Suppose event random student siblings. complement one sibling. complement least one sibling.theorem prove De Morgan’s lawsTheorem 1.1  (DE MORGAN'S LAWS) complement union intersection complements:\n\\[(\\cup B)^{c} = ^{c} \\cap B^{c}\\]complement intersection union complements:\n\\[(\\cap B)^{c} = ^{c} \\cup B^{c}\\]way \\(P\\) `measure’ function maps subsets sample space interval \\(\\left[0,1\\right]\\).Definition 1.10  Probability function whose input subset sample space \\(\\subseteq \\Omega\\) whose range interval \\(\\left[0,1\\right]\\), following two axioms hold:probability whole set possible events unity. notation: \\(\\text{P}(\\Omega ) =1\\).probability whole set possible events unity. notation: \\(\\text{P}(\\Omega ) =1\\).(additivity) collection disjoint events \\(A_1 , A_2, A_3, \\dots\\) probability union sum probabilities. notation can written \\[\\text{P}(A_1 \\cup A_2 \\cup \\dots ) = \\text{P}(A_1) + \\text{P}(A_2)+\\dots .\\](additivity) collection disjoint events \\(A_1 , A_2, A_3, \\dots\\) probability union sum probabilities. notation can written \\[\\text{P}(A_1 \\cup A_2 \\cup \\dots ) = \\text{P}(A_1) + \\text{P}(A_2)+\\dots .\\]definition 1.10 due Russian Mathematician Kolmogorov. axioms help make sense infinite case.Using definition can prove following important results.Proposition 1.1  (PROBABILITY COMPLEMENT) event \\(\\) :\n\\[\\text{P}(^{c}) = 1 - \\text{P}().\\]Proof. Write \\(\\Omega = \\cup ^{c}\\), disjoint union. additivity,\n\\[\\text{P}(\\Omega) = \\text{P}() + \\text{P}(^{c}) \\]\nNow axiom () LHS \\(1\\).Theorem 1.2  (PROBABILITY UNION) Given two events \\(\\) \\(B\\) :\\[\\text{P}(\\cup B) = \\text{P}() + \\text{P}(B) - \\text{P}(\\cap B)\\]Proof. idea write \\(\\) disjoint union part intersection \\(B\\), : \\(=(\\cap B)\\cup(\\cap B^{c})\\). Hence,\\[\\text{P}() = \\text{P}(\\cap B) + \\text{P}(\\cap B^{c})\\]split \\(\\cup B\\) way, obtain \\((\\cup B)\\cap B\\) \\((\\cup B)\\cap B^{c}\\). former simply \\(B\\), latter \\(\\cap B^{c}\\). additivity,\\[\\text{P}(\\cup B) = P(B) + P(\\cap B^{c}).\\]\nEliminating \\(P(\\cap B^{c})\\) two equations proves rule.proving Theorems course, neither ask recount proof exam. however know use results applied problems.Example 1.9  (Multiple Choice) Suppose multiple choice test consists three questions two options, correct answer (C) wrong answer (W). probability student always randomly guesses answers gets least one correct?\\[\\begin{align}\n\\text{P(least one correct)} &= 1 - \\text{P(wrong)} \\\\\n&= 1- \\frac{1}{8}  \\\\\n&=\\frac{7}{8}\n\\end{align}\\]Example 1.10  (Mode travel) table shows type journey undertaken sample commuters classified live.individual selected random group, find probability , travel car live townsolution\\(\\text{P}(\\text{Car}\\cup \\text{Town}) = \\frac{25+40+30}{100}=0.95\\)\\(\\text{P}(\\text{Car})+ \\text{P}(\\text{Town})-\\text{P}(\\text{Car}\\cap \\text{Town})= \\frac{65}{100}+\\frac{70}{100}-\\frac{40}{100} =0.95\\)Example 1.11  particular city \\(60\\%\\) people watch news morning, \\(50\\%\\) people watch news evening \\(30\\%\\) watch . probability individual selected random watches either morning news evening news.solution\\(\\text{P}(M\\cup E) = 0.6 + 0.5 - 0.3 = 0.8\\)","code":""},{"path":"index.html","id":"outcomes-and-counting","chapter":"1 Introduction to Probability","heading":"1.4 Outcomes and counting","text":"One might imagine finite situation simple, even seen full picture. One simply counts many ways event can happen total number configurations. can actually quite complicated. learn formulae enable us count .","code":""},{"path":"index.html","id":"factorials","chapter":"1 Introduction to Probability","heading":"1.4.1 Factorials","text":"Example 1.12  (Three people line) many ways can three people \\(\\), \\(B\\) \\(C\\) stand line?solution\\(ABC, ACB, BAC, BCA, CAB,CBA\\) \\(6\\).Definition 1.11  non-negative integer, \\(n\\) say, define factorial \\(n\\), written \\(n!\\) equal product \\(n\\) numbers less \\(n\\) \\(1\\). ,\\[n! = n \\times (n-1) \\times (n-2) \\times \\dots 3 \\times 2 \\times 1\\]Definition 1.12  (Multiplication Rule) \\(n\\) ways operation happen, \\(m\\) ways something else happen, total number ways sequence occur \\(n \\times m\\).Example 1.13  MMU assigns student \\(8\\) digit ID number. many possible ID numbers ?solution\nfirst digit zero, \\(9\\) digits choose.\ndigits \\(10\\) choices \\(0,1,2,3,4,5,6,7,8,9\\).Total = \\(9 \\times 10^7\\).Example 1.14  (objects line) number ways arranging \\(n\\) distinct objects line \\(n!\\).\n\\(n\\) choices first number line, one fewer choice \\((n-1)\\) second, , last one line one choice remaining.Definition 1.13  (rule division) number ways arranging \\(n\\) objects line \\(p\\) \\(\\frac{n!}{p!}\\).Example 1.15  Suppose letters \\(,,,B\\) - many `words’ can made?Suppose letters \\(,,,B\\) - many `words’ can made?Suppose letters \\(,,,B,B\\) - many `words’ can made?Suppose letters \\(,,,B,B\\) - many `words’ can made?solution\n)\nAAAB, AABA, ABAA, BAAAThere 4. find number without write ?might think \\(4!\\) thinking different, overcounts word. factor overcount? Take one words ABAA number , one finds rearrangements 1,2,3:\\(A_1BA_2A_3, A_1BA_3A_2, A_2BA_1A_3, A_2BA_3A_1, A_3BA_1A_2, A_3BA_2A_1.\\)upshot need divide factorial number letters , \\(\\frac{4!}{3!} =4\\).\\(3\\) letter \\(\\), \\(2\\) letter \\(B\\). correct number \\[\\frac{5!}{3!\\times2!} = 10\\]words AAABB, AABBA, ABBAA, BBAAA, BABAA, ABABA, AABAB, BAABA, ABAAB, BAAAB. (can systematically list considering number ’s B’s).Definition 1.14  (rule sum) Given two disjoint events \\(\\) \\(B\\), size union sum sizes \\(\\) \\(B\\). ,\\[|\\cup B|=||+|B|\\]Example 1.16  many possible MMU IDs start \\(1\\) \\(3\\)?solutionThe IDs form 1******* 3*******. 1 choice first digit \\(10^7\\) choices next digits either case.total number starting \\(1\\times 10^7 + 1\\times 10^7 = 2\\times 10^7.\\)","code":""},{"path":"index.html","id":"permutations","chapter":"1 Introduction to Probability","heading":"1.4.2 Permutations","text":"Example 1.17  Consider number ways placing three letters \\(,B,C,D,E,F G\\) three empty spaces. first space can filled \\(7\\) ways, second \\(6\\) ways last \\(5\\) ways.total \\(7\\times 6\\times 5 = 120\\)number can written \n\\[\\frac{7\\times 6 \\times 5\\times 4\\times 3\\times 2\\times 1}{4\\times 3 \\times 2\\times 1}=\\frac{7!}{(7-3)!}\\]Definition 1.15  (Permutations) number ways choosing \\(k\\) distinct items \\(n\\) order relevant \n\\[^n\\text{P}_k = \\frac{n!}{(n-k)!}\\]\nway choosing \\(k\\) distinct items \\(n\\) order matters called permutation.Example 1.18  PIN \\(4\\) different digits. many different PINs ?solutionOrder matters - guess 1234 different 4321, example.\\[^{10}\\text{P}_4 = \\frac{10!}{(10-4)!} = \\frac{10\\times 9 \\times \\dots 2 \\times 1 }{6!} =10\\times 9 \\times 8 \\times 7 =5040\\]\nexpression \\(10\\times 9 \\times 8 \\times 7\\) can interpreted saying \\(10\\) choices first digit, \\(9\\) second, .Example 1.19  (Birthday Problem) Suppose \\(k\\) people room. probability least one birthday someone else room?solution\\[\\text{P}(\\text{least one birthday }) = 1 - \\text{P}(\\text{birthdays different})\\]first person born day \\(365\\) days, second person different birthday \\(364\\) \\(k^{th}\\) person.\\(\\text{P}(\\text{birthdays different}) = \\frac{^{365}\\text{P}_k}{365^k}\\)can evaluated computer different values \\(k\\).\\(k=23\\) one finds \\(\\text{P}(\\text{birthdays different}) = 0.493\\).implies \\(\\text{P}(\\text{least one birthday }) = 1- 0.493 > 0.5\\).greater evens chance two people birthday room \\(23\\) people.","code":""},{"path":"index.html","id":"combinations","chapter":"1 Introduction to Probability","heading":"1.4.3 Combinations","text":"Definition 1.16  (Combinations) number ways choosing \\(k\\) distinct items \\(n\\) order relevant :\\[{}^nC_k = \\frac{n!}{(n-k)!k!}\\]\nway choosing \\(k\\) distinct items \\(n\\) order matter called combination.Example 1.20  many ways can \\(4\\) cards dealt ordinary pack \\(52\\) playing cards?solutionSuppose one hand Ace spades, king clubs, three hearts Jack diamonds. matter card given first, hand matters play.`order matter’.number hands \\({}^{52}C_{4}=270725\\).Example 1.21  (National Lottery) main National Lottery draw, six numbers chosen \\(49\\).probability winning jackpot lottery (.e. \\(6\\) match)?probability winning jackpot lottery (.e. \\(6\\) match)?probability three winning numbers come lottery ticket?probability three winning numbers come lottery ticket?solutionsTotal number outcomes \\({}^{49}C_{6} = 13983816\\).probability \\(\\frac{1}{^{49}C_{6}}\\), \\(1\\) \\(14\\) million.three winning numbers can three six winning numbers \\(^6C_3\\) combinations. numbers ticket can three \\(43\\) losing numbers week. number ways choosing \\(^{43}C_3\\).Therefore probability three winning numbers \n\\[\\text{P}(\\text{three winning numbers}) = \\frac{^{43}C_3 \\times ^6C_3}{^{49}C_6} = 0.0177\\]\napproximately \\(1\\) \\(56\\).","code":""},{"path":"index.html","id":"exercises-week-1","chapter":"1 Introduction to Probability","heading":"1.5 Exercises Week 1","text":"","code":""},{"path":"index.html","id":"tutorial-exercises","chapter":"1 Introduction to Probability","heading":"1.5.1 Tutorial exercises","text":"Exercise 1.1  letter chosen random word STATISTICS.\n) probability vowel?\nb) complement event )?Exercise 1.2  Suppose eating restaurant two friends. agree pay bill follows. person tosses coin. person gets result different two pay bill. three tosses , bill shared equally. Find probability :pay billAll three share billDo think fair way split bill?Exercise 1.3  investment can either; increase value (), break even (B) make loss (L). Suppose outcome equally likely. two separate investments made,List sample space drawing tree diagram.List sample space drawing tree diagram.Find probability :Find probability :investments increase value.investments make loss.least one investments increases value.Suppose investments type company. might model unrealistic, improve ?big sample space three separate investments made?Exercise 1.4  set cards consists standard suits \\(\\clubsuit\\), \\(\\spadesuit\\), \\(\\diamondsuit\\), \\(\\heartsuit\\), \\(13\\) cards suit.\n) Suppose one card drawn random. Find probability :\n() Ace Hearts, \\(\\heartsuit\\)\n(ii) King Spades \\(K\\spadesuit\\).\n(iii) picture card.Suppose two cards drawn random, first replaced deck shuffled second drawn ( called sampling replacement). Find probability :cards King Hearts, \\(K\\heartsuit\\).cards Aces.Exercise 1.5  Fifty male fifty female students asked whether agreed statement “Statistics often misleading”. Seventy students, thirty male, agreed.\n) Summarise information two-way table.\nb) student selected random, find probability :\n() Agree\n(ii) female\n(iii) male\n(iv) male agree\n(v) female agreeExercise 1.6  Interviews \\(120\\) working people revealed \\(76\\) stressed, \\(20\\) managers \\(14\\) managers stressed.\n) Summarise information two-way table.\nb) Assuming individual drawn random, find probability thatthey \n() Stressed\n(ii) shopfloor worker\n(iii) manager stressed\n(iv) shopfloor worker stressed.Exercise 1.7  Evaluate ) \\(^5\\text{P}_3\\), b) \\(^7\\text{P}_4\\), c) \\(^6\\text{P}_4\\).Exercise 1.8  value \\(n\\) following equality true?\n\\[ ^{n+1}\\text{P}_3 = ^n\\text{P}_4 \\]Exercise 1.9  Three different Mathematics books \\(5\\) different statistics books arranged shelf. many ways can books arranged ,\n) books subject must stand together\nb) statistics books must stand togetherExercise 1.10  Four different Mathematics books, \\(5\\) different statistics books \\(3\\) different computing books arranged shelf. many ways can books arranged ,\n) books subject must stand together\nb) statistics books must stand togetherExercise 1.11  Evaluate ) \\(^7\\text{C}_6\\), b) \\(^5\\text{C}_3\\), c) \\(^9\\text{C}_5\\), \\(^9\\text{C}_4\\).Exercise 1.12  many different committees can formed \\(8\\) men \\(6\\) women committee consists :\n) \\(1\\) man \\(4\\) women\nb) \\(5\\) men \\(3\\) women\nc) \\(4\\) men \\(4\\) women\nd) equal number men women.Exercise 1.13  council consists \\(10\\) members, \\(6\\) Party X \\(4\\) Party \\(Y\\).\n) many ways can committee \\(4\\) formed?\nb) many ways can committee \\(4\\) formed :\n) Party X majority\nii) Party Y majority\niii) Neither party majorityExercise 1.14  Ten equally qualified assistant managersare lined promotion. Seven men three women. company promotes four ten random, probability exactly two four chosen women?Exercise 1.15  Suppose library bookshelf contains equal number, \\(n\\) say, Mathematics books Physics books. bookshelf emptied books placed back randomly, probability books subject separated?Exercise 1.16  miscellaneous questions permutations combinations:\n) group \\(20\\) employees, \\(4\\) chosen promotion. many ways can chosen?\nb) group \\(20\\) employees, \\(4\\) shosen promotion, different role. many ways can chosen?\nc) product code consists \\(4\\) letters followed \\(3\\) digits. many codes possible repetitions allowed?\nd) \\(7\\)-card hand dealt normal pack \\(52\\) cards. many hands contain \\(4\\) clubs \\(3\\) hearts?\ne) many ways can merit awards allocated group \\(15\\) students one first prize, one second prize \\(4\\) identical third prizes?\nf) Four students chosen group \\(10\\). exactly one first three students must chosen, many ways choosing four students?Exercise 1.17  game poker, five cards standard deck \\(52\\) cards dealt hand. Find probability hand contains,\n) royal flush (ace, king, queen, jack \\(10\\) suit)\nb) Four kind (e.g. four \\(5\\)s)\nc) Two pairs\nd) full house (.e. three one kind two another)\ne) One pairExercise 1.18  \\(\\text{P()}=0.6\\) \\(\\text{P(B)}=0.5\\), can B mutually exclusive?Exercise 1.19  medical records \\(100\\) male diabetic patients reported clinic family history diabetes (Yes ), together symptoms either mild severe. provided following classification.Suppose patient chosen random clinic events , B C defines follows:: severe diseaseB : \\(40\\)C : parents diabeticFind probabilities P(), P(B), P(\\(\\cap\\)B), P(B\\(\\cap\\)C), P(\\(\\cap\\)B\\(\\cap\\)C).Find probabilities P(), P(B), P(\\(\\cap\\)B), P(B\\(\\cap\\)C), P(\\(\\cap\\)B\\(\\cap\\)C).Describe following events words calculate : \\(^c\\cap\\)B\\(^c\\), \\(^c\\cup\\)C\\(^c\\), \\(^c\\cap\\)B\\(^c\\cap\\)C\\(^c\\).Describe following events words calculate : \\(^c\\cap\\)B\\(^c\\), \\(^c\\cup\\)C\\(^c\\), \\(^c\\cap\\)B\\(^c\\cap\\)C\\(^c\\).","code":""},{"path":"index.html","id":"exercises-for-feedback","chapter":"1 Introduction to Probability","heading":"1.5.2 Exercises for feedback","text":"remember phone number. contains following digits something like \\(132 \\ 747 \\ 6965\\).probability first number even?probability first number even?many ways can numbers rearranged?many ways can numbers rearranged?many ways can number rearranged start end odd number?many ways can number rearranged start end odd number?Suppose certain numbers blocks \\(132\\),\\(747\\) \\(6965\\), sure order within block.many ways can numbers rearranged numbers within block ?many ways can numbers rearranged numbers within block ?probability wrote correct number originally?probability wrote correct number originally?lottery, \\(6\\) numbers drawn numbers \\(1\\) \\(49\\). Calculate following probabilities.numbers \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\), \\(6\\) drawn.numbers \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\), \\(6\\) drawn.numbers \\(4\\), \\(23\\), \\(24\\), \\(35\\), \\(40\\), \\(45\\) drawn.numbers \\(4\\), \\(23\\), \\(24\\), \\(35\\), \\(40\\), \\(45\\) drawn.\\(44\\) one numbers drawn.\\(44\\) one numbers drawn.Three dice rolled. sum numbers dice score.Describe sample space.Describe sample space.many ways score equal \\(5\\)?many ways score equal \\(5\\)?likely score?likely score?Suppose finite set \\(S\\) size \\(n\\).\n(Hint: question general, check answers concrete example S = { ,b,c,d })many subsets \\(S\\)?many subsets \\(S\\)?many subsets S size \\(1\\)?many subsets S size \\(1\\)?many subsets S size \\(k\\), \\(1\\leq k\\leq n\\)many subsets S size \\(k\\), \\(1\\leq k\\leq n\\)Using ) c), describe words following equality holds.Using ) c), describe words following equality holds.\\[2^n = \\sum_{k=0}^n {^n}C_k\\]Five office workers write names piece paper, fold paper put hat. names mixed person selects piece paper hat. everyone selected piece paper hat, staff look names drawn. probability member staff selected name?","code":""},{"path":"cond.html","id":"cond","chapter":"2 Conditional Probability","heading":"2 Conditional Probability","text":"chapter learn conditional probability. probability event, context another event happened potentially happening.","code":""},{"path":"cond.html","id":"independence","chapter":"2 Conditional Probability","heading":"2.1 Independence","text":"Independence important concept Statistics, one sometimes misused assumed without justification. basic idea follows:Definition 2.1  (Independence) Two events \\(\\text{}\\) \\(\\text{B}\\) independent exactly \n\\[\\text{P}(\\text{}\\cap\\text{B}) = \\text{P}(\\text{})\\times \\text{P}(\\text{B}).\\]\nwords means probability \\(\\text{}\\) \\(\\text{B}\\) happen product individual probabilities \\(\\text{}\\) \\(\\text{B}\\) respectively.Example 2.1  events can modelled independent include:\n- Outcomes successive tosses coin die. happened previous throw affect happens subsequent throws.sex babies. sex baby determined random, notwithstanding sexes previous babies.Example 2.2  Suppose power plant two safety systems, primary system works probability \\(0.999\\), backup system works probability \\(0.89\\) Assuming two systems operate independently, reliability safety power plant.solutionWe can work \\(\\text{P}(\\text{plant safe})\\) using complement:\\[\\text{P}(\\text{plant safe}) = 1-\\text{P}(\\text{plant fails}).\\]Let \\(F\\) event plant fails, \\(F_1\\) event first system fails, \\(F_2\\) backup fails.\\(F = F_1 \\cap F_2\\).\\[\\begin{align}\n\\text{P}(F) &= \\text{P}(F_1 \\cap F_2) \\\\\n&= \\text{P}(F_1) \\times \\text{P}(F_2) \\\\\n&= (1-0.999)\\times (1-0.89) \\\\\n&= 0.00011\n\\end{align}\\]\\(1-0.00011 = 0.99989\\).Calculations often used arrive unrealistic figures safety complex operating processes, e.g. nuclear power plants. example, ’s easy check three backup systems reliability \\(0.99\\), probability failure assuming independence \\(1\\times 10^{-6}\\) - reassuringly small figure! However can make calculations can justify assumption independence. example ’s unusual find backup systems used often can unreliable supposed actually called upon.might give reason particular context good example assume independence. example exercise 1.3 part (c) asks two investments may independent. many reasonable answers. Similar companies dependent - companies bakeries, may affected price wheat. companies may competitors, case one company better may cause worse.Example 2.3  Suppose toss ten coins coin many Heads. throw simultaneously. throw one time, order. matter?solutionNo, independent coins. Let\n\\[A_i =\\{\\text{} \\ ^{\\text{th}} \\ \\text{coin Heads} \\}\\]probability simultaneously Heads product probabilities individual coin Heads.\nNotice order matter \n\\[\\text{P}(\\text{}_i)\\times \\text{P}(\\text{}_j) = \\text{P}(\\text{}_j)\\times \\text{P}(\\text{}_i).\\]Assuming independence allows us consider simultaneous events separately one another, complicated examples can analysed easily using tree diagrams. path tree diagram root leaf distinct outcome sample space.Example 2.4  Vehicles approaching crossroads must go one three directions - left, right straight . Observations traffic engineers showed vehicles approaching north, \\(45\\%\\) turn left, \\(20\\%\\) turn right \\(35\\%\\) go straight . Assuming driver vehicle chooses direction independently, probability next three vehicles approaching north:go straight onall go straight onall go directionall go directiontwo turn left one turns righttwo turn left one turns rightall go different directionsall go different directionsexactly two turn left.exactly two turn left.solution\nFigure 2.1: tree diagram representing choices three vehicles\n\\(0.35^3\\)\\(0.35^3\\)\\(0.45^3+0.2^3+0.35^3\\)\\(0.45^3+0.2^3+0.35^3\\)LLR can rearranged \\(3\\) ways: LLR, LRL, RLL. \\(3\\times 0.45^2 \\times 0.2\\).LLR can rearranged \\(3\\) ways: LLR, LRL, RLL. \\(3\\times 0.45^2 \\times 0.2\\).SRL can rearranged \\(3!\\) ways. \\(3!\\times 0.35 \\times 0.45 \\times 0.2\\).SRL can rearranged \\(3!\\) ways. \\(3!\\times 0.35 \\times 0.45 \\times 0.2\\).LLR LLS. can rearranged \\(3\\) ways, mutually exclusive outcomes can add probabilities. \\[3\\times 0.45^2 \\times 0.2 + 3\\times 0.45^2 \\times 0.35\\].LLR LLS. can rearranged \\(3\\) ways, mutually exclusive outcomes can add probabilities. \\[3\\times 0.45^2 \\times 0.2 + 3\\times 0.45^2 \\times 0.35\\].","code":""},{"path":"cond.html","id":"conditional-probability","chapter":"2 Conditional Probability","heading":"2.2 Conditional Probability","text":"consider following examples motivate definition conditional probability.Example 2.5  number insurance claims previous \\(12\\) months cross tabulated whether driver involved young driver.insurance company interested claim rate. Overall claim rate ,\\[\\text{P}(\\text{Claim})=\\frac{50}{1000} = 0.05\\]estimate probability driver claiming insurance \\(1\\) \\(20\\).However figure hides substantial difference claim rates young older drivers.consider \\(250\\) young drivers separately ,\\[\\text{P}(\\text{Claim}|\\text{}\\ 25)=\\frac{25}{250} = 0.1.\\]\nWhereas \\(750\\) older drivers ,\\[\\text{P}(\\text{Claim}| 25 \\ \\text{})=\\frac{25}{750} = 0.03.\\]notation \\(|\\) read ‘given ’ conditional statement. conditional probabilities show claim rate much higher younger drivers. One can compute ratio probabilities see many times higher , \\(0.1/0.03 \\approx 3.3\\), just three times higher. relative risk scoring common medical statistics.Example 2.6  Consider following data study male lung cancer patients carried \\(1950\\) UK. one earliest applications epidemiology - use statistics study disease patterns populations.Calculate relative risk lung cancer smoker compared non-smoker.solution\\[\\text{P}(\\text{Lung cancer}|\\text{Smoker}) = \\frac{647}{1267}\\]\\[\\text{P}(\\text{Lung cancer}|\\text{Non-smoker}) = \\frac{2}{29}\\]\\(\\approx 7.4\\) times higher relative risk lung cancer smokers.examples motivate definition conditional probability.Definition 2.2  (conditional probability) conditional probability \\(\\text{P}(|B)\\) event \\(\\) given another event non-zero probability \\(B\\) given ,\\[\\text{P}(|B) = \\frac{\\text{P}(\\cap B)}{\\text{P}(B)}.\\]One verify fraction left precisely conditional probability calculated previous two examples.Theorem 2.1  conditional probability \\(\\text{P}(|B)\\) satisfies Kolmogorov’s definition probability.Proof. lectured examined, completeness.Firstly need check \\(P(|B)\\[0,1]\\). \\(P(|B) \\geq 0\\) \\(P(\\cap B)\\geq0\\) \\(P(B)>0\\).intersection \\(B\\) another set contained \\(B\\), \\(\\cap B \\subseteq B\\), \n\\[P(\\cap B) \\leq P(B).\\]\ndividing \\(P(B)\\) gives \\(P(|B) \\leq 1\\).Secondly, \\[P(\\Omega|B) = \\frac{P(\\Omega \\cap B)}{P(B)} = \\frac{P(B)}{P(B)}=1.\\]Lastly, given two disjoint \\(A_1\\),\\(A_2\\) \\(A_1\\cap A_2 = \\varnothing\\).\\[\\begin{align}\nP(A_1\\cup A_2 |B) &= \\frac{P((A_1\\cup A_2)\\cap B)}{P(B)} \\\\\n&= \\frac{P((A_1\\cap B)\\cup (A_2\\cap B))}{P(B)} \\\\\n&= \\frac{P(A_1\\cap B)}{P(B)} + \\frac{P(A_2\\cap B)}{P(B)} \\\\\n&= P(A_1|B) + P(A_2|B)\n\\end{align}\\]Example 2.7  Note \\(P(|B) \\neq P(B|)\\). Revisiting driver’s example gives,\\[\\text{P}(\\text{Claim}|\\text{}\\ 25)=0.1.\\]\nHowever,\n\\[\\text{P}(\\text{}\\ 25|\\text{Claim})=\\frac{25}{50} = 0.5\\]Theorem 2.2  Two events \\(\\) \\(B\\) independent \n\\[\\text{P}(|B) = \\text{P}() \\ \\text{ } \\ \\text{P}(B|) = \\text{P}(B)\\]\nwords, conditioning either event affect probability event occurring.Proof. Using definition conditional probability,\n\\[\\text{P}(\\cap B) = \\text{P}(|B)\\text{P}(B)=\\text{P}(B|)\\text{P}()\\]\n\n\\[\\text{P}(|B) = \\text{P}() \\ \\text{ } \\ \\text{P}(B|) = \\text{P}(B),\\]\nsubstituting former yields\n\\[\\text{P}(\\cap B) = \\text{P}()\\text{P}(B), \\]\ndefinition independence.\nConversely two events independent, \n\\[\\text{P}(|B) = \\frac{\\text{P}(\\cap B)}{\\text{P}(B)} = \\frac{\\text{P}()\\text{P}(B)}{\\text{P}(B)} = \\text{P}(), \\]\nlikewise \\(\\text{P}(B|)\\).constructing tree diagrams probabilities involved usually conditional probabilities natural progression tree left right conditioning happened previously. diagram , events \\(\\) \\(B\\) may independent.\nFigure 2.2: second level branches represent conditional probabilities B given complement, may different numbers\nExample 2.8  Jon always goes campus bike takes tram. one day goes campus bike, probability goes campus tram next day \\(0.4\\). one day goes campus tram, probability goes campus bike next day \\(0.7\\).\nGiven Jon goes campus Monday tram, find probability takes tram campus Wednesday.solutionThis may solved considering tree diagram levels Tuesday Wednesday. probabilities question \\(\\text{P}(\\text{tram} \\ |\\ \\text{bike})=0.4\\) \\(\\text{P}(\\text{bike} \\ |\\ \\text{tram})=0.7\\).\nMonday’s journey done. Possible sequences ‘tram tram’, ‘bike tram’. mutually exclusive outcomes. calculation \\[0.3^2+0.7\\times 0.4 = 0.37\\].Surveys questions sensitive delicate nature often result respondents missing question lying answers. Conditional probability can used mask awkward question find proportion answer certain way.Example 2.9  company want find proportion employees ever called sick work, fact sick. boss asks employee toss coin hide result.result heads, employee answer question ‘age odd number?’.result tails, answer ‘ever taken day ?’.boss know question people answering, employees can answer truthfully.Suppose \\(40\\%\\) employees mark ‘yes’ answer. Let,\\[p= \\text{P}(\\text{taken day } \\ | \\ \\text{tails})\\]\nAssume ages randomly distributed chance even odd number years old \\(0.5\\). can find \\(p\\)?solutionOne can draw tree diagram.\nFigure 2.3: outcomes survey.\noverall probability answering ‘yes’ \\(0.25+0.5p\\), survey \\(40\\%\\) answered ‘yes’. \\[0.25+0.5p = 0.4, \\]\nhence \\(p=0.3\\). means can estimate \\(30\\%\\) employees taken day supposed .","code":""},{"path":"cond.html","id":"bayes-theorem","chapter":"2 Conditional Probability","heading":"2.3 Bayes Theorem","text":"Example 2.10  two coins bag. One coin fair, heads sides (double-header).coin selected bag random, selected coin flipped three times. Unfortunately coin selected unknown us.three flips coin comes heads.Without calculations, likely think unfair coin?solutionLet\n\\(=\\left\\{ \\text{double-header selected} \\right\\}\\) \n\\(B =\\left\\{ \\text{coin lands heads three times row} \\right\\}\\)\nFigure 2.4: tree diagram double headed coin example.\nOne can use tree diagram find \\(8/9\\).can generalise picture come formula conditional probability called Bayes’ formula.\nFigure 2.5: Tree showing Bayes’ formula\n\\[P(|B) = \\frac{P(\\cap B)}{P(B)} = \\frac{P()P(B|)}{P()P(B|)+P(^{\\mathsf{c}})P(B|^{\\mathsf{c}})}\\]Previously, \\(A_1=\\) \\(A_2 = ^{\\mathsf{c}}\\) disjoint union gives entire sample space. situation called partition.can extended partition \\(n\\) events \\(A_1,A_2, \\dots , A_n\\).Definition 2.3  collection events \\(A_1, A_2, \\dots , A_n\\) partition union entire sample space, exhaustive, mutually exclusive. \\(\\Omega = A_1 \\cup A_2 \\cup \\dots \\cup A_n\\).\\(\\Omega = A_1 \\cup A_2 \\cup \\dots \\cup A_n\\).\\(A_1 \\cap A_2 \\cap \\dots \\cap A_n = \\varnothing\\)\\(A_1 \\cap A_2 \\cap \\dots \\cap A_n = \\varnothing\\)event complement form partition.picture partition:\nFigure 2.6: example partition six sets.\ncan now extend concept conditional probability general situation condition event least one event partition.Theorem 2.3  (Law Total Probability) Suppose partition \\(A_1, A_2, \\dots , A_n\\) sample space \\(\\Omega\\). event \\(B \\subseteq \\Omega\\), \\[\\text{P}(B) =P(A_1)P(B|A_1)+ \\dots + P(A_n)P(B|A_n) \\]intuitive proof imagine tree diagram \\(n\\) branches \\(A_i\\) first layer, \\(B\\) \\(B^{\\mathsf{c}}\\) next layer. multiply along branches ways \\(B\\) can occur end sum RHS.Theorem 2.4  (Bayes' Theorem) Suppose partition \\(A_1, A_2, \\dots , A_n\\) sample space \\(\\Omega\\). conditional probability one event partition \\(A_k\\) \\(k\\), given event \\(B\\) can written ,\\[\\text{P}(A_k |B) = \\frac{\\text{P}(B|A_k)\\text{P}(A_k)}{\\sum^{n}_{=1}\\text{P}(B|A_i)P(A_i)}\\]Proof. Note \\(\\text{P}(A_k\\cap B) = \\text{P}(B|A_k)\\text{P}(A_k)\\),denominator $(B) using law total probability.Example 2.11  company produces electrical components using three shifts. first shift \\(50%\\) components produced, \\(20\\%\\) \\(30\\%\\) produced shifts \\(2\\) \\(3\\) respectively. proportion defective components produced shift \\(1\\) \\(6\\%\\). shifts \\(2\\) \\(3\\) proportions \\(8\\%\\) \\(12\\%\\) respectively.Find percentage defective components.Find percentage defective components.component defective, probability came shift \\(3\\)?component defective, probability came shift \\(3\\)?solutionLet \\(D\\) event component defective \\(S_1,S_2,S_3\\) denotethat produced shifts \\(1,2\\) \\(3\\) respectively.Use theorem total probability, follows:\n\\[\\begin{align}\n\\text{P}(D)  &= \\text{P}(D|S_1)P(S_1)+\\text{P}(D|S_2)\\text{P}(S_2)+\\text{P}(D|S_3)\\text{P}(S_3) \\\\\n&= 0.06\\times 0.5 + 0.08\\times 0.2 + 0.12\\times 0.3 \\\\\n&= 0.082\n\\end{align}\\]Use theorem total probability, follows:\n\\[\\begin{align}\n\\text{P}(D)  &= \\text{P}(D|S_1)P(S_1)+\\text{P}(D|S_2)\\text{P}(S_2)+\\text{P}(D|S_3)\\text{P}(S_3) \\\\\n&= 0.06\\times 0.5 + 0.08\\times 0.2 + 0.12\\times 0.3 \\\\\n&= 0.082\n\\end{align}\\]Using Bayes’ theorem,Using Bayes’ theorem,\\[\\text{P}(S_3|D) = \\frac{\\text{P}(D|S_3)\\text{P}(S_3)}{\\text{P}(D)}\\]\ndenominator worked part ), gives \\(\\frac{0.12\\times 0.3}{0.082}=0.439\\).Bayes’ theorem allows us update probability event light new evidence. fact main practical use theorem, leads whole branch Bayesian Statistics.Example 2.12  Gary suspected committing crime. evidence far points probability guilt \\(0.9\\). ‘prove innocence’ Gary undergoes lie detector test, \\(70\\%\\) accuracy rate. test say positive indicate guilt, negative indicate guilty. test \n\\[\\text{P}(\\text{Positive}|\\text{Guilty}) = 0.7\\]\n\\[\\text{P}(\\text{Negative}|\\text{Innocent})=0.7\\]Gary’s test comes back negative, probability guilt?solutionOne can directly apply Bayes’ theorem.\n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{\\text{P}(\\text{Negative}|\\text{Guilt})\\text{P}(\\text{Guilt})}{\\text{P}(\\text{Negative}|\\text{Guilt})\\text{P}(\\text{Guilt})+\\text{P}(\\text{Negative}|\\text{Innocent})\\text{P}(\\text{Innocent})}\\]\n\n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 0.9}{0.3\\times 0.9 \\ + \\ 0.7\\times 0.1}=0.794 \\ \\text{(3 d.p.)}\\]Beware extreme prior beliefs, evidence can change mind. Believing something true \\(100\\%\\) \\(0\\%\\), mean reason evidence change position.Example 2.13  (Cromwell's Rule) believe Gary \\(100\\%\\) guilty start \n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 1}{0.3\\times 1 \\ + \\ 0.7\\times 0}=1\\]\nstill believe Gary \\(100\\%\\) guilty.believe Gary \\(0\\%\\) guilty start \n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 0}{0.3\\times 0 \\ + \\ 0.7\\times 1}=0\\]\nstill believe Gary \\(0\\%\\) guilty.educated people always consider opposing opinion update beliefs according evidence available. strong opinion something, consider change mind. Always leave room doubt , wrong.","code":""},{"path":"cond.html","id":"exercises-week-2","chapter":"2 Conditional Probability","heading":"2.4 Exercises Week 2","text":"Exercise 2.1  toss fair coin roll die.\n) events independent?probability obtain head \\(6\\)?Exercise 2.2  torch uses two batteries series. battery works probability \\(0.95\\), independently . Work probability :torch work.torch work.batteries failBoth batteries failOnly one batteries work.one batteries work.Exercise 2.3  Whether student gets time depends whether remembered set alarm night . \\(90\\%\\) time remembers, \\(10\\%\\) forgets. clock set, get time \\(95\\%\\) occasions. set, chance oversleep \\(35\\%\\). Use tree diagram find probability oversleep.Exercise 2.4  following data shows distribution male female students various degree courses university.Suppose student selected random. Find probability ,femalefemalestudying Economicsstudying Economicsmale studying Economicsmale studying Economicsmale given studying Economicsmale given studying Economicsfemale given studying Economicsfemale given studying Economicsstudying Economics given femalestudying Economics given femaleAre events ‘student male’ ‘studying Economics’ independent?Exercise 2.5  following table shows lung cancer data females \\(1950\\) study given example 2.6.Calculate relative risk female smokers compared non-smokers.Calculate relative risk female smokers compared non-smokers.Can suggest reason difference figures males females?Can suggest reason difference figures males females?Exercise 2.6  Two electrical components \\(X\\) \\(Y\\) probabilities working \\(\\frac{3}{4}\\) \\(\\frac{7}{8}\\), respectively. also function independently . Two devices \\(D_1\\) \\(D_2\\) constructed. \\(D_1\\), \\(X\\) \\(Y\\) series, \\(D_2\\) wired parallel.Find probability \\(D_1\\) works.\nFind probability \\(D_1\\) works.Find probability \\(D_2\\) works.Suppose \\(D_1\\) works, find probability ;\\(X\\) working.\\(X\\) working.\\(X\\) \\(Y\\) working.Suppose \\(D_2\\) works, find probability ;\\(X\\) working.\\(X\\) working.\\(X\\) \\(Y\\) working.Exercise 2.7  urn contains two green balls three red bals. Supose two balls drawn random one another without replacement. Draw tree diagram, find probability :green ball appears first draw.green ball appears first draw.green ball appears second draw.green ball appears second draw.Exercise 2.8  following table shows fear factor children attending dentist, cross tabulated School age child.child selected random define events; \\(= \\{ \\text{child afraid} \\}\\),\\(N\\) afraid, \\(\\),\\(P\\) \\(S\\) School age obvious fashion.Calculate following probabilities,\\(\\text{P}()\\), \\(\\text{P}(N)\\), \\(\\text{P}(\\cup )\\).\\(\\text{P}()\\), \\(\\text{P}(N)\\), \\(\\text{P}(\\cup )\\).\\(\\text{P}(| )\\) \\(\\text{P}(| )\\).\\(\\text{P}(| )\\) \\(\\text{P}(| )\\).\\(\\text{P}(| S)\\) \\(\\text{P}(N| S)\\) - notice two probabilities?\\(\\text{P}(| S)\\) \\(\\text{P}(N| S)\\) - notice two probabilities?\\(\\) \\(\\) independent?Exercise 2.9  survey electrical retailer determines \\(40\\%\\) customers seek advice sales staff appliance \\(20\\%\\) seek advice buy appliance. \\(30\\%\\) customers seek advice, probability customer entering warehouse buys appliance?Exercise 2.10  Four cards drawn random without replacement deck \\(52\\) cards. probability sequence :\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\clubsuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\clubsuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\spadesuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\spadesuit\\)Exercise 2.11  student comes back night pub bunch keys, one works. try one key random lock discard doesn’t fit.Suppose bunch contains \\(2\\) keys. Find probability open door onthe first attemptthe first attemptthe second attemptthe second attemptRepeat bunch three keys successul first, second third attempts.Repeat bunch three keys successul first, second third attempts.Suppose now bunch contains \\(n\\) keys. Find probability door opened \\(r^{\\text{th}}\\) attempt (\\(1\\leq r \\leq n\\)).Suppose now bunch contains \\(n\\) keys. Find probability door opened \\(r^{\\text{th}}\\) attempt (\\(1\\leq r \\leq n\\)).Exercise 2.12  ascertain proportion people sexually transmitted infection, following survey pocedure used \\(1000\\) individuals.asked think day week recent birthday fell .last birthday Monday, Tuesday Wednesday answer question ‘every sexually transmitted infection?’.last birthday day week, answer question ‘age even number?’.survey \\(290\\) people answered ‘yes’. Assuming ages birthdays uniformly distributed, can estimate proportion people sexually transmitted infection?Exercise 2.13  Suppose two events \\(\\) \\(B\\) independent. Show \\(\\) \\(B^{\\mathsf{c}}\\) also independent. Show also \\(^{\\mathsf{c}}\\) \\(B^{\\mathsf{c}}\\) independent.Exercise 2.14  Forty percent new employees hired large company degree. Seventy percent employees degrees promoted within two years.without degrees, \\(30\\%\\) arepromoted within two years.probability new empoyee promoted?probability new empoyee promoted?employee promoted, probability degree?employee promoted, probability degree?Exercise 2.15  bag contains \\(3\\) coins; two normal unbiased coins third double headed. coin chosen random bag tossed. coin tossed \\(4\\) times came heads time. probability double header?Exercise 2.16  Approximately \\(25\\%\\) males \\(50\\) form heart problem. clinic observed males heart problem three times likely smokers males heart problem. probability male \\(50\\) heart problem given smoker?Exercise 2.17  Cage contains five hens disease six hens without disease. Cage B contains two diseased hens five hens without disease. Two hens chosen random cage transferred cage B. hen now chosen random cage B found diseased. Find probability two hens transferred ,diseasedboth diseasedboth without disease.without disease.","code":""},{"path":"drv.html","id":"drv","chapter":"3 Discrete Random Variables","heading":"3 Discrete Random Variables","text":"practical situations encounter uncertainty, random outcome interest numerical quantity. number minutes end waiting bus, much win lottery week, even number times try catch fly chopsticks eventually manage .","code":""},{"path":"drv.html","id":"random-variables","chapter":"3 Discrete Random Variables","heading":"3.1 Random Variables","text":"chapter learn concept discrete random variable.Example 3.1  Suppose roll two dice find sum numbers two dice. Let \\(X\\) sum numbers two dice. know sample space :\n\\[\\Omega = \\{ (n_1,n_2) : n_1,n_2 \\\\mathbb{N}, \\ 1 \\leq n_1 , n_2 \\leq 6 \\},\\]\nGiven outcome \\((n_1,n_2)\\), ‘variable’ \\(X\\) takes particular whole numbered value \\(x=2, \\dots , 12\\). seen particular values equally likely.Definition 3.1  random variable \\(X\\) set function maps potential outcomes statistical experiment (subset ) real number line.random variable written capital letter (\\(X\\)), particular values takes written lowercase letter (\\(x\\)). probability \\(X\\) takes particular value written \\(\\text{P}(X=x)\\).Just data analysis difference discrete continuous random variables. One can think discrete random variables arising process involves counting can take integer values. continuous random variables can thought arising measuring process.Example 3.2  Let $R = $ result spinning roulette wheel. roulette wheel can take particular values\n\\[\\Omega = \\{0,1,2, \\dots,36\\}.\\]\nnumber ranges 1 10 19 28, odd numbers red even black. ranges 11 18 29 36, odd numbers black even red. green pocket numbered 0 (zero). \\(R\\) discrete random variable, takes particular discrete values.Let \\(T =\\) time spent waiting bus. \\(T\\) positive number arrive bus stop (time timetabled arrival time, negative early bus). \\(T\\) continuous random variable.consider discrete random variables first, study types course.","code":""},{"path":"drv.html","id":"discrete-probability-distributions","chapter":"3 Discrete Random Variables","heading":"3.2 Discrete probability distributions","text":"order understand random variable likely behave, thus able predict possible future values, clearly need consider probability take particular values. set probability values known probability distribution. develop theory examples.Definition 3.2  distribution function, also known probability mass function, random variable \\(X\\) function outputs probability \\(X\\) attaining particular value. ,\\[f(x) = \\text{P}(X=x)\\]\ntexts, two variables play, may also write variable subscript \\(f_X(x)\\) clear mass function referring.Example 3.3  (discrete uniform distribution) Consider rolling fair die let discrete random variable \\(X\\) score observed die. know probability getting particular values set \\(\\{1,2, \\dots 6\\}\\) \\(\\frac{1}{6}\\) probability distribution. may tabulate values followsAlternatively may use formula:\n\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{6}, & \\text{} x = 1, 2, \\dots , 6.\\\\\n    0 & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]graph:\nFigure 3.1: Probability mass function fair die\nClearly graph useful way visualise probability distributed. can also see called discrete uniform distribution - ’s values .questions consider:Suppose die \\(n\\) sides, \\(n\\) whole number greater \\(1\\), faces numbered \\(1,2,\\dots n\\). distribution look like now?Suppose die \\(n\\) sides, \\(n\\) whole number greater \\(1\\), faces numbered \\(1,2,\\dots n\\). distribution look like now?Can represent distribution three ways ?Can represent distribution three ways ?Example 3.4  (Urn problem) urn contains five balls numbered \\(1\\) \\(5\\). Two balls drawn simultaneously.Let \\(X\\) larger two numbers.Let \\(X\\) larger two numbers.Let \\(Y\\) sum two numbers.Let \\(Y\\) sum two numbers.Find probability distributions \\(X\\) \\(Y\\).solutionWe proceed follows enumerating possibilities noting \\(^5C_2=10\\) ways drawing balls urn. Note balls drawn simultaneously, order matter .find distribution \\(X\\) one can list outcomes systematically largest value.find distribution \\(Y\\) one can list outcomes systematically sum.either case check individual probability \\(0\\) \\(1\\) possible particular values sum \\(1\\).Example 3.5  (geometric distribution) archer hits target rather randomly. Let’s suppose time takes aim \\(\\text{P}(\\text{Hit})=\\frac{1}{4}\\), complement \\(\\text{P}(\\text{Miss})=\\frac{3}{4}\\). Let \\(Y\\) number attempts required hits target. Find distribution \\(Y\\).solutionWe can consider number attempts separately.\\(Y=1\\), first attempt hit, \\(\\text{P}(Y=1)=\\frac{1}{4}.\\)\\(Y=2\\), first attempt miss, second hit, \n\\[\\text{P}(Y=2)=\\frac{3}{4}\\times \\frac{1}{4} = \\frac{3}{16}.\\]\\(Y=3\\), first attempt miss, second miss, third hit \n\\[\\text{P}(Y=3)=\\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{1}{4} = \\frac{9}{64}.\\]\n\\(Y=4\\), sequence miss, miss, miss hit:\n\\[\\text{P}(Y=3)=\\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{1}{4} = \\frac{27}{256}.\\]\n.Notice archer hit target \\(y^{\\text{th}}\\) attempt, must missed previous \\(y-1\\) attempts, formula mass function follows.\\[\\begin{equation*}\n  f(Y=y)=\\begin{cases}\n    \\left( \\frac{3}{4} \\right)^{y-1}\\frac{1}{4} \\ , & \\text{} y = 1, 2, 3, \\dots \\\\\n    \\ 0 \\ & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Clearly probabilities quickly getting small - may recognise terms geometric sequence common ration \\(\\frac{3}{4}\\).graph distribution looks like:\nFigure 3.2: geometric distribution\nchoice \\(\\frac{1}{4}\\) infact arbitrary. general can ‘success’ probability \\(\\pi\\) ‘failure’ probability \\(1-\\pi\\).Definition 3.3  random variable \\(X\\) representing number independent trials first success follows geometric distribution success probability \\(\\pi\\), written \\(X \\sim \\text{Geom}(\\pi)\\), defined probability mass function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\left( 1-\\pi \\right)^{x-1}\\pi , & x = 1, 2, 3, \\dots \\\\\n    \\ 0 \\ & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]course trials archer arguably independent - ?","code":""},{"path":"drv.html","id":"properties-of-probability-mass-functions","chapter":"3 Discrete Random Variables","heading":"3.3 Properties of probability mass functions","text":"random variable \\(X\\) probability distribution \\(f(x)\\) following two properties:probability particular value \\(0\\) \\(1\\). ,\n\\[ 0 \\leq f(x) \\leq 1, \\ \\forall x\\]probability particular value \\(0\\) \\(1\\). ,\n\\[ 0 \\leq f(x) \\leq 1, \\ \\forall x\\]probabilities sum unity. ,probabilities sum unity. ,\\[ \\sum_{x} f(x)= 1\\]Probability distributions can represented variety different ways. practice use tables distributions use computer functions evaluate .R can use following functions evaluate probabilities example 3.5.important function \\(\\texttt{dgeom()}\\), \\(\\texttt{d}\\) stands distribution \\(\\texttt{geom}\\) geometric distribution.Another way represent probability distribution cumulative sum.Definition 3.4  (Cumulative distribution function) Given random variable \\(X\\) probability mass function \\(f(x)\\), cumulative distribution function (abbreviated CDF) denoted capital letter \\(F(x)\\) defined sum probabilities less equal value \\(x\\). ,\\[ F(x) = \\text{P}(X\\leq x) = \\sum_{t\\leq x}f(t)\\]Example 3.6  (another urn problem) Consider setup previously two balls numbered \\(1\\) \\(5\\) drawn maximum two numbers taken.\nfound probability distribution ,Work CDF \\(F(x)\\).solutionIf \\(x<2\\) \\(F(x)=0\\).\n\\(2\\leq x < 3\\) \\(F(x) = \\frac{1}{10}\\).\n\\(3\\leq x < 4\\) \\(F(x) = \\frac{1}{10} + \\frac{2}{10}\\).\n\\(4\\leq x < 5\\) \\[F(x) = \\frac{1}{10} + \\frac{2}{10} + \\frac{3}{10}.\\]\n\\(5\\leq x\\) \\[F(x) = \\frac{1}{10} + \\frac{2}{10} + \\frac{3}{10} + \\frac{4}{10}.\\]Altogether,\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n  0  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   x<2 \\\\\n  \\frac{1}{10} \\  \\  2\\leq x < 3 \\\\\n  \\frac{3}{10} \\ \\  3\\leq x < 4 \\\\\n  \\frac{6}{10} \\ \\ \\ 4\\leq x < 5 \\\\\n  1 \\ \\ \\  \\ \\ \\  5\\leq x\n  \\end{cases}\n\\end{equation*}\\]Example 3.7  CDF geometric distribution given \n\\[F(x) = 1- (1-\\pi)^{x}.\\]solution\\[F(x) = \\sum_{t\\leq x}f(t)\\]\nSum \\(t=1\\) \\(t=x\\).\\[  = \\pi + \\pi(1-\\pi) + \\pi(1-\\pi)^2 + \\dots +  \\pi(1-\\pi)^{x-1} \\]\nmight recognise geometric series , \\(=\\pi\\) \\(r=(1-\\pi)\\), can collected :\\[F(x) = \\frac{\\pi (1-(1-\\pi)^x)}{1-(1-\\pi)} \\]\nEvaluating denominator cancelling gives result.CDF useful mass function since given CDF can calculate mass function directly difference.\\[f(x) = F(x)-F(x-1)\\]Example 3.8  Calculate \\(f(4)\\) given CDF\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n  0  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   x<2 \\\\\n  \\frac{1}{10} \\  \\  2\\leq x < 3 \\\\\n  \\frac{3}{10} \\ \\  3\\leq x < 4 \\\\\n  \\frac{6}{10} \\ \\ \\ 4\\leq x < 5 \\\\\n  1 \\ \\ \\  \\ \\ \\  5\\leq x\n  \\end{cases}\n\\end{equation*}\\]solution\\(f(4) = F(4)-F(3) = \\frac{6}{10}-\\frac{3}{10} = \\frac{3}{10}\\)Due fact mass function can calculated CDF, statistical tables often prioritise tabulating CDF various different types distribution.finish section example theory may used applied calculations.Example 3.9  Assuming archer’s attempts hit target follows geometric distribution success parameter \\(\\frac{1}{4}\\) calculate probability heHits \\(10^{\\text{th}}\\) attempt.Hits \\(10^{\\text{th}}\\) attempt.Takes fewer \\(4\\) attempts hit target.Takes fewer \\(4\\) attempts hit target.Takes least \\(8\\) attempts hit target.Takes least \\(8\\) attempts hit target.Takes \\(4\\) \\(8\\) attempts inclusive.Takes \\(4\\) \\(8\\) attempts inclusive.solutionLet \\(Y\\) number attempts hit target. know \\[f(y) = \\left( \\frac{3}{4} \\right) ^{y-1}\\frac{1}{4}\\]\\[ F(y) = 1- \\left(1-\\frac{1}{4}\\right)^y = 1-\\left( \\frac{3}{4}\\right)^y.\\]\\(\\text{P}(Y=10) = f(10) = \\left( \\frac{3}{4}\\right)^9\\times \\frac{1}{4} = 0.0188\\) (\\(3\\) s.f.).\\(\\text{P}(Y=10) = f(10) = \\left( \\frac{3}{4}\\right)^9\\times \\frac{1}{4} = 0.0188\\) (\\(3\\) s.f.).\\(\\text{P}(Y<4) = \\text{P}(Y\\leq 3) = F(3) =1 - \\left( \\frac{3}{4}\\right)^3 = 0.578\\), (\\(3\\) s.f.).\\(\\text{P}(Y<4) = \\text{P}(Y\\leq 3) = F(3) =1 - \\left( \\frac{3}{4}\\right)^3 = 0.578\\), (\\(3\\) s.f.).Using complement, \\(\\text{P}(Y\\geq 8) = 1 - \\text{P}(Y\\leq 7)\\). Now using CDF:Using complement, \\(\\text{P}(Y\\geq 8) = 1 - \\text{P}(Y\\leq 7)\\). Now using CDF:\\[1-F(7) = 1- \\left( 1-\\left(\\frac{3}{4}\\right)^7\\right) = 0.134.\\]Rewrite required range difference two CDF values follows:\\[\\text{P}(4\\leq Y\\leq 8) = \\text{P}(Y\\leq 8) - \\text{P}(Y\\leq 3)\\]\\[ = F(8) - F(3)\\]\\[ = \\left[ 1-\\left(\\frac{3}{4}\\right)^8\\right] -  \\left[ 1-\\left(\\frac{3}{4}\\right)^3\\right]\\]\n\\[ = 0.322\\]\ncareful evaluating CDF ensure correct values given inequality. small diagram list can invaluable .","code":"\ny <- dgeom(x = 1:4, #these are the particular values 1,2,3 and 4\n           prob = 1/4 ) #This is the probability of success\ny## [1] 0.18750000 0.14062500 0.10546875 0.07910156\n#You can output these as fractions using the MASS library\nMASS::fractions(y)## [1]    3/16    9/64  27/256 81/1024"},{"path":"drv.html","id":"mean-variance-and-moments","chapter":"3 Discrete Random Variables","heading":"3.4 Mean, variance and moments","text":"mean variance random variable essentially mirror definitions mean variance samples.mean expected value average value variable observed repeatedly. variance indicates likely spread values variable.Example 3.10  toss coin \\(2\\) times many heads expect turn ?solutionYour expect \\(1\\) intuitively. Let \\(X\\) number heads.\noutcomes \\((T,T),(H,T),(T,H),(H,H)\\). average number heads \\[ \\frac{0+1+1+2}{4} = 1\\]\ncan relate probability number heads. ,\\[\\text{P}(X=0) = \\frac{1}{4}\\]\n\\[\\text{P}(X=1) = \\frac{2}{4}\\]\n\\[\\text{P}(X=2) = \\frac{1}{4}\\]sum possible \\(x\\) values weighted probability :\n\\[0\\times \\frac{1}{4} + 1\\times \\frac{2}{4} + 2\\times \\frac{1}{4} = 1.\\]Definition 3.5  expectation, expected value random variable \\(X\\) defined sum possible values random variable weighted probability value.\\[ \\text{E}[X] = \\sum_x x\\times\\text{P}(X=x)\\]\njust number calculated called mean, written constant \\(\\text{E}[X]=\\mu\\) omit random quantity \\(X\\).expected value function discrete random variable \\(g(X)\\) defined similarly \n\\[ \\text{E}[X] = \\sum_x g(x)\\times\\text{P}(X=x)\\]Definition 3.6  variance random variable \\(X\\) defined :\\[ \\text{Var}[X] = \\text{E}[(X-\\mu)^2]\\]following useful practice actually computing variance.Theorem 3.1  Given random variable \\(X\\) variance equal difference expectation \\(X^2\\) squared expectation \\(X\\). ,\\[ \\text{Var}[X]=\\text{E}[X^2]-\\text{E}[X]^2 \\]omit proof now see examples, leaving interested reader.Proof. expectation sum, behaves linearly. definition,\\[\\text{Var}[X] = \\text{E}[(X-\\mu)^2]\\]\nExpanding bracket inside gives,\n\\[ = \\text{E}[X^2 - 2\\mu X +\\mu^2] \\]\nUsing linearity,\\[= \\text{E}[X^2]-2\\mu\\text{E}[X]+\\mu^2.\\]\n\\[= \\text{E}[X^2]-2\\mu^2+\\mu^2.\\]\nHence result.Example 3.11  discrete random variable \\(X\\) representing score loaded die following probability mass function.Calculate:\\(\\text{E}[X]\\)\\(\\text{E}[X]\\)\\(\\text{E}[X^2]\\)\\(\\text{E}[X^2]\\)\\(\\text{Var}[X]\\)\\(\\text{Var}[X]\\)\\(\\text{E}[e^X]\\)\\(\\text{E}[e^X]\\)solutionUsing definition expectation:\\[ \\text{E}[X] = 1\\times \\frac{1}{21}+2\\times \\frac{2}{21}+3\\times \\frac{3}{21}+4\\times \\frac{4}{21}+5\\times \\frac{5}{21}+6\\times \\frac{6}{21},\\]\n\\[ = 4.33 \\ \\ \\ (3 \\ \\text{s. f.})\\]\nCompared fair die, mean loaded die higher.\\[ \\text{E}[X^2] = 1^2\\times \\frac{1}{21}+2^2\\times \\frac{2}{21}+3^2\\times \\frac{3}{21}+4^2\\times \\frac{4}{21}+5^2\\times \\frac{5}{21}+6^2\\times \\frac{6}{21},\\]\\[ = 21\\]variance ,\\[\\text{Var}[X]=\\text{E}[X^2]-\\mu^2 = 21-(4.33\\dots)^2= 2.22 \\ \\ \\ (3 \\ \\text{s. f.})\\]\n4. \\(e^X\\) just function \\(X\\).\\[ \\text{E}[X] = e^1\\times \\frac{1}{21}+e^2\\times \\frac{2}{21}+e^3\\times \\frac{3}{21}+e^4\\times \\frac{4}{21}+e^5\\times \\frac{5}{21}+e^6\\times \\frac{6}{21},\\]\\[ = 164.622 \\ (3 \\ \\text{d. p.}) \\]Example 3.12  (expected profit) Consider following game. spinning wheel divided three equal sections numbered \\(1\\), \\(2\\) \\(3\\). pay £\\(1\\) play game, guess number show wheel spun. guess correctly, get £\\(2\\). get nothing. expected profit playing game?solutionThe profit winnings minus stake. Let profit random variable \\(X\\). distribution \\(X\\) :\\[\\text{E}[X] = -1 \\times \\frac{2}{3} + 1 \\times \\frac{1}{3} = -\\frac{1}{3}\\]\nexpect average make loss playing game. gambling game profitable house, necessary expectation players winnings negative.Example 3.13  Let \\(X\\) random variable whose value constant, particular values can take , \\(x=\\). Show \\(\\text{E}[X]=\\) \\(\\text{Var}[X]=0\\)solution\\[\\text{E}[X]=\\sum_{x}x\\times\\text{P}(X=x)= \\sum \\times\\text{P}(X=)=\\times \\sum \\text{P}(X=) = \\times 1 = \\]variance,\\[ \\text{Var}[X] = \\text{E}[(X-\\mu)^2]=\\text{E}[(-)^2]=0 \\]now proceed find mean variance Geometric distribution. need fact series first.Proposition 3.1  Suppose \\(|r|<1\\) recall infinite geometric series given following formula:\\[g(r) = \\sum_{k=0}^{\\infty}ar^{k} = \\frac{}{1-r}\\]\nconvergent series can differentiate term term respect \\(r\\), equate get differentiating RHS likewise. results following two formulae:\\[g'(r) = \\sum_{k=0}^{\\infty}akr^{k-1} = \\frac{}{(1-r)^2}\\]\\[g''(r) = \\sum_{k=0}^{\\infty}ak(k-1)r^{k-2} = \\frac{2a}{(1-r)^3}\\]Theorem 3.2  Let \\(X\\) random variable follows geometric distribution, \\(X \\thicksim \\text{Geom}(\\pi)\\), :\\[\\text{E}[X] = \\frac{1}{\\pi}\\]\n\n\\[ \\text{Var}[X]=\\frac{1-\\pi}{\\pi^2}\\]Proof. definition,\n\\[\\text{E}[X] = \\sum_{x=1}^{\\infty}x(1-\\pi)^{x-1}\\pi\\]\n\\[ = \\pi + 2\\pi(1-\\pi) + 3\\pi(1-\\pi)^2+4\\pi(1-\\pi)^3+ \\dots \\]\nlatter sum can seen \\(g'(1-\\pi)\\), \\(=\\pi\\). Using RHS result previous proposition ,\n\\[\\text{E}[X] = \\frac{\\pi}{[1-(1-\\pi)]^2} = \\frac{1}{\\pi}\\]\nvariance first find expectation function \\(X\\) called factorial moment.\\[\\text{E}[X(X-1)] = \\sum_{x=1}^{\\infty}x(x-1)\\pi(1-\\pi)^{x-1}\\]\n\\[ = (1-\\pi)\\sum_{x=2}^{\\infty}x(x-1)\\pi(1-\\pi)^{x-2}\\]\ninfinite series turns \\(g''(1-\\pi)\\) \\(=\\pi\\). Substituting gives,\\[\\text{E}[X(X-1)]=(1-\\pi)\\frac{2\\pi}{[1-(1-\\pi)]^3} = \\frac{2(1-\\pi)}{\\pi^2}.\\]\nNow can use find variance follows,\\[\\text{Var}[X] = \\text{E}[X^2]-\\text{E}[X]^2 \\]\n\\[ = \\text{E}[X(X-1)]+\\text{E}[X]-\\text{E}[X]^2 \\]\n\\[ = \\frac{2(1-\\pi)}{\\pi^2} + \\frac{1}{\\pi} - \\frac{1}{\\pi^2} \\]\n\\[ = \\frac{1-\\pi}{\\pi^2}\\]\nrequired.given two random variables \\(X\\) \\(Y\\) linear combination means expression form \\(aX+\\).Theorem 3.3  (Linear Combinations) random variables \\(X\\) \\(Y\\) constants \\(\\) \\(b\\) expectation linear combination linear combination expectations.\\[\\text{E}[aX\\pm ] = \\text{E}[X]\\pm b\\text{E}[Y]\\]\nHowever variance nonlinear sum variances.\\[\\text{Var}[aX\\pm ] = ^2\\text{Var}[X]+b^2\\text{Var}[Y] \\]Proof. omitted, follows properties summations mass functions.Example 3.14  Recall loaded die mass function given ,Suppose win \\(W\\) amount depending number roll loaded die.\\(W = 3X-10\\) find \\(\\text{E}[W]\\) \\(\\text{Var}[W]\\)solution\\[\\text{E}[W] = 3\\times (4.333\\dots) -10 = £3\\]\\[\\text{Var}[W] = 3^2\\times(2.22\\dots) = 19.99\\dots = 20.0 \\  (3 \\ \\text{s.f.})\\]","code":""},{"path":"drv.html","id":"exercises-week-3","chapter":"3 Discrete Random Variables","heading":"3.5 Exercises Week 3","text":"Exercise 3.1  urn contains two yellow balls three red balls. Three balls drawn random urn without replacement.Draw tree diagram represent sample space experiment find probabilities outcome.Draw tree diagram represent sample space experiment find probabilities outcome.Let random variable \\(X\\) denote number red balls drawn.Let random variable \\(X\\) denote number red balls drawn.Write probability distribtion \\(X\\).Write probability distribtion \\(X\\).Find mean variance \\(X\\).Exercise 3.2  Let \\(X\\) value observed rolling \\(8\\)-sided dieWhat probability distribution \\(X\\).probability distribution \\(X\\).Draw graph probability distribution.Draw graph probability distribution.Find mean variance \\(X\\).Find mean variance \\(X\\).Find expected value :Find expected value :\\(3X+5\\)\\(3X+5\\)\\(\\ln(X)\\)Exercise 3.3  game consists tossing coin first head appears. score recorded number tosses required.random variable \\(Y\\) number tosses, distribution \\(Y\\)?random variable \\(Y\\) number tosses, distribution \\(Y\\)?Write first \\(6\\) values probability distribution, draw sketch.Write first \\(6\\) values probability distribution, draw sketch.Find mean variance \\(Y\\).Find mean variance \\(Y\\).Exercise 3.4  Two fair dice rolled total score observed.Write probability distribution total score.Write probability distribution total score.Find mean variance total score.Find mean variance total score.Exercise 3.5  Two fair dice rolled maximum score observed.Write probability distribution maximum score.Write probability distribution maximum score.Find mean variance maximum score.Find mean variance maximum score.Exercise 3.6  fair coin tossed three times. Let \\(X\\) number heads tosses minus number tails.\n) Find probability distribution \\(X\\)Find mean variance \\(X\\).Exercise 3.7  game simple Chuck--luck played single player house. game conducted follows:player chooses number \\(1\\) \\(6\\) inclusive places bet £\\(1\\). banker rolls \\(2\\) fair dice. player’s number occurs \\(1\\) \\(2\\) times, wins £\\(1\\) £\\(2\\) respectively. player’s numberdoes appear dice, loses £\\(1\\) stake. Let random variable \\(X\\) denote player’s winnings game.Find probability mass function \\(X\\).Find probability mass function \\(X\\).Find expected value winnings, \\(\\text{E}[X]\\).Find expected value winnings, \\(\\text{E}[X]\\).Exercise 3.8  random variable \\(X\\) following probability mass function:Find value \\(c\\) makes valid probability mass function.Find value \\(c\\) makes valid probability mass function.Find \\(\\text{E}[X]\\) \\(\\text{Var}[X]\\).Find \\(\\text{E}[X]\\) \\(\\text{Var}[X]\\).Exercise 3.9  random variable \\(X\\) following probability mass function:\\(\\text{E}[Y]=\\frac{14}{3}\\)Find values \\(\\) \\(b\\).Find values \\(\\) \\(b\\).Find \\(\\text{Var}[Y]\\).Find \\(\\text{Var}[Y]\\).Exercise 3.10  fair six-sided die ‘\\(1\\)’ one face, ‘\\(2\\)’ two faces ‘\\(3\\)’ remaining three faces.Let \\(Y\\) denote score single roll die. Tabulate mass function calculate mean variance \\(Y\\).Let \\(Y\\) denote score single roll die. Tabulate mass function calculate mean variance \\(Y\\).Let \\(X\\) total score two rolls die. Tabulate mass function calculate mean variance \\(X\\).Let \\(X\\) total score two rolls die. Tabulate mass function calculate mean variance \\(X\\).Exercise 3.11  urn contains \\(n\\) balls numbered \\(1\\) \\(n\\) two balls drawn simultaneously. Find probability distribution \\(X\\), larger two numbers drawn. Calculate expected value \\(X\\).Exercise 3.12  \\(\\) \\(B\\) play game involves rolling fair die simultaneously. Let \\(X\\) absolute difference scores.Tabulate probability mass function \\(X\\).Tabulate probability mass function \\(X\\).Find mean variance \\(X\\).Find mean variance \\(X\\).value \\(X\\) \\(1\\) \\(2\\) \\(\\) wins. \\(X\\) \\(3\\),\\(4\\) \\(5\\) \\(B\\) wins. \\(X\\) zero roll . Find probability \\(\\) wins first go. Find probability \\(\\) wins second go. Find probability \\(\\) wins \\(r^{\\text{th}}\\) go.value \\(X\\) \\(1\\) \\(2\\) \\(\\) wins. \\(X\\) \\(3\\),\\(4\\) \\(5\\) \\(B\\) wins. \\(X\\) zero roll . Find probability \\(\\) wins first go. Find probability \\(\\) wins second go. Find probability \\(\\) wins \\(r^{\\text{th}}\\) go.Find probability \\(\\) wins.Find probability \\(\\) wins.Exercise 3.13  discrete random variable following mass function\\[\\begin{equation*}\n  f(y)=\\begin{cases}\n    \\pi \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  y = 1 \\\\\n    1-\\pi \\ \\  \\ y = 0 .\n  \\end{cases}\n\\end{equation*}\\]\\(0<\\pi<1\\).known Bernoulli distribution.Find \\(\\text{E}[Y]\\) \\(\\text{Var}[Y]\\)","code":""},{"path":"drv.html","id":"exercises-for-feedback-1","chapter":"3 Discrete Random Variables","heading":"3.5.1 Exercises for feedback","text":"Exercise 3.14  Scrabble tiles letters word EXERCISES bag.random tile drawn, probability letter E?random tile drawn, probability letter E?Given letter drawn bag vowel, probability E?Given letter drawn bag vowel, probability E?Explain two questions different words, compare size probabilities either part.Explain two questions different words, compare size probabilities either part.Exercise 3.15  \\(40\\) students Maths class, given number \\(1\\) \\(40\\). Separately numbers \\(1-40\\) placed hat mixed randomly. teacher give three random students prize. Three numbers selected hat without replacement. numbers drawn teacher guesses three numbers writes board.Work probability teacher matching \\(0\\), \\(1\\), \\(2\\) \\(3\\) numbers drawn hat.different occasion, teacher \\(5\\) students tutor group. wants give two prizes Maths students, one tutor group. draw two numbers hat, separately draw one numbers \\(1-5\\) shoe (one hat). writes prediction board selection.Work probability teacher predicting \\(0\\), \\(1\\) \\(2\\) Maths students, getting tutee correct, probability predicting \\(0\\), \\(1\\) \\(2\\) Maths students getting tutee correct.Exercise 3.16  fairground game played \\(5\\) dice. player pays £1 play, every \\(6\\) appears dice player rewarded £\\(6\\).Work probabilities getting \\(0\\),\\(1\\),\\(2\\),\\(\\dots\\),\\(5\\) sixes rolling five dice.Work probabilities getting \\(0\\),\\(1\\),\\(2\\),\\(\\dots\\),\\(5\\) sixes rolling five dice.\\(X\\) profit player game, work expected profit \\(\\text{E}[X]\\).\\(X\\) profit player game, work expected profit \\(\\text{E}[X]\\).Work also variance \\(\\text{Var}[X]\\).Work also variance \\(\\text{Var}[X]\\).Explain think good game .Explain think good game .Exercise 3.17  (Extension / Challenge) play game standard pack \\(52\\) cards. dealt hand \\(3\\) cards. hand contains pair, get \\(3\\) points. hand contains \\(3\\) kind, get \\(10\\) points. hand contains neither pair \\(3\\) kind lose point. expected number points score game?","code":""},{"path":"binpois.html","id":"binpois","chapter":"4 Special discrete random variables","heading":"4 Special discrete random variables","text":"chapter able recognise contexts Binomial distributions arise. Calculate binomial probabilities using formulae. Use binomial tables, calculators R look probabilities.","code":""},{"path":"binpois.html","id":"the-binomial-distribution","chapter":"4 Special discrete random variables","heading":"4.1 The Binomial Distribution","text":"binomial distribution one important discrete distributions finds application wide number areas.example mind following:Example 4.1  (coin tossing) Suppose toss coin \\(10\\) times count number heads observed.fixed number trials, \\(10\\), maximal number heads can observe.fixed number trials, \\(10\\), maximal number heads can observe.coin , probability heads throughout process. fair coin \\(\\frac{1}{2}\\).coin , probability heads throughout process. fair coin \\(\\frac{1}{2}\\).coin tosses independent. physical reason previous outcome may make heads less likely subsequent tosses.coin tosses independent. physical reason previous outcome may make heads less likely subsequent tosses.two outcomes coin toss: heads tails.two outcomes coin toss: heads tails.binomial distribution can used find probabilities whenever following conditions met:probability observing success single experiment fixed quantity, probability constant \\(\\text{P}(\\text{success}) = \\pi\\). (P constant probability)probability observing success single experiment fixed quantity, probability constant \\(\\text{P}(\\text{success}) = \\pi\\). (P constant probability)trials independent. ()trials independent. ()number experiments, trials, fixed number maximum value attainable. (N maximum number)number experiments, trials, fixed number maximum value attainable. (N maximum number)two outcomes.(T two outcomes)two outcomes.(T two outcomes)list assumptions underlying binomial model can summarised mnemonic PINT.Although can check mnemonic satisfied, may practicebe easier given situation make analogy coin tossing example. particular context number well vary, definition ‘success’. example, suppose considering many number men \\(50\\), suffer heart attack next year. ‘success’ heart attack!","code":""},{"path":"binpois.html","id":"the-binomial-mass-function","chapter":"4 Special discrete random variables","heading":"4.2 The binomial mass function","text":"Example 4.2  throw five drawing pins air note land pin pin . many ways can two pins land facing others land face ?Suppose probability single pin lands facing \\(0.3\\), probability exactly two land facing ?solutionConsider problem word UUDDD, many different words can obtained rearrangement? number ways rearranging \\(\\frac{5!}{2!}{3!} = 10\\).Note one choice numbers \\(^5C_2\\). choosing \\(5\\) things, two face remaining ones face .choice two pins calculation probability. , \\(0.3^2 \\times 0.7^3\\).Altogether probability \\(^5C_2 \\times 0.3^2 \\times 0.7^3\\).can derive binomial mass function similar way example.Theorem 4.1  Suppose random variable \\(X\\) satisfies conditions binomial random variable, \\(n\\) trials success probability \\(\\pi\\). mass function given :\n\\[\\text{P}(X=x) = {}^nC_x \\pi^{x}(1-\\pi)^{n-x}\\]Proof. \\(n\\) trials result \\(x\\) successes, probability \\(\\pi\\), must also \\(n-x\\) failures probability \\((1-\\pi)\\). Using independence, probability happening \\[\\pi ^x (1-\\pi)^{n-x} \\]\nnumber ways can happen, equal \\(^nC_x\\). Hence result.Example 4.3  Suppose fair die rolled four times. probability getting,exactly one six?exactly one six?\\(1\\) six?\\(1\\) six?solutionA common mistake \\(\\frac{1}{6}\\times \\left( \\frac{5}{6} \\right)^3\\). correct - ? can happen \\(^4C_1=4\\) ways,\\[4\\times \\frac{1}{6}\\times \\left( \\frac{5}{6} \\right)^3 = 0.386 \\text{ (3 s.f.)}\\]\\(X\\) number sixes, one means \\(X \\leq 1\\). work adding two cases \\(X=0\\) \\(X=1\\) together. One calculate directly mass function follows:\\[^4C_0 \\times \\left( \\frac{1}{6} \\right)^0 \\times \\left( \\frac{5}{6} \\right)^4+ ^4C_1 \\times \\left( \\frac{1}{6} \\right)^1 \\times \\left( \\frac{5}{6} \\right)^3\\]\nObtaining \\(0.868\\text{ (3 s.f.)}\\).examples binomial probability distributions given following figures.\nFigure 4.1: Probability mass function B(9,0.2)\n\nFigure 4.2: Probability mass function B(8,0.5)\ncan account seemingly different shape?success probability close \\(0.5\\) distribution symmetrical shape, otherwise skewed.Example 4.4  train station \\(5\\) self-service ticket machines. probability machine working time \\(0.15\\). Let \\(X\\) number machines working.Comment whether binomial distribution suitable model \\(X\\).Assuming binomial distribution X, evaluate probability following number machines working.exactly \\(2\\).exactly \\(2\\).least \\(4\\).least \\(4\\).\\(2\\).\\(2\\).solutionChecking mnemonic PINT works. ‘success’ ticket machine working. Independence might hold example one machine working caused others also fail somehow, probability time including time others failed.Checking mnemonic PINT works. ‘success’ ticket machine working. Independence might hold example one machine working caused others also fail somehow, probability time including time others failed.\\(\\text{P}(X=2) = ^5C_2 \\times 0.15^2 \\times (1-0.15)^{5-2} = 0.138\\).\\(\\text{P}(X=2) = ^5C_2 \\times 0.15^2 \\times (1-0.15)^{5-2} = 0.138\\).\\(\\text{P}(X\\geq 4) = \\text{P}(X=4) + \\text{P}(X=5)\\). Evaluating formulae gives:\\(\\text{P}(X\\geq 4) = \\text{P}(X=4) + \\text{P}(X=5)\\). Evaluating formulae gives:\\[= {}^5C_4 \\times 0.15^4 \\times (1-0.15)^{5-4}+ ^5C_5 \\times 0.15^5 \\times (1-0.15)^{5-5}\\]\n\\[= 0.0022\\]\\(\\text{P}(X\\leq 2) = \\text{P}(X=0) + \\text{P}(X=1) + \\text{P}(X=2)\\). evaluating formula term sum gives:\\[= {}^5C_0 \\times 0.15^0 \\times (1-0.15)^{5-0}+ {}^5C_1 \\times 0.15^1 \\times (1-0.15)^{5-1}+ {}^5C_2 \\times 0.15^2 \\times (1-0.15)^{5-2}\\]\n\\[ = 0.973 \\]Alternatively, number cases add large enough tedious hand calculation (need add cases together), one may consult statistical tables CDF.binomial distribution widely applied important, almost every book statistical tables contain pages binomial CDF. tables used MMU give probabilities selected values \\(n\\) \\(\\pi\\) form \\(\\text{P}(X\\leq x)\\). probability can calculated tables using rules like following:\\(\\text{P}(X\\leq x)\\), directly table.\\(\\text{P}(X\\leq x)\\), directly table.\\(\\text{P}(X\\geq x) = 1- \\text{P}(X\\leq x-1)\\), using complements.\\(\\text{P}(X\\geq x) = 1- \\text{P}(X\\leq x-1)\\), using complements.\\(\\text{P}(X = x) = \\text{P}(X\\leq x) - \\text{P}(X\\leq x-1)\\), getting mass function CDF usual way.\\(\\text{P}(X = x) = \\text{P}(X\\leq x) - \\text{P}(X\\leq x-1)\\), getting mass function CDF usual way.can probability \\(X\\) lying range , one must careful whether inequality strict .\\(\\text{P}(\\leq X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(\\leq X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(< X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq )\\)\\(\\text{P}(< X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq )\\)\\(\\text{P}(\\leq X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(\\leq X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(< X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq )\\)\\(\\text{P}(< X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq )\\)Graphing inequality listing required values \\(X\\) helps improve accuracy , recommend learning just rules .modern times commonly consult calculator, tables recorded memory. example, R can calculation 4.3 using following commands.geometric distribution, binomial distribution function called R \\(\\texttt{dbinom()}\\), \\(\\texttt{d}\\) stands distribution \\(\\texttt{binom}\\) binomial distribution.","code":"\ny <- dbinom(x=0:1, size = 4, prob = 1/6 ) # putting x=0:1 makes y take the two values we want\nsum(y) # working out the sum is easy now## [1] 0.8680556"},{"path":"binpois.html","id":"mean-and-variance","chapter":"4 Special discrete random variables","heading":"4.3 Mean and variance","text":"goal find simple expressions mean variance binomial distribution. choose directly, though methods may see next year.Theorem 4.2  binomially distributed random variable \\(X\\sim \\text{Bin}(n,\\pi)\\) mean product number trials success probability. ,\\[\\text{E}[X] = n\\pi \\]variance \\(X\\) product mean failure probability. ,\\[ \\text{Var}[X] = n\\pi (1-\\pi)\\]Proof. Starting definition,\\[ \\text{E}[X] = \\sum_{x=0}^{n}x\\times \\text{P}(X=x)\\]\nCombining mass function gives\\[ \\text{E}[X] = \\sum_{x=0}^{n}x\\times ^{n}C_{x} \\pi^x (1-\\pi)^{n-x} \\]\ndefinition numbers \\(^{n}C_{x}\\),\\[ \\text{E}[X] = \\sum_{x=0}^{n}x\\times \\frac{n!}{x!\\times(n-x)!} \\pi^x (1-\\pi)^{n-x} \\]\nNow first term sum \\(x=0\\), \\(x\\) factor sum actually starts \\(x=1\\).\n\\[  = \\sum_{x=1}^{n} \\frac{n!}{(x-1)!\\times(n-x)!} \\pi^x (1-\\pi)^{n-x} \\]\n\\[  = n\\pi\\sum_{x=1}^{n} \\frac{(n-1)!}{(x-1)!\\times(n-x)!} \\pi^{x-1} (1-\\pi)^{n-x} \\]\nNow letting \\(m=n-1\\) \\(y=x-1\\) sum becomes,\\[  = n\\pi\\sum_{y=0}^{m} \\frac{m!}{y!\\times(m-y)!} \\pi^{y} (1-\\pi)^{m-y} \\]\nterm sum binomial probability \\(Y\\sim \\text{Bin}(m,\\pi)\\), altogether sum equal \\(1\\).Hence \\(\\text{E}[X] = n\\pi\\).variance omit proof longer instructive.interested reader consider \\(\\text{E}[X(X-1)]\\) \\(\\text{E}[X^2]\\), manipulations sums similar .","code":""},{"path":"binpois.html","id":"the-poisson-distribution","chapter":"4 Special discrete random variables","heading":"4.4 The Poisson distribution","text":"distribution invented French mathematician Simeon Poisson, distribution bears namesake appears capitalised unlike binomial distribution.Poisson distribution can applied remarkable number areas involving counting processes. examples include.number ‘goals’ scored sports game.number ‘goals’ scored sports game.number sales per week.number sales per week.number Website visitors per hour.number Website visitors per hour.number arrivals &E Manchester Royal Infirmary day.number arrivals &E Manchester Royal Infirmary day.number bacterial growths given area, Petri dish.number bacterial growths given area, Petri dish.Poisson distribution may applied whenever random variable interest counts number events given interval, number without bound (though larger counts less likely). events occur one time, independently randomly given interval. events occur uniformly given interval, mean number events proportional size interval - events occur constant average rate.mnemonic SIR/MR can used summarise paragraph.S - simultaneouslyI - IndependentR - RandomlyM - maximum number eventsR - constant average rateExample 4.5  (telephone calls) Let number telephone calls arriving switchboard minute random variable \\(X\\). \\(X\\) satisfies assumptions modelled Poisson distribution.Poisson distribution depends one parameter - mean rate \\(\\lambda\\). pictures Poisson distribution functions different values mean rate.\nFigure 4.3: Probability mass function Pois(3)\n\nFigure 4.4: Probability mass function Pois(6)\nDefinition 4.1  Given random variable following Poisson distribution \\(X\\sim \\text{Pois}(\\lambda)\\) mass function given :\\[\\text{P}(X=x) = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\]\n\\(x=0,1,2, \\dots\\), \\(\\lambda>0\\).Although probabilities attached higher values \\(x\\) positive, quickly become small. mean rate \\(\\lambda\\) need whole number, even though count given interval need whole number. binomial distribution, tables given CDF Poisson distribution.Example 4.6  company operates helpdesk hotline service. Incoming calls hotline arrive mean rate \\(3.5\\) per minute outgoing calls made rate \\(4.2\\) per minute. Find probability thatat least five calls arrive one minute.least five calls arrive one minute.exactly five calls arrive one minute.exactly five calls arrive one minute.7 calls outgoing one minute.7 calls outgoing one minute.\\(4\\) \\(9\\) calls inclusive outgoing one minute.\\(4\\) \\(9\\) calls inclusive outgoing one minute.solution\\(\\text{P}(X\\geq 5) = 1 - \\text{P}(X\\leq 4) = 1-0.7254 = 0.2746\\)\\(\\text{P}(X\\geq 5) = 1 - \\text{P}(X\\leq 4) = 1-0.7254 = 0.2746\\)\\(\\text{P}(X=5) = \\text{P}(X\\leq 5) - \\text{P}(X\\leq 4) = 0.8576 - 0.7254 = 0.1322\\)\\(\\text{P}(X=5) = \\text{P}(X\\leq 5) - \\text{P}(X\\leq 4) = 0.8576 - 0.7254 = 0.1322\\)\\(\\text{P}(Y\\leq 7) = 0.9361\\)\\(\\text{P}(Y\\leq 7) = 0.9361\\)\\(\\text{P}(4\\leq Y \\leq 9 ) = \\text{P}(Y\\leq 9) - \\text{P}(Y\\leq 3) = 0.9889 - 0.3954 = 0.5935\\).\\(\\text{P}(4\\leq Y \\leq 9 ) = \\text{P}(Y\\leq 9) - \\text{P}(Y\\leq 3) = 0.9889 - 0.3954 = 0.5935\\).","code":""},{"path":"binpois.html","id":"further-properties","chapter":"4 Special discrete random variables","heading":"4.4.1 Further properties","text":"important aspect Poisson model uniform average rate. means assume events occur rate interval. size interval changes, must change mean rate direct proportion change size.Example 4.7  (hotline continued) assume calls hotline incoming rate \\(3.5\\) per minute. Find probability thatat least \\(20\\) calls arrive exchange \\(4\\) minute period.least \\(20\\) calls arrive exchange \\(4\\) minute period.\\(1\\) call arrives \\(12\\) second period.\\(1\\) call arrives \\(12\\) second period.solutionIf \\(3.5\\) calls per minute, \\(4\\) minute period one expects rate \\(3.5\\times 4=14\\) calls.Let \\(W\\) number calls \\(4\\) minute period. \\(W\\sim\\text{Pois}(14)\\). ,\\[\\text{P}(W\\geq 20) = 1- \\text{P}(W\\leq 19) = 1-0.9235 = 0.0765.\\]\\(12\\) seconds one fifth minute, expect rate \\(3.5\\div 5 = 0.7\\) calls.Let \\(Z\\) number calls \\(12\\) second period. ,\\[\\text{P}(Z\\leq 1) = 0.8442\\]second useful property different Poisson variables can added together yield another Poisson distribution whose rate parameter sum individual rates.Theorem 4.3  , \\(X\\sim \\text{Pois}(\\lambda)\\) \\(Y\\sim \\text{Pois}(\\mu)\\) \n\\[X+Y \\sim \\text{Pois}(\\lambda+\\mu)\\]Proof. Omitted now. second year course learn moment generating functions makes proof easy.Example 4.8  Suppose game football home team scores goals rate \\(2\\) per match, away team scores goals rate \\(3\\) per match. expect total number goals two teams occur rate \\(5\\) per match.context particular pair teams may realistic model. ?","code":""},{"path":"binpois.html","id":"mean-and-variance-1","chapter":"4 Special discrete random variables","heading":"4.5 Mean and Variance","text":"section consider mean variance Poisson distribution.need Mathematical preliminaries Calculus.Proposition 4.1  (characterisations Euler's number) real number \\(x \\\\mathbb{R}\\) \\[e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}\\]\\[ \\lim_{n\\\\infty} \\left( 1+\\frac{x}{n} \\right)^n = e^x\\]Theorem 4.4  Let \\(X\\) Poisson distributed random variable rate \\(\\lambda\\), \\(X\\sim \\text{Pois}(\\lambda)\\). \\[\\text{E}[X]  = \\lambda\\]\n\n\\[\\text{Var}[X] = \\lambda\\]Proof. \\[\\text{E}[X] = \\sum_{x=0}^{\\infty}x\\frac{\\lambda^x e^{-\\lambda}}{x!}\\]\n\\[ =\\lambda e^{-\\lambda} \\sum_{x=1}^{\\infty}\\frac{\\lambda^{(x-1)}}{(x-1)!} \\]\n\\[=\\lambda e^{-\\lambda} \\sum_{y=0}^{\\infty}\\frac{\\lambda^{y}}{y!} \\]\n\\[=\\lambda e^{-\\lambda} e^{\\lambda}  \\]\n\\[ = \\lambda .\\]\nvariance consider\\[\\text{E}[X(X-1)] = \\sum_{x=0}^{\\infty}x(x-1)\\frac{\\lambda^x e^{-\\lambda}}{x!}\\]\n\\[ =\\lambda^2e^{-\\lambda} \\sum_{x=2}^{\\infty}\\frac{\\lambda^{x-2}}{(x-2)!}\\]\n\\[ =\\lambda^2e^{-\\lambda} \\sum_{y=0}^{\\infty}\\frac{\\lambda^y}{y!}\\]\n\\[ =\\lambda^2e^{-\\lambda} e^{\\lambda}\\]\n\\[ =\\lambda^2\\]\n\\(\\text{E}[X(X-1)] = \\text{E}[X^2] - \\text{E}[X]\\), can rearrange find \\[\\text{E}[X^2] = \\lambda^2 + \\lambda \\]variance \\(\\text{Var}[X] = \\text{E}[X^2] - \\text{E}[X]^2\\), :\\[\\text{Var}[X] = \\lambda^2 + \\lambda - \\lambda ^2 = \\lambda .\\]","code":""},{"path":"binpois.html","id":"deriving-the-poisson-mass-function","chapter":"4 Special discrete random variables","heading":"4.6 Deriving the Poisson mass function","text":"Poisson distribution intimately linked binomial distribution. aim section show mass function form given definition.Suppose events occur result Poisson process independently uniform rate \\(\\lambda\\) given time interval. Divide time period large number smaller intervals, \\(n\\) say, chance two events happening one interval negligible. probability event happening one small intervals \\(\\lambda / n\\).Letting \\(X\\) random variable representing number small intervals contain event, can see one hand binomially distributed fixed \\(n\\). \\[ \\text{P}(X=x) = {}^nC_{x} \\left(\\frac{\\lambda}{n}\\right)^x \\left( 1- \\frac{\\lambda}{n}\\right)^{n-x}\\]\\[ = \\lambda^{x} \\underbrace{\\frac{^nC_{x}}{n^x}}_{1} \\underbrace{\\left( 1- \\frac{\\lambda}{n}\\right)^{n}}_{2}\\underbrace{\\left( 1- \\frac{\\lambda}{n}\\right)^{-x}}_{3} \\]consider happens increase \\(n\\), consider term separately (allowed convergent sequences).term \\(2\\), \\(n\\) gets larger number inside bracket gets close \\(1\\), overall limit \\(1\\).term \\(3\\) can seen equal \\(e^{-\\lambda}\\) proposition (B).first term \\(1\\), can manipulated follows:\\[\\lim_{n\\\\infty}\\frac{^nC_{x}}{n^x} = \\lim_{n\\\\infty} \\frac{n!}{(n-x)!x!n^x}\\]\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{n(n-1)(n-2)\\dots(n-x+1)}{n^x}\\]\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{n}{n}\\frac{(n-1)}{n}\\frac{(n-2)}{n}\\dots \\frac{(n-x+1)}{n}\\]\n\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{n}{n}\\frac{(n-1)}{n}\\frac{(n-2)}{n}\\dots \\frac{(n-x+1)}{n}\\]\n\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{(n-1)}{n}\\frac{(n-2)}{n}\\dots \\frac{(n-x+1)}{n}\\]\n\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\left(1 - \\frac{1}{n}\\right)\\lim_{n\\\\infty}\\left(1 - \\frac{2}{n}\\right)\\dots \\lim_{n\\\\infty} \\left(1 - \\frac{x-1}{n}\\right)\\]\nlimits \\(1\\).Altogether ,\\[lim_{n\\\\infty} {}^nC_{x} \\left(\\frac{\\lambda}{n}\\right)^x \\left( 1- \\frac{\\lambda}{n}\\right)^{n-x}  = \\lambda^x \\times \\frac{1}{x!} \\times e^{-\\lambda}\\times 1 = \\frac{\\lambda^xe^{-\\lambda}}{x!}.\\]\nprobability observing \\(x\\) events whole time interval.side relationship Poisson distribution can used approximate binomial distribution.Theorem 4.5  \\(\\pi\\) small \\(n\\) large , binomial distribution can approximated Poisson distribution rate parameter equal mean binomial distribution.\\[\\text{Binom}(n,\\pi) \\approx \\text{Pois} (\\lambda)\\]\nset \\(\\lambda = n\\pi.\\)proof\nOmitted.","code":""},{"path":"binpois.html","id":"exercises-week-4","chapter":"4 Special discrete random variables","heading":"4.7 Exercises week 4","text":"Exercise 4.1  Ropes tested certain breaking strain. According past experience quarter ropes break strain. \\(4\\) identical ropes tested, write probability distribution number ropes breaking.Exercise 4.2  estimated \\(20\\%\\) individuals carry anibodies particular virus. probability group \\(20\\) randomly selected individuals:\\(8\\) antibodies.\\(8\\) antibodies.Exactly \\(6\\) antibodies.Exactly \\(6\\) antibodies.Fewer \\(4\\) antibodies.Fewer \\(4\\) antibodies.\\(3\\) \\(6\\) inclusive antibodies.\\(3\\) \\(6\\) inclusive antibodies.Exercise 4.3  car salesperson knows past experience make sale \\(30\\%\\) customers. Find probability \\(20\\) randomly selected sales pitches makes sale toMore 4 customersMore 4 customersFewer \\(7\\) customersFewer \\(7\\) customersExactly \\(6\\) customersExactly \\(6\\) customersbetween \\(4\\) \\(10\\) exclusive.\\(4\\) \\(10\\) exclusive.Exercise 4.4  footballer takes free kick scores goal \\(10\\%\\) occasions. Find probability match \\(10\\) free kicks takenShe scores least two goalsShe scores least two goalsShe scores exactly two goalsShe scores exactly two goalsShe scores \\(3\\) goals fewer.scores \\(3\\) goals fewer.goals free kicks alone. assumptions need make, extent think reasonable?Exercise 4.5  statistics lecturer sets test involving \\(20\\) multiple choice questions, four possible answers question. want choose pass mark chance passing student guesses every question less \\(5\\%\\). pass mark ?Exercise 4.6  game advanced Chuck--luck extension simple game last week’s exercises. banker rolls \\(n\\) dice player wins £\\(x\\) number player guesses appears \\(x\\) \\(n\\) dice. loses £\\(1\\) stake number come dice.Write probability mass function \\(X\\).Write probability mass function \\(X\\).Show \\(\\text{E}[X] = \\frac{n}{6} - 1\\)Show \\(\\text{E}[X] = \\frac{n}{6} - 1\\)(Hint might want build part () particular picking values \\(n=1,2,3,\\dots\\) pattern spotting.)Exercise 4.7  biologist field trip studying biodiversity found number plant species \\(1 \\  \\text{m}^2\\) quadrat follows Poisson distribution mean \\(6\\).Find probability number plant species given \\(1 \\  \\text{m}^2\\) quadrat ;least 8at least 8less equal \\(8\\)less equal \\(8\\)exactly \\(8\\)exactly \\(8\\)\\(6\\) \\(12\\) inclusivebetween \\(6\\) \\(12\\) inclusiveFind probability quadrat area \\(0.5 \\  \\text{m}^2\\), number plant species isat least \\(3\\)least \\(3\\)fewer \\(5\\)fewer \\(5\\)exactly \\(4\\)exactly \\(4\\)\\(3\\) \\(6\\) inclusivebetween \\(3\\) \\(6\\) inclusiveExercise 4.8  car leaves production line carefully examined signs imperfection paintwork. Previous experience shown number blemishes per car follows Poisson distribution mean \\(0.4\\).\n) Find probability car hasat least one blemishat least one blemishmore one blemishmore one blemishexactly one blemishexactly one blemishno blemishesno blemishesIn \\(1\\) hour inspector can examine \\(20\\) cars. Assuming blemishes occur independently, find probability inspector findsfewer \\(5\\) blemishesfewer \\(5\\) blemishesexactly five blemishesexactly five blemishesat least one blemishat least one blemishExercise 4.9  traffic survey found buses pass checkpoint average rate \\(4.5\\) per hour. Lorries pass checkpoint rate \\(5\\) per hour coaches rate \\(1.5\\) per hour.Find probability \\(1\\) hour\\(5\\) buses pass checkpoint\\(5\\) buses pass checkpointbetween \\(10\\) \\(15\\) lorries inclusive pass checkpointbetween \\(10\\) \\(15\\) lorries inclusive pass checkpointfewer \\(3\\) buses pass checkpointfewer \\(3\\) buses pass checkpointAt least \\(8\\) buses coaches pass checkpoint hour\nleast \\(8\\) buses coaches pass checkpoint hourexactly \\(15\\) buses coaches pass checkpoint hourexactly \\(15\\) buses coaches pass checkpoint hourten fewer buses, lorries coaches pass checkpoint half hour.ten fewer buses, lorries coaches pass checkpoint half hour.Exercise 4.10  numbers emissions per minute two radioactive rocks \\(\\) \\(B\\) independent Poisson variables means \\(0.65\\) \\(0.45\\) respectively. Find probability thatIn period three minutes least three emissions \\(\\).period three minutes least three emissions \\(\\).period two minutes total less four emissions \\(\\) \\(B\\) combined.period two minutes total less four emissions \\(\\) \\(B\\) combined.Exercise 4.11  particular form cancer, deformed blood corpuscles occur random rate \\(10\\) per \\(1000\\) corpuscles.Use appropriate approximation determine probability random sample \\(200\\) corpuscles taken cancerous area contain deformed corpuscles.Use appropriate approximation determine probability random sample \\(200\\) corpuscles taken cancerous area contain deformed corpuscles.large sample taken order \\(99\\%\\) certain least one deformed corpuscle sample?large sample taken order \\(99\\%\\) certain least one deformed corpuscle sample?Exercise 4.12  (counting practice) box contains \\(12\\) golf balls, \\(3\\) substandard. random sample \\(4\\) balls selected, without replacement, box. random variable \\(R\\) denotes number balls sample substandard.Show probability mass function \\(R\\) satisfies\\[\\text{P}(R=r) = \\frac{{}^3C_r \\times {}^9C_{4-r}}{^{12}C_{4}} \\]\n(ii) Determine probability \\(R=0\\)Determine probability fewer two substandard balls.large bin contains \\(5000\\) used golf balls, \\(1500\\) defective. random variable \\(X\\) denotes number defective balls random sample 20balls selected, without replacement,bin. Explain \\(X\\) may approximated binomial variable parameters \\(20\\) \\(0.3\\). Using binomial model, calculate probability sample containsfewer \\(5\\) defective ballsfewer \\(5\\) defective ballsat least \\(7\\) defective ballsat least \\(7\\) defective ballsExercise 4.13  independent Poisson random variables \\(X\\) \\(Y\\)means \\(2.5\\) \\(1.5\\) respectively. Obtain mean variance random variables , hence give reason Poisson.\n) \\(X-Y\\)\nb) \\(2X+5\\)","code":""},{"path":"cont.html","id":"cont","chapter":"5 Continuous random variables","heading":"5 Continuous random variables","text":"chapter learn continuous random variables. random variable may arise measurement process.real life many observations assumed take real numbered values. principle observe value continuum. example:lifetime lithium-ion batteryThe lifetime lithium-ion batteryThe weight babyThe weight babyThe height random personThe height random personIn practice constrained accuracy measuring device (heights often quoted nearest inch, centimeter) distinction discrete continuous sometimes blurred.Example 5.1  Consider class undergraduates MMU. following measurement age:Age nearest decadeAge nearest decadeAge yearsAge yearsAge monthsAge monthsAge daysAge daysAge secondsAge secondsAlthough none variables strictly measured continuous scale, measure variables differently. decades take particular values modelled discrete, whereas age seconds take many different values ’s almost continuous.","code":""},{"path":"cont.html","id":"relation-to-histograms","chapter":"5 Continuous random variables","heading":"5.1 Relation to histograms","text":"Given actual continuous data, one make plot frequently data lies within certain intervals. resulting plot called histogram. intervals need equal, modern practice . computer implementations intervals called bins interval size bin width.classic example built R Old Faithful geyser data. waiting times eruptions duration eruption recorded Old Faithful geyser Yellowstone National Park, Wyoming, USA.Suppose want estimate proportion probability particularly long waiting time. instead bar height equal frequency can set area proportional frequency. can done way make total area histogram equal \\(1\\).\nFigure 5.1: Waiting time eruptions, one sees data precision smaller bin width\nfind proportion two values one total area bars. One can see limit idea, perhaps large sample smooth curve like plot titled ‘estimated density’, find area curve.","code":""},{"path":"cont.html","id":"two-students","chapter":"5 Continuous random variables","heading":"5.2 Two students","text":"Consider two students appointment tutor \\(12\\)-noon.first student makes effort get time, likely little late late, live far university. may late certainly \\(1\\) o’clock.\nsecond student forgotten appointment, lives close university, may arrive time \\(1\\) o’clock, soon remember.sample space ?Take \\(\\Omega = [0,1]\\) delay measured hours. event interval student arrives. example \\([0,\\frac{1}{2}]\\) event student half hour late.probability arriving given interval area curve \\[f(x) = 2-2x \\ ,\\ \\text{} x\\[0,1].\\]shown image :\nFigure 5.2: density function first student\nprobability student arriving first half hour, \\(12:00\\) \\(12:30\\), \\(\\frac{3}{4}\\), whereas probability arriving last half hour, \\(12:30\\) \\(13:00\\), \\(\\frac{1}{4}\\).time second student arrives may modelled function\\[f(x) = 1\\ ,\\ \\text{} x\\[0,1].\\]called uniform density reflects fact time equally likely.\nFigure 5.3: density function second student\nprobability related function \\(\\text{P}([,b]) = b-\\).Can find expression \\(\\text{P}([,b])\\) first student?","code":""},{"path":"cont.html","id":"the-probability-density-function","chapter":"5 Continuous random variables","heading":"5.3 The probability density function","text":"continuous random variables equivalent probability mass function called probability density function.discrete random variables makes sense ask probability \\(X\\) takes particular value \\(\\text{P}(X=x)\\), always zero continuous setting. Instead probability \\(X\\) lying interval \\(\\text{P}(<X<b)\\).Definition 5.1  probability density functionof continuous random variable \\(X\\) function thatThe function everywhere non-negative\n\\[f(x) \\geq 0 \\text{ } \\ x\\\\mathbb{R}\\]function everywhere non-negative\n\\[f(x) \\geq 0 \\text{ } \\ x\\\\mathbb{R}\\]probability \\(X\\) taking value interval \\((,b)\\) given corresponding integral curve respect \\(x\\).probability \\(X\\) taking value interval \\((,b)\\) given corresponding integral curve respect \\(x\\).\\[\\text{P}(<X<b) = \\int_{}^{b} f(x) \\  dx\\]total area graph domain \\(f(x)\\) unity. Let domain \\(f(x)\\) \\(x\\(c,d)\\).\\[ \\int_{c}^{d} f(x) \\  dx = 1\\]Example 5.2  continuous random variable \\(X\\) probability density function given \\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{2}x, &  0< x < 2\\\\\n    0 & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Calculate \\(\\text{P}(X>1)\\).solutionyou sketch get intuition whether probability half.use calculus , draw picture area required trapezium.area therefore \\(\\frac{(\\frac{1}{2}+1)\\times 1}{2}=\\frac{3}{4}\\).Example 5.3  continuous random variable probability density function \\(f(x) = kx^2\\) \\(0\\leq x\\leq 4\\).Find value constant \\(k\\)Find value constant \\(k\\)Find \\(\\text{P}(1\\leq X \\leq 3)\\)Find \\(\\text{P}(1\\leq X \\leq 3)\\)solutionWe need use calculus curve.find \\(k\\), use fact \\(f\\) integrates \\(1\\) domain.\\[ \\int_{0}^{4}kx^2 \\ dx = \\left[ \\frac{kx^3}{3}\\right]^{x=4}_{x=0}\\]\\[ 1= \\frac{k}{3} (64-0)\\]\n\\[ 1= \\frac{64k}{3} \\]\nHence \\(k=\\frac{3}{64}\\).\\[\\text{P}(1\\leq X \\leq 3) = \\int_{1}^{3} \\frac{3}{64}x^2 \\ dx\\]Evaluating numerically gives \\(0.406\\) \\(3\\) significant figures.Notice inequality \\(1<X<3\\) combination \\(<\\) \\(\\leq\\) calculation , need worry inequality strict continuous random variables.area single \\(x\\) value zero width, contribute integral.","code":""},{"path":"cont.html","id":"expectation-and-variance","chapter":"5 Continuous random variables","heading":"5.4 Expectation and variance","text":"expectation defined similarly case discrete random variables, use integral rather sum.Definition 5.2  expectation, expected value mean value continuous random variable \\(X\\) given \\[ \\text{E}[X] = \\int_{-\\infty}^{\\infty}x f(x) \\ dx\\]\nlimits indicate integral smallest largest attainable values \\(X\\). mean value often denotes \\(\\text{E}[X] = \\mu\\).generally define\\[ \\text{E}[g(X)] = \\int_{-\\infty}^{\\infty}g(x) f(x) \\ dx\\]Definition 5.3  variance continuous random variable given \\[\\text{Var}[X] = \\text{E}[(X-\\mu)^2] = \\text{E}[X^2]-\\mu^2\\]\nstandard deviation \\(\\sigma\\) \\(X\\) square root variance. \\[\\sigma = \\sqrt{\\text{Var}[X]}\\]Example 5.4  (marathon times) times excess \\(2\\) hours taken complete marathon road race modelled continuous random variable \\(T\\) hours, \\(T\\) probability density function\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n    \\frac{4}{27}t^2(3-t), &  0< x < 3\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Find mean standard deviation times taken complete race.solutionFor mean\\[ \\text{E}[T] = \\int_{0}^{3} t\\times \\frac{4}{27}t^2(3-t) \\ dt\\]can evaluated (example numerically) \\(\\frac{9}{5}\\). can interpreted \\(1\\) hour \\(48\\) minutes excess \\(2\\) hours, mean time \\(3\\) hours \\(48\\) minutes.variance use \\(\\text{Var}[T]=\\text{E}[X^2]-\\text{E}[X]^2 = \\frac{18}{5} - (\\frac{9}{5})^2 =\\frac{9}{25}\\). interpretation \\(21.6\\) minutes variance, \\(\\sigma = \\sqrt{21.6} = 4.65\\) minutes (\\(3\\) s.f.) standard deviation","code":""},{"path":"cont.html","id":"mode","chapter":"5 Continuous random variables","heading":"5.5 Mode","text":"probability density function unique maximum value \\(X\\) maximum called mode. locate mode good idea draw sketch. Sometimes mode can deduced immediately. times one may need differentiate.Example 5.5  Deduce mode following cases\\[f(x) = \\frac{1}{8}x , 0\\leq x \\leq 4\\]\\[f(x) = \\frac{1}{8}x , 0\\leq x \\leq 4\\]\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n \\frac{1}{4}x, &  0< x \\leq 2 \\\\\n 1-\\frac{1}{4}x & \\ \\  2< x \\leq 4 \\\\\n 0& \\ \\ \\ \\ \\  \\ \\ \\text{otherwise}\n  \\end{cases}\n\\end{equation*}\\]\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n \\frac{1}{4}x, &  0< x \\leq 2 \\\\\n 1-\\frac{1}{4}x & \\ \\  2< x \\leq 4 \\\\\n 0& \\ \\ \\ \\ \\  \\ \\ \\text{otherwise}\n  \\end{cases}\n\\end{equation*}\\]\\[f(x) = \\frac{3}{80}(2+x)(4-x) , \\ \\  0\\leq x \\leq 4.\\]\\[f(x) = \\frac{3}{80}(2+x)(4-x) , \\ \\  0\\leq x \\leq 4.\\]solutionmode 4mode 4mode 2mode 2One differentiate complete square show mode \\(1\\).One differentiate complete square show mode \\(1\\).Example 5.6  (marathon times) times excess \\(2\\) hours taken complete marathon road race modelled continuous random variable \\(T\\) hours, \\(T\\) probability density function\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n    \\frac{4}{27}t^2(3-t), &  0< t < 3\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Find modal time taken complete race.solutionDifferentiating gives\\[f'(t) = \\frac{4}{27}(2t \\times(3-t) + t^2\\times(-1)) = \\frac{4}{27}(6t -3t^2)\\]Setting \\(f'(t)=0\\) yields\\[0 = 3t(2 - t) \\]\neither\\(t=0\\) \\(2\\). modal excess \\(2\\) hours, modal total time \\(2+2=4\\) hours.","code":""},{"path":"cont.html","id":"cdf","chapter":"5 Continuous random variables","heading":"5.6 CDF","text":"cumulative distribution function can defined similar way discrete random variables.Definition 5.4  distribution function simply CDF continuous random variable function defined \\[F(x) = \\text{P}(X\\leq x) = \\text{P}(X< x).\\]function \\(F\\) related density via\\[F(x) = \\int_{-\\infty}^{x}f(u) \\ du\\]\nlower limit \\(-\\infty\\) practice lowest attainable value \\(X\\).hand,\\[ f(x) = \\frac{d}{dx} F(x)\\]facts CDF.Since always impossible value smaller \\(-\\infty\\) larger \\(\\infty\\) \\(F(-\\infty)=0\\) \\(F(\\infty)=1\\)Since always impossible value smaller \\(-\\infty\\) larger \\(\\infty\\) \\(F(-\\infty)=0\\) \\(F(\\infty)=1\\)\\(F\\) called monotonically increasing means either increases remains constant never decreases.\\(F\\) called monotonically increasing means either increases remains constant never decreases.\\(F\\) continuous function, even \\(f\\) .\\(F\\) continuous function, even \\(f\\) .Useful relations \n\\[\\text{P}(c<X<d) = F(d) - F(c)\\]Useful relations \n\\[\\text{P}(c<X<d) = F(d) - F(c)\\]\\[ \\text{P}(X>x) = 1-F(x)\\]Example 5.7  continuous random variable \\(X\\) density\\[f(x) = \\frac{1}{8}x, \\ 0\\leq x\\leq 4\\]\n) Find distribution function \\(F(x)\\) sketch .Evaluate \\(\\text{P}(0.3\\leq X\\leq 1.8)\\)solutionFor values \\(0\\) \\(4\\) \\[F(t) = \\int_{0}^{t} \\frac{1}{8}x \\ dx = \\left[ \\frac{x^2}{16}\\right]^{t}_{0}= \\frac{t^2}{16}\\]Altogether\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n        0 \\ \\ \\ \\ x\\leq 0 \\\\\n        \\frac{x^2}{16} \\ \\ \\   0\\leq x \\leq 4\\\\\n        1 \\ \\ \\ \\ x\\geq 4\n  \\end{cases}\n\\end{equation*}\\]Example 5.8  continuous random variable \\(X\\) density\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        \\frac{x}{3} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\leq x\\leq 2  \\\\\n        -\\frac{2}{3}x+2 \\ \\ \\   2\\leq x \\leq 3\\\\\n        0 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\text{otherwise}\n  \\end{cases}\n\\end{equation*}\\]Find CDF F(x) sketch .solutionThe CDF must found two stages \\(f\\) piecewise function.Integrating interval \\(0\\leq x\\leq 2\\) gives \\(\\frac{x^2}{6}\\)Integrating interval \\(2\\leq x \\leq 3\\), adding integral previous interval, gives \\(-\\frac{x^2}{3} +2x -2\\)Altogether\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n        \\frac{x^2}{6} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\leq x\\leq 2  \\\\\n        -\\frac{x^2}{3} +2x -2 \\ \\ \\   2\\leq x \\leq 3\\\\\n        1 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\  \\ \\ \\ x\\geq 3\n  \\end{cases}\n\\end{equation*}\\]Generally speaking plot sketch \\(F\\) look vaguely S-shaped.\nFigure 5.4: cumulative distribution function S shaped\ndiscrete random variables sometimes called \\(f\\) distribution function called \\(F\\) cumulative distribution function. However continuous random variables \\(f\\) never called distribution function, called density function, \\(F\\) called distribution function exclusively.","code":""},{"path":"cont.html","id":"median-quartiles-and-percentiles","chapter":"5 Continuous random variables","heading":"5.7 median, quartiles and percentiles","text":"median, quartiles percentiles best expressed terms CDF.median value \\(50\\%\\) way distribution. splits area curve \\(y=f(x)\\) two halves.Definition 5.5  median continuous random variable \\(X\\) value \\(m\\) satisfies either \\[F(m) = 0.5 , \\ \\ \\ \\ \\int_{-\\infty}^{m}f(x) \\ dx = 0.5\\]Definition 5.6  lower quartile \\(Q_1\\) satisfies \\(F(Q_1) = 0.25\\).\nupper quartile \\(Q_3\\) satisfies \\(F(Q_3) = 0.75\\).\nmedian second quartile \\(m=Q_2\\).Definition 5.7  generally one may define percentile \\(P_{\\alpha}\\) \\(\\alpha \\%\\) value \\(F(P_{\\alpha})= \\alpha \\%\\). median \\(50^{\\text{th}}\\) percentile \\(m = P_{50}\\), \\(Q_1 = P_{25}\\), \\(Q_3 = P_{75}\\)Definition 5.8  generally still quantile value \\(q\\) \\(F(q)=p\\) \\(p\\(0,1)\\)Example 5.9  Let’s find median marathon example.\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n    \\frac{4}{27}t^2(3-t), &  0< t < 3\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]First find CDF.range \\(0< t < 3\\)\n\\[F(t) = \\frac{4}{27}\\int_{0}^{t} u^2(3-u) \\ du\\]\\[= \\frac{4}{27}\\left[\\frac{3u^3}{3}-\\frac{u^4}{4}\\right]^{t}_{0} =\\frac{4}{27}\\left( t^3 - \\frac{t^4}{4} \\right)\\]solving \\(F(t)=0.5\\),\\[\\frac{4}{27}\\left(t^3 - \\frac{t^4}{4} \\right)= 0.5\\]\ncan evaluated numerically two values \\(t=3.74\\) \\(t= 1.84\\) first one outside range \\(0< t < 3\\) discarded. median time \\(2+1.84 = 3.84\\) hours complete marathon. just mean.marathon example shows mode, median mean number usually. mode \\(4\\), median \\(3.84\\) mean \\(3.8\\) hours.","code":""},{"path":"cont.html","id":"uniform-distribution","chapter":"5 Continuous random variables","heading":"5.8 Uniform distribution","text":"encountered uniform random variable example forgetful student. characteristic entire domain values \\(X\\) density constant.density constant interval, means \\(f(x) = k\\) \\(\\leq x \\leq b\\). value \\(k\\)?Definition 5.9  continuous random variable follows continuous uniform distribution (sometimes called rectangular) support \\([,b]\\), denoted \\(X\\sim U(,b)\\) probability density function given \\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{b-}, &  < x < b\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]uniform distribution symmetrical mean equal median, mode .Theorem 5.1  continuous uniform distribution \\(X\\sim U(,b)\\)\\[\\text{E}[X] = \\frac{+b}{2}\\]\\[\\text{Var}[X]= \\frac{(b-)^2}{12}\\]Proof. \\[\\text{E}[X] = \\int_a^b x \\times \\frac{1}{b-} dx  =\\frac{1}{b-} \\left[ \\frac{x^2}{2} \\right]^{b}_{}\\]Now\\[= \\frac{1}{b-} \\left( \\frac{b^2-^2}{2} \\right)\\]\nusing difference two squares\\[= \\frac{1}{b-} \\left( \\frac{(b-)(b+)}{2} \\right)\\]\nHence result, upon cancelling \\((b-)\\).variance consider\\[\\text{E}[X^2] = \\int_a^b x^2 \\times \\frac{1}{b-} dx  =\\frac{1}{b-} \\left[ \\frac{x^3}{3} \\right]^{b}_{}\\]\\[= \\frac{1}{b-} \\left( \\frac{b^3-^3}{3} \\right)\\]using difference cubes\\[= \\frac{1}{b-} \\left( \\frac{(b-)(b^2+ab+^2)}{3} \\right)\\]Hence \\(\\text{E}[X^2] = \\frac{b^2+ab+^2}{3}\\).Now\\[\\text{Var}[X] = \\text{E}[X^2] - \\text{E}[X]^2 = \\frac{b^2+ab+^2}{3} - \\left(\\frac{+b}{2} \\right)^2\\]\\[ = \\frac{4(b^2+ab+^2)- 3(^2 + 2ab +b^2)}{12}\\]\n\\[= \\frac{^2-2ab +b^2}{12}\\]\nHence result factorising numerator.CDF continuous uniform distribution can also found.Proposition 5.1  CDF continuous uniform distribution \\(X\\sim U(,b)\\) form\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n        0 & x \\leq \\\\\n    \\frac{x-}{b-}, &  < x < b\\\\\n    1 & \\ \\ x \\geq b.\n  \\end{cases}\n\\end{equation*}\\]proofFind equation line \\((,0)\\) \\((b,1)\\).","code":""},{"path":"cont.html","id":"exponential-distribution","chapter":"5 Continuous random variables","heading":"5.9 Exponential distribution","text":"exponential distribution like continuous version geometric distribution. Instead counting many attempts event happens, instead measure time event occurs ordinarily occur rate.Consider sequence independent events occuring random points time rate \\(\\lambda\\). learned last week number events occur modelled discrete random variable called Poisson distribution.Instead counting many events occur, consider measuring long wait next event.set starting time \\(x=0\\) denote random variable ‘time first event’ \\(X\\).\\[\\text{P}(X>x) = \\text{P}( \\{\\text{events occur time interval (0,x)}\\})\\]mean number events occur per unit interval \\(\\lambda\\). number events occur interval \\((0,x)\\) length \\(x-0 = x\\) scaled proportionally equals \\(\\lambda \\times x\\).probability obtaining \\(0\\) events Poisson distribution mean \\(\\lambda x\\) \\[\\frac{(\\lambda x)^0 e^{-\\lambda x}}{0!} = e^{-\\lambda x}\\]\n\\[\\text{P}(X>x) =  e^{-\\lambda x}\\]\ncumulative distribution equals\\[F(x) = 1-\\text{P(X>x)}=1-e^{-\\lambda x}\\]Differentiating respect \\(x\\) obtain\\[f(x) = \\lambda e^{-\\lambda x}\\]Definition 5.10  continuous random variable \\(X\\) said exponential distribution, denoted \\(X\\sim \\text{Exp}(\\lambda)\\) density function\\[f(x) = \\lambda e^{-\\lambda x} , x >0\\]Now consider shape exponential distribution.Theorem 5.2  exponential distribution \\(X\\sim \\text{Exp}(\\lambda)\\), \\[\\text{E}[X] = \\frac{1}{\\lambda}\\]\n\\[\\text{Var}[X] = \\frac{1}{\\lambda ^2}\\]Proof. can verified using integration.","code":""},{"path":"cont.html","id":"exercises-week-5","chapter":"5 Continuous random variables","heading":"5.10 Exercises week 5","text":"Exercise 5.1  random variable \\(Y\\) density function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        ky & 0 \\leq y \\leq 4 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show \\(k = \\frac{1}{8}\\) makes valid density functionShow \\(k = \\frac{1}{8}\\) makes valid density functionFind cumulative distribution function \\(F(y)\\)Find cumulative distribution function \\(F(y)\\)Sketch density \\(f\\) \\(F\\) axesSketch density \\(f\\) \\(F\\) axesCalculate \\(\\text{P}(1\\leq Y \\leq 3)\\) two ways, one \\(f\\) one \\(F\\).Calculate \\(\\text{P}(1\\leq Y \\leq 3)\\) two ways, one \\(f\\) one \\(F\\).Calculate mean \\(\\text{E}[Y]\\) variance \\(\\text{Var}[Y]\\) \\(Y\\).Calculate mean \\(\\text{E}[Y]\\) variance \\(\\text{Var}[Y]\\) \\(Y\\).Exercise 5.2  length time minutes serve customer fast food restaurant random variable \\(T\\) density\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n        k(3t^2 + t) & 0 \\leq t \\leq 2 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show \\(k = \\frac{1}{10}\\) makes valid density functionShow \\(k = \\frac{1}{10}\\) makes valid density functionFind cumulative distribution function \\(F(t)\\)Find cumulative distribution function \\(F(t)\\)Sketch density \\(f\\) distribution \\(F\\).Sketch density \\(f\\) distribution \\(F\\).Use graph \\(F\\) find median.Use graph \\(F\\) find median.Calculate probability time serve customer one minute less.Calculate probability time serve customer one minute less.Calculate mean \\(\\text{E}[T]\\) variance \\(\\text{Var}[T]\\) serving times.Calculate mean \\(\\text{E}[T]\\) variance \\(\\text{Var}[T]\\) serving times.Exercise 5.3  Suppose profit certain contractor make one job, thousands pounds, random variable \\(X\\) density function given \\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        c(4x -x^3) & 0 \\leq x \\leq 2 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show \\(k =\\frac{1}{4}\\) makes valid density functionShow \\(k =\\frac{1}{4}\\) makes valid density functionFind expected profit variance profit per contract.Find expected profit variance profit per contract.Find cumulative distribution function \\(F(x)\\) hence median profit level.Find cumulative distribution function \\(F(x)\\) hence median profit level.probability contractor makes profit less £\\(600\\) contract?probability contractor makes profit less £\\(600\\) contract?Assuming profit levels contract independent, probability profit level less £\\(600\\) \n) next \\(10\\) jobs?\nii) exactly \\(4\\) next \\(10\\) jobs?Assuming profit levels contract independent, probability profit level less £\\(600\\) \n) next \\(10\\) jobs?\nii) exactly \\(4\\) next \\(10\\) jobs?(Hint: part (e) use answer (d) appropriate binomial distribution)Exercise 5.4  lifetime mobile phone batters (hundreds hours) random variable \\(X\\) density function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        2xe^{-x^2} &  x \\geq 0 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show valid density function (integrate substitution)Show valid density function (integrate substitution)Find cumulative distribution function.Find cumulative distribution function.Find median lifetime batteryFind median lifetime batteryEvaluate \\(\\text{P}(X\\geq 2)\\)Evaluate \\(\\text{P}(X\\geq 2)\\)Exercise 5.5  Bacteria grow Petri dish circular disk. radius circle \\(R\\) can modelled uniform distribution interval \\(1\\) \\(3\\) cm.Write density distribution functions \\(R\\)Write density distribution functions \\(R\\)Work expected value R variance \\(R\\).Work expected value R variance \\(R\\).area circle random variable \\(\\), determine distribution function \\(\\).\n(Start considering \\(\\text{P}(\\leq )\\) means terms \\(R\\).)area circle random variable \\(\\), determine distribution function \\(\\).\n(Start considering \\(\\text{P}(\\leq )\\) means terms \\(R\\).)Determine density function \\(\\).Determine density function \\(\\).Calculate expected value area \\(\\).Calculate expected value area \\(\\).","code":""},{"path":"cont.html","id":"exercises-for-feedback-week-5","chapter":"5 Continuous random variables","heading":"5.10.1 Exercises for feedback week 5","text":"archer continues shoot target hits bullseye.Give reason may possible model X geometric\ndistribution.archer shoots target around \\(100\\) times \\(5\\%\\) shots hit bullseye.\nSuppose \\(X \\sim Geom(p)\\) \\(p =5\\%\\).Calculate probability shoots target least ten attempts.Calculate probability shoots target least ten attempts.Give reason geometric distribution may appropriate , improve model.Give reason geometric distribution may appropriate , improve model.continuous random variable \\(X\\) density function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        kx(1-x^2) & 0\\leq x \\leq 1 \\\\\n        0 , &  \\text{   otherwise}\\\\\n  \\end{cases}\n\\end{equation*}\\]Find value constant \\(k\\)Find value constant \\(k\\)Calculate mean variance \\(X\\).Calculate mean variance \\(X\\).Find expression cumulative distribution \\(F_X(x)\\) sketch function.Find expression cumulative distribution \\(F_X(x)\\) sketch function.Hence otherwise calculate \\(\\text{P}(X\\leq \\frac{1}{3})\\).Hence otherwise calculate \\(\\text{P}(X\\leq \\frac{1}{3})\\).(counting practice)box contains \\(12\\) golf balls, \\(3\\) substandard. random sample \\(4\\) balls selected, without replacement, box. random variable \\(R\\) denotes number balls sample substandard.Show probability mass function \\(R\\) satisfies\\[\\text{P}(R=r) = \\frac{{}^3C_r \\times {}^9C_{4-r}}{^{12}C_{4}}\\](hint: count number choices total number ways. may find helpful cases \\(r=0,1,2,3\\) separately.)Determine probability \\(R=0\\)Determine probability \\(R=0\\)Determine probability fewer two substandard balls.Determine probability fewer two substandard balls.","code":""}]
