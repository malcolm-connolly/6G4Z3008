[{"path":"index.html","id":"intro","chapter":"1 Introduction to Probability","heading":"1 Introduction to Probability","text":"things happen entirely predictable. example, one drops ball height, know hit ground. Things happen like can decribed deterministic. may heard people talk things written stars, fate, destiny. opinion things pre-determined called determinism.However, even determinist, live uncertainty. everyday lives can think examples things happen predict; bus may late, may rain, one might win lottery. one living uncertainty, reasonable quantify uncertainty act assuming outcomes pre-determined. outcome pre-determined called random.Mathematics random phenomena called Probability Theory. people intuitive idea meant probability chance. Unfortunately Probability Theory subject endless examples seemingly simple questions turn complicated severely counter-intuitive answers.","code":""},{"path":"index.html","id":"frequentist-perspective","chapter":"1 Introduction to Probability","heading":"1.1 Frequentist perspective","text":"need start terminology.Definition 1.1  experiment procedure happens random least two different outcomes. example rolling die observing score statistical experiment. experiment repeatable repetition called run.calculating number times event occurs divided number runs one can estimate theoretical probability. idea relative cumulative frequency outcomes tend actual probability long run. perspective probability called Frequentist, incredibly useful practice.\nFigure 1.1: result simulating rolling die 6000 times, counting many times 6 occures. cumulative relative frequency tends theoretical 1/6 (red).\nrecreate plot like labs.Example 1.1  Suppose toss \\(10\\) coins \\(10\\) times results recorded table , draw graph relative frequency.cumulative relative frequencies calculated cumulative number flips divided cumulative number heads:course learn R programming. R free open-source software language suitable many probability statistical calculations. following R code make list two outcomes Heads Tails create sample \\(10\\) random outcomes.Definition 1.2  statistical experiment \\(n\\) runs, outcome \\(\\) happens cumulative number times depending \\(n\\) can call \\(a_n\\), frequentist probability outcome \\(\\), written \\(P()\\), limit:\\[P() = \\lim_{n\\\\infty} \\frac{a_n}{n}\\]possible repeatedly run experiment, frequentist methods useful finding approximation true theoretical probability.simple, consider following questions. probability life planets? probability Conservatives win next general election?events like flipping coin, possible find frequentist interpretation probability.","code":"\noutcomes <- c(\"Heads\",\"Tails\")\nsample(outcomes, 10, replace=TRUE)##  [1] \"Heads\" \"Tails\" \"Heads\" \"Heads\" \"Tails\" \"Tails\" \"Tails\" \"Heads\" \"Heads\"\n## [10] \"Heads\""},{"path":"index.html","id":"naive-probability","chapter":"1 Introduction to Probability","heading":"1.2 Naive probability","text":"may time resources many thousands runs. Therefore also need able evaluate theoretical probability directly exactly.Definition 1.3  sample space set whose elements outcomes experiment. sample space denoted greek letter \\(\\Omega\\).Example 1.2  pick person random street ask month birthday,\ncan let\n\\[\\Omega = \\{\\text{Jan}, \\ \\text{Feb}, \\ \\text{Mar},  \\ \\text{Apr}, \\ \\text{May}, \\ \\text{Jun}, \\ \\text{Jul}, \\ \\text{Aug}, \\ \\text{Sep}, \\ \\text{Oct}, \\ \\text{Nov}, \\ \\text{Dec} \\}.\\]Definition 1.4  event subset sample space \\(\\Omega\\).Example 1.3  example 1.2, let \\(\\text{L}\\) event month long month (.e. 31 days). \n\\[\\text{L} = \\{\\text{Jan}, \\ \\text{Mar}, \\ \\text{May},  \\ \\text{Jul}, \\ \\text{Aug},  \\ \\text{Oct}, \\ \\text{Dec} \\}.\\]Let \\(R\\) event letter r name month written fully. ,\\[\\text{R} = \\{\\text{Jan}, \\ \\text{Feb}, \\ \\text{Mar}, \\ \\text{Apr},  \\ \\text{Sep}, \\ \\text{Oct}, \\ \\text{Nov}, \\  \\text{Dec} \\}\\]Definition 1.5  Naively probability event \\(\\) number elements set \\(\\) divided size sample space \\(\\Omega\\).,\\(\\text{P} () = \\frac{||}{|\\Omega|}\\).example 1.3 :\\[\\text{P}(R) = \\frac{|R|}{|\\Omega|} = \\frac{8}{12} = \\frac{2}{3},\\],\\[\\text{P}(L) = \\frac{|L|}{|\\Omega|} =\\frac{7}{12}.\\]Example 1.4  (Coin Tossing) Toss fair coin twice record possible outcomes. Let\n\\[= \\{\\text{exactly one coin Heads}\\}\\]\n\n\\[B = \\{\\text{neither coin Heads}\\}\\]sample space \\(\\Omega = \\{HH, HT, TH, TT\\}\\).Events \\(\\) \\(B\\) correspond :\\[= \\{HT, TH\\}\\]\n\n\\[B = \\{ TT \\}\\]\nHence \\(\\text{P}() = \\frac{2}{4} = \\frac{1}{2}\\), \\(\\text{P}(B)=\\frac{1}{4}\\).Example 1.5  (Two dice) Two dice thrown, probability total number dots :equal \\(7\\)equal \\(3\\)greater \\(5\\)even numbersolutionThe sample space \\(\\Omega = \\{ (n_1,n_2) : n_1 , n_2 \\\\{1,2,3,4,5,6 \\} \\}\\). However, sums equally likely, best seen table.\\(\\frac{6}{36}\\)\\(\\frac{2}{36}\\)\\(\\frac{26}{36}\\)\\(\\frac{18}{36}\\)infinite sets problem naive definition 1.5. Consider following:Example 1.6  Suppose random unit vector rotated origin anticlockwise, making angle \\(\\theta\\) positive \\(x\\)-axis. probability angle acute?continuum infinitely many angles. naive definition says \\(\\frac{\\infty}{\\infty}\\), absurd.Intuitively, answer \\(\\frac{1}{4}\\).","code":""},{"path":"index.html","id":"complements-and-mutual-exclusivity","chapter":"1 Introduction to Probability","heading":"1.3 Complements and mutual exclusivity","text":"case, events subsets sample space \\(\\Omega\\) follow rules set theory, important know set notation, definitions results. recap important definitions.Definition 1.6  union \\(\\) \\(B\\) written:\\[\\cup B = \\{ x \\\\Omega :  x \\\\ \\text{} \\ x\\B \\}.\\]\nMathematics inclusive, means need say ``’’ included union.Definition 1.7  intersection \\(\\) \\(B\\) written:\n\\[\\cap B = \\{ x \\\\Omega:  x \\\\ \\text{} \\ x\\B \\}.\\]Definition 1.8  empty set \\(\\varnothing\\) set elements. sets \\(\\) \\(B\\) called disjoint elements common, ,\\(\\cap B = \\varnothing.\\)Probability Theory disjoint events called mutually exclusive.Definition 1.9  complement event \\(\\) event \\(^{c} = \\{x \\\\Omega : x\\notin \\}.\\)\nNote \\(\\cap ^{c} = \\varnothing\\). words means: event mutually exclusive complement.Example 1.7  Suppose event throwing die. event one throws even number. complement one throws odd number.Example 1.8  Suppose event random student siblings. complement one sibling. complement least one sibling.theorem prove De Morgan’s lawsTheorem 1.1  (DE MORGAN'S LAWS) complement union intersection complements:\n\\[(\\cup B)^{c} = ^{c} \\cap B^{c}\\]complement intersection union complements:\n\\[(\\cap B)^{c} = ^{c} \\cup B^{c}\\]way \\(P\\) `measure’ function maps subsets sample space interval \\(\\left[0,1\\right]\\).Definition 1.10  Probability function whose input subset sample space \\(\\subseteq \\Omega\\) whose range interval \\(\\left[0,1\\right]\\), following two axioms hold:probability whole set possible events unity. notation: \\(\\text{P}(\\Omega ) =1\\).probability whole set possible events unity. notation: \\(\\text{P}(\\Omega ) =1\\).(additivity) collection disjoint events \\(A_1 , A_2, A_3, \\dots\\) probability union sum probabilities. notation can written \\[\\text{P}(A_1 \\cup A_2 \\cup \\dots ) = \\text{P}(A_1) + \\text{P}(A_2)+\\dots .\\](additivity) collection disjoint events \\(A_1 , A_2, A_3, \\dots\\) probability union sum probabilities. notation can written \\[\\text{P}(A_1 \\cup A_2 \\cup \\dots ) = \\text{P}(A_1) + \\text{P}(A_2)+\\dots .\\]definition 1.10 due Russian Mathematician Kolmogorov. axioms help make sense infinite case.Using definition can prove following important results.Proposition 1.1  (PROBABILITY COMPLEMENT) event \\(\\) :\n\\[\\text{P}(^{c}) = 1 - \\text{P}().\\]Proof. Write \\(\\Omega = \\cup ^{c}\\), disjoint union. additivity,\n\\[\\text{P}(\\Omega) = \\text{P}() + \\text{P}(^{c}) \\]\nNow axiom () LHS \\(1\\).Theorem 1.2  (PROBABILITY UNION) Given two events \\(\\) \\(B\\) :\\[\\text{P}(\\cup B) = \\text{P}() + \\text{P}(B) - \\text{P}(\\cap B)\\]Proof. idea write \\(\\) disjoint union part intersection \\(B\\), : \\(=(\\cap B)\\cup(\\cap B^{c})\\). Hence,\\[\\text{P}() = \\text{P}(\\cap B) + \\text{P}(\\cap B^{c})\\]split \\(\\cup B\\) way, obtain \\((\\cup B)\\cap B\\) \\((\\cup B)\\cap B^{c}\\). former simply \\(B\\), latter \\(\\cap B^{c}\\). additivity,\\[\\text{P}(\\cup B) = P(B) + P(\\cap B^{c}).\\]\nEliminating \\(P(\\cap B^{c})\\) two equations proves rule.proving Theorems course, neither ask recount proof exam. however know use results applied problems.Example 1.9  (Multiple Choice) Suppose multiple choice test consists three questions two options, correct answer (C) wrong answer (W). probability student always randomly guesses answers gets least one correct?\\[\\begin{align}\n\\text{P(least one correct)} &= 1 - \\text{P(wrong)} \\\\\n&= 1- \\frac{1}{8}  \\\\\n&=\\frac{7}{8}\n\\end{align}\\]Example 1.10  (Mode travel) table shows type journey undertaken sample commuters classified live.individual selected random group, find probability , travel car live townsolution\\(\\text{P}(\\text{Car}\\cup \\text{Town}) = \\frac{25+40+30}{100}=0.95\\)\\(\\text{P}(\\text{Car})+ \\text{P}(\\text{Town})-\\text{P}(\\text{Car}\\cap \\text{Town})= \\frac{65}{100}+\\frac{70}{100}-\\frac{40}{100} =0.95\\)Example 1.11  particular city \\(60\\%\\) people watch news morning, \\(50\\%\\) people watch news evening \\(30\\%\\) watch . probability individual selected random watches either morning news evening news.solution\\(\\text{P}(M\\cup E) = 0.6 + 0.5 - 0.3 = 0.8\\)","code":""},{"path":"index.html","id":"outcomes-and-counting","chapter":"1 Introduction to Probability","heading":"1.4 Outcomes and counting","text":"One might imagine finite situation simple, even seen full picture. One simply counts many ways event can happen total number configurations. can actually quite complicated. learn formulae enable us count .","code":""},{"path":"index.html","id":"factorials","chapter":"1 Introduction to Probability","heading":"1.4.1 Factorials","text":"Example 1.12  (Three people line) many ways can three people \\(\\), \\(B\\) \\(C\\) stand line?solution\\(ABC, ACB, BAC, BCA, CAB,CBA\\) \\(6\\).Definition 1.11  non-negative integer, \\(n\\) say, define factorial \\(n\\), written \\(n!\\) equal product \\(n\\) numbers less \\(n\\) \\(1\\). ,\\[n! = n \\times (n-1) \\times (n-2) \\times \\dots 3 \\times 2 \\times 1\\]Definition 1.12  (Multiplication Rule) \\(n\\) ways operation happen, \\(m\\) ways something else happen, total number ways sequence occur \\(n \\times m\\).Example 1.13  MMU assigns student \\(8\\) digit ID number. many possible ID numbers ?solution\nfirst digit zero, \\(9\\) digits choose.\ndigits \\(10\\) choices \\(0,1,2,3,4,5,6,7,8,9\\).Total = \\(9 \\times 10^7\\).Example 1.14  (objects line) number ways arranging \\(n\\) distinct objects line \\(n!\\).\n\\(n\\) choices first number line, one fewer choice \\((n-1)\\) second, , last one line one choice remaining.Definition 1.13  (rule division) number ways arranging \\(n\\) objects line \\(p\\) \\(\\frac{n!}{p!}\\).Example 1.15  Suppose letters \\(,,,B\\) - many `words’ can made?Suppose letters \\(,,,B\\) - many `words’ can made?Suppose letters \\(,,,B,B\\) - many `words’ can made?Suppose letters \\(,,,B,B\\) - many `words’ can made?solution\n)\nAAAB, AABA, ABAA, BAAAThere 4. find number without write ?might think \\(4!\\) thinking different, overcounts word. factor overcount? Take one words ABAA number , one finds rearrangements 1,2,3:\\(A_1BA_2A_3, A_1BA_3A_2, A_2BA_1A_3, A_2BA_3A_1, A_3BA_1A_2, A_3BA_2A_1.\\)upshot need divide factorial number letters , \\(\\frac{4!}{3!} =4\\).\\(3\\) letter \\(\\), \\(2\\) letter \\(B\\). correct number \\[\\frac{5!}{3!\\times2!} = 10\\]words AAABB, AABBA, ABBAA, BBAAA, BABAA, ABABA, AABAB, BAABA, ABAAB, BAAAB. (can systematically list considering number ’s B’s).Definition 1.14  (rule sum) Given two disjoint events \\(\\) \\(B\\), size union sum sizes \\(\\) \\(B\\). ,\\[|\\cup B|=||+|B|\\]Example 1.16  many possible MMU IDs start \\(1\\) \\(3\\)?solutionThe IDs form 1******* 3*******. 1 choice first digit \\(10^7\\) choices next digits either case.total number starting \\(1\\times 10^7 + 1\\times 10^7 = 2\\times 10^7.\\)","code":""},{"path":"index.html","id":"permutations","chapter":"1 Introduction to Probability","heading":"1.4.2 Permutations","text":"Example 1.17  Consider number ways placing three letters \\(,B,C,D,E,F G\\) three empty spaces. first space can filled \\(7\\) ways, second \\(6\\) ways last \\(5\\) ways.total \\(7\\times 6\\times 5 = 120\\)number can written \n\\[\\frac{7\\times 6 \\times 5\\times 4\\times 3\\times 2\\times 1}{4\\times 3 \\times 2\\times 1}=\\frac{7!}{(7-3)!}\\]Definition 1.15  (Permutations) number ways choosing \\(k\\) distinct items \\(n\\) order relevant \n\\[^n\\text{P}_k = \\frac{n!}{(n-k)!}\\]\nway choosing \\(k\\) distinct items \\(n\\) order matters called permutation.Example 1.18  PIN \\(4\\) different digits. many different PINs ?solutionOrder matters - guess 1234 different 4321, example.\\[^{10}\\text{P}_4 = \\frac{10!}{(10-4)!} = \\frac{10\\times 9 \\times \\dots 2 \\times 1 }{6!} =10\\times 9 \\times 8 \\times 7 =5040\\]\nexpression \\(10\\times 9 \\times 8 \\times 7\\) can interpreted saying \\(10\\) choices first digit, \\(9\\) second, .Example 1.19  (Birthday Problem) Suppose \\(k\\) people room. probability least one birthday someone else room?solution\\[\\text{P}(\\text{least one birthday }) = 1 - \\text{P}(\\text{birthdays different})\\]first person born day \\(365\\) days, second person different birthday \\(364\\) \\(k^{th}\\) person.\\(\\text{P}(\\text{birthdays different}) = \\frac{^{365}\\text{P}_k}{365^k}\\)can evaluated computer different values \\(k\\).\\(k=23\\) one finds \\(\\text{P}(\\text{birthdays different}) = 0.493\\).implies \\(\\text{P}(\\text{least one birthday }) = 1- 0.493 > 0.5\\).greater evens chance two people birthday room \\(23\\) people.","code":""},{"path":"index.html","id":"combinations","chapter":"1 Introduction to Probability","heading":"1.4.3 Combinations","text":"Definition 1.16  (Combinations) number ways choosing \\(k\\) distinct items \\(n\\) order relevant :\\[{}^nC_k = \\frac{n!}{(n-k)!k!}\\]\nway choosing \\(k\\) distinct items \\(n\\) order matter called combination.Example 1.20  many ways can \\(4\\) cards dealt ordinary pack \\(52\\) playing cards?solutionSuppose one hand Ace spades, king clubs, three hearts Jack diamonds. matter card given first, hand matters play.`order matter’.number hands \\({}^{52}C_{4}=270725\\).Example 1.21  (National Lottery) main National Lottery draw, six numbers chosen \\(49\\).probability winning jackpot lottery (.e. \\(6\\) match)?probability winning jackpot lottery (.e. \\(6\\) match)?probability three winning numbers come lottery ticket?probability three winning numbers come lottery ticket?solutionsTotal number outcomes \\({}^{49}C_{6} = 13983816\\).probability \\(\\frac{1}{^{49}C_{6}}\\), \\(1\\) \\(14\\) million.three winning numbers can three six winning numbers \\(^6C_3\\) combinations. numbers ticket can three \\(43\\) losing numbers week. number ways choosing \\(^{43}C_3\\).Therefore probability three winning numbers \n\\[\\text{P}(\\text{three winning numbers}) = \\frac{^{43}C_3 \\times ^6C_3}{^{49}C_6} = 0.0177\\]\napproximately \\(1\\) \\(56\\).","code":""},{"path":"index.html","id":"exercises-week-1","chapter":"1 Introduction to Probability","heading":"1.5 Exercises Week 1","text":"","code":""},{"path":"index.html","id":"tutorial-exercises","chapter":"1 Introduction to Probability","heading":"1.5.1 Tutorial exercises","text":"Exercise 1.1  letter chosen random word STATISTICS.\n) probability vowel?\nb) complement event )?Exercise 1.2  Suppose eating restaurant two friends. agree pay bill follows. person tosses coin. person gets result different two pay bill. three tosses , bill shared equally. Find probability :pay billAll three share billDo think fair way split bill?Exercise 1.3  investment can either; increase value (), break even (B) make loss (L). Suppose outcome equally likely. two separate investments made,List sample space drawing tree diagram.List sample space drawing tree diagram.Find probability :Find probability :investments increase value.investments make loss.least one investments increases value.Suppose investments type company. might model unrealistic, improve ?big sample space three separate investments made?Exercise 1.4  set cards consists standard suits \\(\\clubsuit\\), \\(\\spadesuit\\), \\(\\diamondsuit\\), \\(\\heartsuit\\), \\(13\\) cards suit.\n) Suppose one card drawn random. Find probability :\n() Ace Hearts, \\(\\heartsuit\\)\n(ii) King Spades \\(K\\spadesuit\\).\n(iii) picture card.Suppose two cards drawn random, first replaced deck shuffled second drawn ( called sampling replacement). Find probability :cards King Hearts, \\(K\\heartsuit\\).cards Aces.Exercise 1.5  Fifty male fifty female students asked whether agreed statement “Statistics often misleading”. Seventy students, thirty male, agreed.\n) Summarise information two-way table.\nb) student selected random, find probability :\n() Agree\n(ii) female\n(iii) male\n(iv) male agree\n(v) female agreeExercise 1.6  Interviews \\(120\\) working people revealed \\(76\\) stressed, \\(20\\) managers \\(14\\) managers stressed.\n) Summarise information two-way table.\nb) Assuming individual drawn random, find probability thatthey \n() Stressed\n(ii) shopfloor worker\n(iii) manager stressed\n(iv) shopfloor worker stressed.Exercise 1.7  Evaluate ) \\(^5\\text{P}_3\\), b) \\(^7\\text{P}_4\\), c) \\(^6\\text{P}_4\\).Exercise 1.8  value \\(n\\) following equality true?\n\\[ ^{n+1}\\text{P}_3 = ^n\\text{P}_4 \\]Exercise 1.9  Three different Mathematics books \\(5\\) different statistics books arranged shelf. many ways can books arranged ,\n) books subject must stand together\nb) statistics books must stand togetherExercise 1.10  Four different Mathematics books, \\(5\\) different statistics books \\(3\\) different computing books arranged shelf. many ways can books arranged ,\n) books subject must stand together\nb) statistics books must stand togetherExercise 1.11  Evaluate ) \\(^7\\text{C}_6\\), b) \\(^5\\text{C}_3\\), c) \\(^9\\text{C}_5\\), \\(^9\\text{C}_4\\).Exercise 1.12  many different committees can formed \\(8\\) men \\(6\\) women committee consists :\n) \\(1\\) man \\(4\\) women\nb) \\(5\\) men \\(3\\) women\nc) \\(4\\) men \\(4\\) women\nd) equal number men women.Exercise 1.13  council consists \\(10\\) members, \\(6\\) Party X \\(4\\) Party \\(Y\\).\n) many ways can committee \\(4\\) formed?\nb) many ways can committee \\(4\\) formed :\n) Party X majority\nii) Party Y majority\niii) Neither party majorityExercise 1.14  Ten equally qualified assistant managersare lined promotion. Seven men three women. company promotes four ten random, probability exactly two four chosen women?Exercise 1.15  Suppose library bookshelf contains equal number, \\(n\\) say, Mathematics books Physics books. bookshelf emptied books placed back randomly, probability books subject separated?Exercise 1.16  miscellaneous questions permutations combinations:\n) group \\(20\\) employees, \\(4\\) chosen promotion. many ways can chosen?\nb) group \\(20\\) employees, \\(4\\) shosen promotion, different role. many ways can chosen?\nc) product code consists \\(4\\) letters followed \\(3\\) digits. many codes possible repetitions allowed?\nd) \\(7\\)-card hand dealt normal pack \\(52\\) cards. many hands contain \\(4\\) clubs \\(3\\) hearts?\ne) many ways can merit awards allocated group \\(15\\) students one first prize, one second prize \\(4\\) identical third prizes?\nf) Four students chosen group \\(10\\). exactly one first three students must chosen, many ways choosing four students?Exercise 1.17  game poker, five cards standard deck \\(52\\) cards dealt hand. Find probability hand contains,\n) royal flush (ace, king, queen, jack \\(10\\) suit)\nb) Four kind (e.g. four \\(5\\)s)\nc) Two pairs\nd) full house (.e. three one kind two another)\ne) One pairExercise 1.18  \\(\\text{P()}=0.6\\) \\(\\text{P(B)}=0.5\\), can B mutually exclusive?Exercise 1.19  medical records \\(100\\) male diabetic patients reported clinic family history diabetes (Yes ), together symptoms either mild severe. provided following classification.Suppose patient chosen random clinic events , B C defines follows:: severe diseaseB : \\(40\\)C : parents diabeticFind probabilities P(), P(B), P(\\(\\cap\\)B), P(B\\(\\cap\\)C), P(\\(\\cap\\)B\\(\\cap\\)C).Find probabilities P(), P(B), P(\\(\\cap\\)B), P(B\\(\\cap\\)C), P(\\(\\cap\\)B\\(\\cap\\)C).Describe following events words calculate : \\(^c\\cap\\)B\\(^c\\), \\(^c\\cup\\)C\\(^c\\), \\(^c\\cap\\)B\\(^c\\cap\\)C\\(^c\\).Describe following events words calculate : \\(^c\\cap\\)B\\(^c\\), \\(^c\\cup\\)C\\(^c\\), \\(^c\\cap\\)B\\(^c\\cap\\)C\\(^c\\).","code":""},{"path":"index.html","id":"exercises-for-feedback","chapter":"1 Introduction to Probability","heading":"1.5.2 Exercises for feedback","text":"remember phone number. contains following digits something like \\(132 \\ 747 \\ 6965\\).probability first number even?probability first number even?many ways can numbers rearranged?many ways can numbers rearranged?many ways can number rearranged start end odd number?many ways can number rearranged start end odd number?Suppose certain numbers blocks \\(132\\),\\(747\\) \\(6965\\), sure order within block.many ways can numbers rearranged numbers within block ?many ways can numbers rearranged numbers within block ?probability wrote correct number originally?probability wrote correct number originally?lottery, \\(6\\) numbers drawn numbers \\(1\\) \\(49\\). Calculate following probabilities.numbers \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\), \\(6\\) drawn.numbers \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\), \\(6\\) drawn.numbers \\(4\\), \\(23\\), \\(24\\), \\(35\\), \\(40\\), \\(45\\) drawn.numbers \\(4\\), \\(23\\), \\(24\\), \\(35\\), \\(40\\), \\(45\\) drawn.\\(44\\) one numbers drawn.\\(44\\) one numbers drawn.Three dice rolled. sum numbers dice score.Describe sample space.Describe sample space.many ways score equal \\(5\\)?many ways score equal \\(5\\)?likely score?likely score?Suppose finite set \\(S\\) size \\(n\\).\n(Hint: question general, check answers concrete example S = { ,b,c,d })many subsets \\(S\\)?many subsets \\(S\\)?many subsets S size \\(1\\)?many subsets S size \\(1\\)?many subsets S size \\(k\\), \\(1\\leq k\\leq n\\)many subsets S size \\(k\\), \\(1\\leq k\\leq n\\)Using ) c), describe words following equality holds.Using ) c), describe words following equality holds.\\[2^n = \\sum_{k=0}^n {^n}C_k\\]Five office workers write names piece paper, fold paper put hat. names mixed person selects piece paper hat. everyone selected piece paper hat, staff look names drawn. probability member staff selected name?","code":""},{"path":"cond.html","id":"cond","chapter":"2 Conditional Probability","heading":"2 Conditional Probability","text":"chapter learn conditional probability. probability event, context another event happened potentially happening.","code":""},{"path":"cond.html","id":"independence","chapter":"2 Conditional Probability","heading":"2.1 Independence","text":"Independence important concept Statistics, one sometimes misused assumed without justification. basic idea follows:Definition 2.1  (Independence) Two events \\(\\text{}\\) \\(\\text{B}\\) independent exactly \n\\[\\text{P}(\\text{}\\cap\\text{B}) = \\text{P}(\\text{})\\times \\text{P}(\\text{B}).\\]\nwords means probability \\(\\text{}\\) \\(\\text{B}\\) happen product individual probabilities \\(\\text{}\\) \\(\\text{B}\\) respectively.Example 2.1  events can modelled independent include:\n- Outcomes successive tosses coin die. happened previous throw affect happens subsequent throws.sex babies. sex baby determined random, notwithstanding sexes previous babies.Example 2.2  Suppose power plant two safety systems, primary system works probability \\(0.999\\), backup system works probability \\(0.89\\) Assuming two systems operate independently, reliability safety power plant.solutionWe can work \\(\\text{P}(\\text{plant safe})\\) using complement:\\[\\text{P}(\\text{plant safe}) = 1-\\text{P}(\\text{plant fails}).\\]Let \\(F\\) event plant fails, \\(F_1\\) event first system fails, \\(F_2\\) backup fails.\\(F = F_1 \\cap F_2\\).\\[\\begin{align}\n\\text{P}(F) &= \\text{P}(F_1 \\cap F_2) \\\\\n&= \\text{P}(F_1) \\times \\text{P}(F_2) \\\\\n&= (1-0.999)\\times (1-0.89) \\\\\n&= 0.00011\n\\end{align}\\]\\(1-0.00011 = 0.99989\\).Calculations often used arrive unrealistic figures safety complex operating processes, e.g. nuclear power plants. example, ’s easy check three backup systems reliability \\(0.99\\), probability failure assuming independence \\(1\\times 10^{-6}\\) - reassuringly small figure! However can make calculations can justify assumption independence. example ’s unusual find backup systems used often can unreliable supposed actually called upon.might give reason particular context good example assume independence. example exercise 1.3 part (c) asks two investments may independent. many reasonable answers. Similar companies dependent - companies bakeries, may affected price wheat. companies may competitors, case one company better may cause worse.Example 2.3  Suppose toss ten coins coin many Heads. throw simultaneously. throw one time, order. matter?solutionNo, independent coins. Let\n\\[A_i =\\{\\text{} \\ ^{\\text{th}} \\ \\text{coin Heads} \\}\\]probability simultaneously Heads product probabilities individual coin Heads.\nNotice order matter \n\\[\\text{P}(\\text{}_i)\\times \\text{P}(\\text{}_j) = \\text{P}(\\text{}_j)\\times \\text{P}(\\text{}_i).\\]Assuming independence allows us consider simultaneous events separately one another, complicated examples can analysed easily using tree diagrams. path tree diagram root leaf distinct outcome sample space.Example 2.4  Vehicles approaching crossroads must go one three directions - left, right straight . Observations traffic engineers showed vehicles approaching north, \\(45\\%\\) turn left, \\(20\\%\\) turn right \\(35\\%\\) go straight . Assuming driver vehicle chooses direction independently, probability next three vehicles approaching north:go straight onall go straight onall go directionall go directiontwo turn left one turns righttwo turn left one turns rightall go different directionsall go different directionsexactly two turn left.exactly two turn left.solution\nFigure 2.1: tree diagram representing choices three vehicles\n\\(0.35^3\\)\\(0.35^3\\)\\(0.45^3+0.2^3+0.35^3\\)\\(0.45^3+0.2^3+0.35^3\\)LLR can rearranged \\(3\\) ways: LLR, LRL, RLL. \\(3\\times 0.45^2 \\times 0.2\\).LLR can rearranged \\(3\\) ways: LLR, LRL, RLL. \\(3\\times 0.45^2 \\times 0.2\\).SRL can rearranged \\(3!\\) ways. \\(3!\\times 0.35 \\times 0.45 \\times 0.2\\).SRL can rearranged \\(3!\\) ways. \\(3!\\times 0.35 \\times 0.45 \\times 0.2\\).LLR LLS. can rearranged \\(3\\) ways, mutually exclusive outcomes can add probabilities. \\[3\\times 0.45^2 \\times 0.2 + 3\\times 0.45^2 \\times 0.35\\].LLR LLS. can rearranged \\(3\\) ways, mutually exclusive outcomes can add probabilities. \\[3\\times 0.45^2 \\times 0.2 + 3\\times 0.45^2 \\times 0.35\\].","code":""},{"path":"cond.html","id":"conditional-probability","chapter":"2 Conditional Probability","heading":"2.2 Conditional Probability","text":"consider following examples motivate definition conditional probability.Example 2.5  number insurance claims previous \\(12\\) months cross tabulated whether driver involved young driver.insurance company interested claim rate. Overall claim rate ,\\[\\text{P}(\\text{Claim})=\\frac{50}{1000} = 0.05\\]estimate probability driver claiming insurance \\(1\\) \\(20\\).However figure hides substantial difference claim rates young older drivers.consider \\(250\\) young drivers separately ,\\[\\text{P}(\\text{Claim}|\\text{}\\ 25)=\\frac{25}{250} = 0.1.\\]\nWhereas \\(750\\) older drivers ,\\[\\text{P}(\\text{Claim}| 25 \\ \\text{})=\\frac{25}{750} = 0.03.\\]notation \\(|\\) read ‘given ’ conditional statement. conditional probabilities show claim rate much higher younger drivers. One can compute ratio probabilities see many times higher , \\(0.1/0.03 \\approx 3.3\\), just three times higher. relative risk scoring common medical statistics.Example 2.6  Consider following data study male lung cancer patients carried \\(1950\\) UK. one earliest applications epidemiology - use statistics study disease patterns populations.Calculate relative risk lung cancer smoker compared non-smoker.solution\\[\\text{P}(\\text{Lung cancer}|\\text{Smoker}) = \\frac{647}{1267}\\]\\[\\text{P}(\\text{Lung cancer}|\\text{Non-smoker}) = \\frac{2}{29}\\]\\(\\approx 7.4\\) times higher relative risk lung cancer smokers.examples motivate definition conditional probability.Definition 2.2  (conditional probability) conditional probability \\(\\text{P}(|B)\\) event \\(\\) given another event non-zero probability \\(B\\) given ,\\[\\text{P}(|B) = \\frac{\\text{P}(\\cap B)}{\\text{P}(B)}.\\]One verify fraction left precisely conditional probability calculated previous two examples.Theorem 2.1  conditional probability \\(\\text{P}(|B)\\) satisfies Kolmogorov’s definition probability.Proof. lectured examined, completeness.Firstly need check \\(P(|B)\\[0,1]\\). \\(P(|B) \\geq 0\\) \\(P(\\cap B)\\geq0\\) \\(P(B)>0\\).intersection \\(B\\) another set contained \\(B\\), \\(\\cap B \\subseteq B\\), \n\\[P(\\cap B) \\leq P(B).\\]\ndividing \\(P(B)\\) gives \\(P(|B) \\leq 1\\).Secondly, \\[P(\\Omega|B) = \\frac{P(\\Omega \\cap B)}{P(B)} = \\frac{P(B)}{P(B)}=1.\\]Lastly, given two disjoint \\(A_1\\),\\(A_2\\) \\(A_1\\cap A_2 = \\varnothing\\).\\[\\begin{align}\nP(A_1\\cup A_2 |B) &= \\frac{P((A_1\\cup A_2)\\cap B)}{P(B)} \\\\\n&= \\frac{P((A_1\\cap B)\\cup (A_2\\cap B))}{P(B)} \\\\\n&= \\frac{P(A_1\\cap B)}{P(B)} + \\frac{P(A_2\\cap B)}{P(B)} \\\\\n&= P(A_1|B) + P(A_2|B)\n\\end{align}\\]Example 2.7  Note \\(P(|B) \\neq P(B|)\\). Revisiting driver’s example gives,\\[\\text{P}(\\text{Claim}|\\text{}\\ 25)=0.1.\\]\nHowever,\n\\[\\text{P}(\\text{}\\ 25|\\text{Claim})=\\frac{25}{50} = 0.5\\]Theorem 2.2  Two events \\(\\) \\(B\\) independent \n\\[\\text{P}(|B) = \\text{P}() \\ \\text{ } \\ \\text{P}(B|) = \\text{P}(B)\\]\nwords, conditioning either event affect probability event occurring.Proof. Using definition conditional probability,\n\\[\\text{P}(\\cap B) = \\text{P}(|B)\\text{P}(B)=\\text{P}(B|)\\text{P}()\\]\n\n\\[\\text{P}(|B) = \\text{P}() \\ \\text{ } \\ \\text{P}(B|) = \\text{P}(B),\\]\nsubstituting former yields\n\\[\\text{P}(\\cap B) = \\text{P}()\\text{P}(B), \\]\ndefinition independence.\nConversely two events independent, \n\\[\\text{P}(|B) = \\frac{\\text{P}(\\cap B)}{\\text{P}(B)} = \\frac{\\text{P}()\\text{P}(B)}{\\text{P}(B)} = \\text{P}(), \\]\nlikewise \\(\\text{P}(B|)\\).constructing tree diagrams probabilities involved usually conditional probabilities natural progression tree left right conditioning happened previously. diagram , events \\(\\) \\(B\\) may independent.\nFigure 2.2: second level branches represent conditional probabilities B given complement, may different numbers\nExample 2.8  Jon always goes campus bike takes tram. one day goes campus bike, probability goes campus tram next day \\(0.4\\). one day goes campus tram, probability goes campus bike next day \\(0.7\\).\nGiven Jon goes campus Monday tram, find probability takes tram campus Wednesday.solutionThis may solved considering tree diagram levels Tuesday Wednesday. probabilities question \\(\\text{P}(\\text{tram} \\ |\\ \\text{bike})=0.4\\) \\(\\text{P}(\\text{bike} \\ |\\ \\text{tram})=0.7\\).\nMonday’s journey done. Possible sequences ‘tram tram’, ‘bike tram’. mutually exclusive outcomes. calculation \\[0.3^2+0.7\\times 0.4 = 0.37\\].Surveys questions sensitive delicate nature often result respondents missing question lying answers. Conditional probability can used mask awkward question find proportion answer certain way.Example 2.9  company want find proportion employees ever called sick work, fact sick. boss asks employee toss coin hide result.result heads, employee answer question ‘age odd number?’.result tails, answer ‘ever taken day ?’.boss know question people answering, employees can answer truthfully.Suppose \\(40\\%\\) employees mark ‘yes’ answer. Let,\\[p= \\text{P}(\\text{taken day } \\ | \\ \\text{tails})\\]\nAssume ages randomly distributed chance even odd number years old \\(0.5\\). can find \\(p\\)?solutionOne can draw tree diagram.\nFigure 2.3: outcomes survey.\noverall probability answering ‘yes’ \\(0.25+0.5p\\), survey \\(40\\%\\) answered ‘yes’. \\[0.25+0.5p = 0.4, \\]\nhence \\(p=0.3\\). means can estimate \\(30\\%\\) employees taken day supposed .","code":""},{"path":"cond.html","id":"bayes-theorem","chapter":"2 Conditional Probability","heading":"2.3 Bayes Theorem","text":"Example 2.10  two coins bag. One coin fair, heads sides (double-header).coin selected bag random, selected coin flipped three times. Unfortunately coin selected unknown us.three flips coin comes heads.Without calculations, likely think unfair coin?solutionLet\n\\(=\\left\\{ \\text{double-header selected} \\right\\}\\) \n\\(B =\\left\\{ \\text{coin lands heads three times row} \\right\\}\\)\nFigure 2.4: tree diagram double headed coin example.\nOne can use tree diagram find \\(8/9\\).can generalise picture come formula conditional probability called Bayes’ formula.\nFigure 2.5: Tree showing Bayes’ formula\n\\[P(|B) = \\frac{P(\\cap B)}{P(B)} = \\frac{P()P(B|)}{P()P(B|)+P(^{\\mathsf{c}})P(B|^{\\mathsf{c}})}\\]Previously, \\(A_1=\\) \\(A_2 = ^{\\mathsf{c}}\\) disjoint union gives entire sample space. situation called partition.can extended partition \\(n\\) events \\(A_1,A_2, \\dots , A_n\\).Definition 2.3  collection events \\(A_1, A_2, \\dots , A_n\\) partition union entire sample space, exhaustive, mutually exclusive. \\(\\Omega = A_1 \\cup A_2 \\cup \\dots \\cup A_n\\).\\(\\Omega = A_1 \\cup A_2 \\cup \\dots \\cup A_n\\).\\(A_1 \\cap A_2 \\cap \\dots \\cap A_n = \\varnothing\\)\\(A_1 \\cap A_2 \\cap \\dots \\cap A_n = \\varnothing\\)event complement form partition.picture partition:\nFigure 2.6: example partition six sets.\ncan now extend concept conditional probability general situation condition event least one event partition.Theorem 2.3  (Law Total Probability) Suppose partition \\(A_1, A_2, \\dots , A_n\\) sample space \\(\\Omega\\). event \\(B \\subseteq \\Omega\\), \\[\\text{P}(B) =P(A_1)P(B|A_1)+ \\dots + P(A_n)P(B|A_n) \\]intuitive proof imagine tree diagram \\(n\\) branches \\(A_i\\) first layer, \\(B\\) \\(B^{\\mathsf{c}}\\) next layer. multiply along branches ways \\(B\\) can occur end sum RHS.Theorem 2.4  (Bayes' Theorem) Suppose partition \\(A_1, A_2, \\dots , A_n\\) sample space \\(\\Omega\\). conditional probability one event partition \\(A_k\\) \\(k\\), given event \\(B\\) can written ,\\[\\text{P}(A_k |B) = \\frac{\\text{P}(B|A_k)\\text{P}(A_k)}{\\sum^{n}_{=1}\\text{P}(B|A_i)P(A_i)}\\]Proof. Note \\(\\text{P}(A_k\\cap B) = \\text{P}(B|A_k)\\text{P}(A_k)\\),denominator $(B) using law total probability.Example 2.11  company produces electrical components using three shifts. first shift \\(50%\\) components produced, \\(20\\%\\) \\(30\\%\\) produced shifts \\(2\\) \\(3\\) respectively. proportion defective components produced shift \\(1\\) \\(6\\%\\). shifts \\(2\\) \\(3\\) proportions \\(8\\%\\) \\(12\\%\\) respectively.Find percentage defective components.Find percentage defective components.component defective, probability came shift \\(3\\)?component defective, probability came shift \\(3\\)?solutionLet \\(D\\) event component defective \\(S_1,S_2,S_3\\) denotethat produced shifts \\(1,2\\) \\(3\\) respectively.Use theorem total probability, follows:\n\\[\\begin{align}\n\\text{P}(D)  &= \\text{P}(D|S_1)P(S_1)+\\text{P}(D|S_2)\\text{P}(S_2)+\\text{P}(D|S_3)\\text{P}(S_3) \\\\\n&= 0.06\\times 0.5 + 0.08\\times 0.2 + 0.12\\times 0.3 \\\\\n&= 0.082\n\\end{align}\\]Use theorem total probability, follows:\n\\[\\begin{align}\n\\text{P}(D)  &= \\text{P}(D|S_1)P(S_1)+\\text{P}(D|S_2)\\text{P}(S_2)+\\text{P}(D|S_3)\\text{P}(S_3) \\\\\n&= 0.06\\times 0.5 + 0.08\\times 0.2 + 0.12\\times 0.3 \\\\\n&= 0.082\n\\end{align}\\]Using Bayes’ theorem,Using Bayes’ theorem,\\[\\text{P}(S_3|D) = \\frac{\\text{P}(D|S_3)\\text{P}(S_3)}{\\text{P}(D)}\\]\ndenominator worked part ), gives \\(\\frac{0.12\\times 0.3}{0.082}=0.439\\).Bayes’ theorem allows us update probability event light new evidence. fact main practical use theorem, leads whole branch Bayesian Statistics.Example 2.12  Gary suspected committing crime. evidence far points probability guilt \\(0.9\\). ‘prove innocence’ Gary undergoes lie detector test, \\(70\\%\\) accuracy rate. test say positive indicate guilt, negative indicate guilty. test \n\\[\\text{P}(\\text{Positive}|\\text{Guilty}) = 0.7\\]\n\\[\\text{P}(\\text{Negative}|\\text{Innocent})=0.7\\]Gary’s test comes back negative, probability guilt?solutionOne can directly apply Bayes’ theorem.\n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{\\text{P}(\\text{Negative}|\\text{Guilt})\\text{P}(\\text{Guilt})}{\\text{P}(\\text{Negative}|\\text{Guilt})\\text{P}(\\text{Guilt})+\\text{P}(\\text{Negative}|\\text{Innocent})\\text{P}(\\text{Innocent})}\\]\n\n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 0.9}{0.3\\times 0.9 \\ + \\ 0.7\\times 0.1}=0.794 \\ \\text{(3 d.p.)}\\]Beware extreme prior beliefs, evidence can change mind. Believing something true \\(100\\%\\) \\(0\\%\\), mean reason evidence change position.Example 2.13  (Cromwell's Rule) believe Gary \\(100\\%\\) guilty start \n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 1}{0.3\\times 1 \\ + \\ 0.7\\times 0}=1\\]\nstill believe Gary \\(100\\%\\) guilty.believe Gary \\(0\\%\\) guilty start \n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 0}{0.3\\times 0 \\ + \\ 0.7\\times 1}=0\\]\nstill believe Gary \\(0\\%\\) guilty.educated people always consider opposing opinion update beliefs according evidence available. strong opinion something, consider change mind. Always leave room doubt , wrong.","code":""},{"path":"cond.html","id":"exercises-week-2","chapter":"2 Conditional Probability","heading":"2.4 Exercises Week 2","text":"Exercise 2.1  toss fair coin roll die.\n) events independent?probability obtain head \\(6\\)?Exercise 2.2  torch uses two batteries series. battery works probability \\(0.95\\), independently . Work probability :torch work.torch work.batteries failBoth batteries failOnly one batteries work.one batteries work.Exercise 2.3  Whether student gets time depends whether remembered set alarm night . \\(90\\%\\) time remembers, \\(10\\%\\) forgets. clock set, get time \\(95\\%\\) occasions. set, chance oversleep \\(35\\%\\). Use tree diagram find probability oversleep.Exercise 2.4  following data shows distribution male female students various degree courses university.Suppose student selected random. Find probability ,femalefemalestudying Economicsstudying Economicsmale studying Economicsmale studying Economicsmale given studying Economicsmale given studying Economicsfemale given studying Economicsfemale given studying Economicsstudying Economics given femalestudying Economics given femaleAre events ‘student male’ ‘studying Economics’ independent?Exercise 2.5  following table shows lung cancer data females \\(1950\\) study given example 2.6.Calculate relative risk female smokers compared non-smokers.Calculate relative risk female smokers compared non-smokers.Can suggest reason difference figures males females?Can suggest reason difference figures males females?Exercise 2.6  Two electrical components \\(X\\) \\(Y\\) probabilities working \\(\\frac{3}{4}\\) \\(\\frac{7}{8}\\), respectively. also function independently . Two devices \\(D_1\\) \\(D_2\\) constructed. \\(D_1\\), \\(X\\) \\(Y\\) series, \\(D_2\\) wired parallel.Find probability \\(D_1\\) works.\nFind probability \\(D_1\\) works.Find probability \\(D_2\\) works.Suppose \\(D_1\\) works, find probability ;\\(X\\) working.\\(X\\) working.\\(X\\) \\(Y\\) working.Suppose \\(D_2\\) works, find probability ;\\(X\\) working.\\(X\\) working.\\(X\\) \\(Y\\) working.Exercise 2.7  urn contains two green balls three red bals. Supose two balls drawn random one another without replacement. Draw tree diagram, find probability :green ball appears first draw.green ball appears first draw.green ball appears second draw.green ball appears second draw.Exercise 2.8  following table shows fear factor children attending dentist, cross tabulated School age child.child selected random define events; \\(= \\{ \\text{child afraid} \\}\\),\\(N\\) afraid, \\(\\),\\(P\\) \\(S\\) School age obvious fashion.Calculate following probabilities,\\(\\text{P}()\\), \\(\\text{P}(N)\\), \\(\\text{P}(\\cup )\\).\\(\\text{P}()\\), \\(\\text{P}(N)\\), \\(\\text{P}(\\cup )\\).\\(\\text{P}(| )\\) \\(\\text{P}(| )\\).\\(\\text{P}(| )\\) \\(\\text{P}(| )\\).\\(\\text{P}(| S)\\) \\(\\text{P}(N| S)\\) - notice two probabilities?\\(\\text{P}(| S)\\) \\(\\text{P}(N| S)\\) - notice two probabilities?\\(\\) \\(\\) independent?Exercise 2.9  survey electrical retailer determines \\(40\\%\\) customers seek advice sales staff appliance \\(20\\%\\) seek advice buy appliance. \\(30\\%\\) customers seek advice, probability customer entering warehouse buys appliance?Exercise 2.10  Four cards drawn random without replacement deck \\(52\\) cards. probability sequence :\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\clubsuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\clubsuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\spadesuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\spadesuit\\)Exercise 2.11  student comes back night pub bunch keys, one works. try one key random lock discard doesn’t fit.Suppose bunch contains \\(2\\) keys. Find probability open door onthe first attemptthe first attemptthe second attemptthe second attemptRepeat bunch three keys successul first, second third attempts.Repeat bunch three keys successul first, second third attempts.Suppose now bunch contains \\(n\\) keys. Find probability door opened \\(r^{\\text{th}}\\) attempt (\\(1\\leq r \\leq n\\)).Suppose now bunch contains \\(n\\) keys. Find probability door opened \\(r^{\\text{th}}\\) attempt (\\(1\\leq r \\leq n\\)).Exercise 2.12  ascertain proportion people sexually transmitted infection, following survey pocedure used \\(1000\\) individuals.asked think day week recent birthday fell .last birthday Monday, Tuesday Wednesday answer question ‘every sexually transmitted infection?’.last birthday day week, answer question ‘age even number?’.survey \\(290\\) people answered ‘yes’. Assuming ages birthdays uniformly distributed, can estimate proportion people sexually transmitted infection?Exercise 2.13  Suppose two events \\(\\) \\(B\\) independent. Show \\(\\) \\(B^{\\mathsf{c}}\\) also independent. Show also \\(^{\\mathsf{c}}\\) \\(B^{\\mathsf{c}}\\) independent.Exercise 2.14  Forty percent new employees hired large company degree. Seventy percent employees degrees promoted within two years.without degrees, \\(30\\%\\) arepromoted within two years.probability new empoyee promoted?probability new empoyee promoted?employee promoted, probability degree?employee promoted, probability degree?Exercise 2.15  bag contains \\(3\\) coins; two normal unbiased coins third double headed. coin chosen random bag tossed. coin tossed \\(4\\) times came heads time. probability double header?Exercise 2.16  Approximately \\(25\\%\\) males \\(50\\) form heart problem. clinic observed males heart problem three times likely smokers males heart problem. probability male \\(50\\) heart problem given smoker?Exercise 2.17  Cage contains five hens disease six hens without disease. Cage B contains two diseased hens five hens without disease. Two hens chosen random cage transferred cage B. hen now chosen random cage B found diseased. Find probability two hens transferred ,diseasedboth diseasedboth without disease.without disease.","code":""},{"path":"drv.html","id":"drv","chapter":"3 Discrete Random Variables","heading":"3 Discrete Random Variables","text":"practical situations encounter uncertainty, random outcome interest numerical quantity. number minutes end waiting bus, much win lottery week, even number times try catch fly chopsticks eventually manage .","code":""},{"path":"drv.html","id":"random-variables","chapter":"3 Discrete Random Variables","heading":"3.1 Random Variables","text":"chapter learn concept discrete random variable.Example 3.1  Suppose roll two dice find sum numbers two dice. Let \\(X\\) sum numbers two dice. know sample space :\n\\[\\Omega = \\{ (n_1,n_2) : n_1,n_2 \\\\mathbb{N}, \\ 1 \\leq n_1 , n_2 \\leq 6 \\},\\]\nGiven outcome \\((n_1,n_2)\\), ‘variable’ \\(X\\) takes particular whole numbered value \\(x=2, \\dots , 12\\). seen particular values equally likely.Definition 3.1  random variable \\(X\\) set function maps potential outcomes statistical experiment (subset ) real number line.random variable written capital letter (\\(X\\)), particular values takes written lowercase letter (\\(x\\)). probability \\(X\\) takes particular value written \\(\\text{P}(X=x)\\).Just data analysis difference discrete continuous random variables. One can think discrete random variables arising process involves counting can take integer values. continuous random variables can thought arising measuring process.Example 3.2  Let $R = $ result spinning roulette wheel. roulette wheel can take particular values\n\\[\\Omega = \\{0,1,2, \\dots,36\\}.\\]\nnumber ranges 1 10 19 28, odd numbers red even black. ranges 11 18 29 36, odd numbers black even red. green pocket numbered 0 (zero). \\(R\\) discrete random variable, takes particular discrete values.Let \\(T =\\) time spent waiting bus. \\(T\\) positive number arrive bus stop (time timetabled arrival time, negative early bus). \\(T\\) continuous random variable.consider discrete random variables first, study types course.","code":""},{"path":"drv.html","id":"discrete-probability-distributions","chapter":"3 Discrete Random Variables","heading":"3.2 Discrete probability distributions","text":"order understand random variable likely behave, thus able predict possible future values, clearly need consider probability take particular values. set probability values known probability distribution. develop theory examples.Definition 3.2  distribution function, also known probability mass function, random variable \\(X\\) function outputs probability \\(X\\) attaining particular value. ,\\[f(x) = \\text{P}(X=x)\\]\ntexts, two variables play, may also write variable subscript \\(f_X(x)\\) clear mass function referring.Example 3.3  (discrete uniform distribution) Consider rolling fair die let discrete random variable \\(X\\) score observed die. know probability getting particular values set \\(\\{1,2, \\dots 6\\}\\) \\(\\frac{1}{6}\\) probability distribution. may tabulate values followsAlternatively may use formula:\n\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{6}, & \\text{} x = 1, 2, \\dots , 6.\\\\\n    0 & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]graph:\nFigure 3.1: Probability mass function fair die\nClearly graph useful way visualise probability distributed. can also see called discrete uniform distribution - ’s values .questions consider:Suppose die \\(n\\) sides, \\(n\\) whole number greater \\(1\\), faces numbered \\(1,2,\\dots n\\). distribution look like now?Suppose die \\(n\\) sides, \\(n\\) whole number greater \\(1\\), faces numbered \\(1,2,\\dots n\\). distribution look like now?Can represent distribution three ways ?Can represent distribution three ways ?Example 3.4  (Urn problem) urn contains five balls numbered \\(1\\) \\(5\\). Two balls drawn simultaneously.Let \\(X\\) larger two numbers.Let \\(X\\) larger two numbers.Let \\(Y\\) sum two numbers.Let \\(Y\\) sum two numbers.Find probability distributions \\(X\\) \\(Y\\).solutionWe proceed follows enumerating possibilities noting \\(^5C_2=10\\) ways drawing balls urn. Note balls drawn simultaneously, order matter .find distribution \\(X\\) one can list outcomes systematically largest value.find distribution \\(Y\\) one can list outcomes systematically sum.either case check individual probability \\(0\\) \\(1\\) possible particular values sum \\(1\\).Example 3.5  (geometric distribution) archer hits target rather randomly. Let’s suppose time takes aim \\(\\text{P}(\\text{Hit})=\\frac{1}{4}\\), complement \\(\\text{P}(\\text{Miss})=\\frac{3}{4}\\). Let \\(Y\\) number attempts required hits target. Find distribution \\(Y\\).solutionWe can consider number attempts separately.\\(Y=1\\), first attempt hit, \\(\\text{P}(Y=1)=\\frac{1}{4}.\\)\\(Y=2\\), first attempt miss, second hit, \n\\[\\text{P}(Y=2)=\\frac{3}{4}\\times \\frac{1}{4} = \\frac{3}{16}.\\]\\(Y=3\\), first attempt miss, second miss, third hit \n\\[\\text{P}(Y=3)=\\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{1}{4} = \\frac{9}{64}.\\]\n\\(Y=4\\), sequence miss, miss, miss hit:\n\\[\\text{P}(Y=3)=\\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{1}{4} = \\frac{27}{256}.\\]\n.Notice archer hit target \\(y^{\\text{th}}\\) attempt, must missed previous \\(y-1\\) attempts, formula mass function follows.\\[\\begin{equation*}\n  f(Y=y)=\\begin{cases}\n    \\left( \\frac{3}{4} \\right)^{y-1}\\frac{1}{4} \\ , & \\text{} y = 1, 2, 3, \\dots \\\\\n    \\ 0 \\ & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Clearly probabilities quickly getting small - may recognise terms geometric sequence common ration \\(\\frac{3}{4}\\).graph distribution looks like:\nFigure 3.2: geometric distribution\nchoice \\(\\frac{1}{4}\\) infact arbitrary. general can ‘success’ probability \\(\\pi\\) ‘failure’ probability \\(1-\\pi\\).Definition 3.3  random variable \\(X\\) representing number independent trials first success follows geometric distribution success probability \\(\\pi\\), written \\(X \\sim \\text{Geom}(\\pi)\\), defined probability mass function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\left( 1-\\pi \\right)^{x-1}\\pi , & x = 1, 2, 3, \\dots \\\\\n    \\ 0 \\ & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]course trials archer arguably independent - ?","code":""},{"path":"drv.html","id":"properties-of-probability-mass-functions","chapter":"3 Discrete Random Variables","heading":"3.3 Properties of probability mass functions","text":"random variable \\(X\\) probability distribution \\(f(x)\\) following two properties:probability particular value \\(0\\) \\(1\\). ,\n\\[ 0 \\leq f(x) \\leq 1, \\ \\forall x\\]probability particular value \\(0\\) \\(1\\). ,\n\\[ 0 \\leq f(x) \\leq 1, \\ \\forall x\\]probabilities sum unity. ,probabilities sum unity. ,\\[ \\sum_{x} f(x)= 1\\]Probability distributions can represented variety different ways. practice use tables distributions use computer functions evaluate .R can use following functions evaluate probabilities example 3.5.important function \\(\\texttt{dgeom()}\\), \\(\\texttt{d}\\) stands distribution \\(\\texttt{geom}\\) geometric distribution.Another way represent probability distribution cumulative sum.Definition 3.4  (Cumulative distribution function) Given random variable \\(X\\) probability mass function \\(f(x)\\), cumulative distribution function (abbreviated CDF) denoted capital letter \\(F(x)\\) defined sum probabilities less equal value \\(x\\). ,\\[ F(x) = \\text{P}(X\\leq x) = \\sum_{t\\leq x}f(t)\\]Example 3.6  (another urn problem) Consider setup previously two balls numbered \\(1\\) \\(5\\) drawn maximum two numbers taken.\nfound probability distribution ,Work CDF \\(F(x)\\).solutionIf \\(x<2\\) \\(F(x)=0\\).\n\\(2\\leq x < 3\\) \\(F(x) = \\frac{1}{10}\\).\n\\(3\\leq x < 4\\) \\(F(x) = \\frac{1}{10} + \\frac{2}{10}\\).\n\\(4\\leq x < 5\\) \\[F(x) = \\frac{1}{10} + \\frac{2}{10} + \\frac{3}{10}.\\]\n\\(5\\leq x\\) \\[F(x) = \\frac{1}{10} + \\frac{2}{10} + \\frac{3}{10} + \\frac{4}{10}.\\]Altogether,\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n  0  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   x<2 \\\\\n  \\frac{1}{10} \\  \\  2\\leq x < 3 \\\\\n  \\frac{3}{10} \\ \\  3\\leq x < 4 \\\\\n  \\frac{6}{10} \\ \\ \\ 4\\leq x < 5 \\\\\n  1 \\ \\ \\  \\ \\ \\  5\\leq x\n  \\end{cases}\n\\end{equation*}\\]Example 3.7  CDF geometric distribution given \n\\[F(x) = 1- (1-\\pi)^{x}.\\]solution\\[F(x) = \\sum_{t\\leq x}f(t)\\]\nSum \\(t=1\\) \\(t=x\\).\\[  = \\pi + \\pi(1-\\pi) + \\pi(1-\\pi)^2 + \\dots +  \\pi(1-\\pi)^{x-1} \\]\nmight recognise geometric series , \\(=\\pi\\) \\(r=(1-\\pi)\\), can collected :\\[F(x) = \\frac{\\pi (1-(1-\\pi)^x)}{1-(1-\\pi)} \\]\nEvaluating denominator cancelling gives result.CDF useful mass function since given CDF can calculate mass function directly difference.\\[f(x) = F(x)-F(x-1)\\]Example 3.8  Calculate \\(f(4)\\) given CDF\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n  0  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   x<2 \\\\\n  \\frac{1}{10} \\  \\  2\\leq x < 3 \\\\\n  \\frac{3}{10} \\ \\  3\\leq x < 4 \\\\\n  \\frac{6}{10} \\ \\ \\ 4\\leq x < 5 \\\\\n  1 \\ \\ \\  \\ \\ \\  5\\leq x\n  \\end{cases}\n\\end{equation*}\\]solution\\(f(4) = F(4)-F(3) = \\frac{6}{10}-\\frac{3}{10} = \\frac{3}{10}\\)Due fact mass function can calculated CDF, statistical tables often prioritise tabulating CDF various different types distribution.finish section example theory may used applied calculations.Example 3.9  Assuming archer’s attempts hit target follows geometric distribution success parameter \\(\\frac{1}{4}\\) calculate probability heHits \\(10^{\\text{th}}\\) attempt.Hits \\(10^{\\text{th}}\\) attempt.Takes fewer \\(4\\) attempts hit target.Takes fewer \\(4\\) attempts hit target.Takes least \\(8\\) attempts hit target.Takes least \\(8\\) attempts hit target.Takes \\(4\\) \\(8\\) attempts inclusive.Takes \\(4\\) \\(8\\) attempts inclusive.solutionLet \\(Y\\) number attempts hit target. know \\[f(y) = \\left( \\frac{3}{4} \\right) ^{y-1}\\frac{1}{4}\\]\\[ F(y) = 1- \\left(1-\\frac{1}{4}\\right)^y = 1-\\left( \\frac{3}{4}\\right)^y.\\]\\(\\text{P}(Y=10) = f(10) = \\left( \\frac{3}{4}\\right)^9\\times \\frac{1}{4} = 0.0188\\) (\\(3\\) s.f.).\\(\\text{P}(Y=10) = f(10) = \\left( \\frac{3}{4}\\right)^9\\times \\frac{1}{4} = 0.0188\\) (\\(3\\) s.f.).\\(\\text{P}(Y<4) = \\text{P}(Y\\leq 3) = F(3) =1 - \\left( \\frac{3}{4}\\right)^3 = 0.578\\), (\\(3\\) s.f.).\\(\\text{P}(Y<4) = \\text{P}(Y\\leq 3) = F(3) =1 - \\left( \\frac{3}{4}\\right)^3 = 0.578\\), (\\(3\\) s.f.).Using complement, \\(\\text{P}(Y\\geq 8) = 1 - \\text{P}(Y\\leq 7)\\). Now using CDF:Using complement, \\(\\text{P}(Y\\geq 8) = 1 - \\text{P}(Y\\leq 7)\\). Now using CDF:\\[1-F(7) = 1- \\left( 1-\\left(\\frac{3}{4}\\right)^7\\right) = 0.134.\\]Rewrite required range difference two CDF values follows:\\[\\text{P}(4\\leq Y\\leq 8) = \\text{P}(Y\\leq 8) - \\text{P}(Y\\leq 3)\\]\\[ = F(8) - F(3)\\]\\[ = \\left[ 1-\\left(\\frac{3}{4}\\right)^8\\right] -  \\left[ 1-\\left(\\frac{3}{4}\\right)^3\\right]\\]\n\\[ = 0.322\\]\ncareful evaluating CDF ensure correct values given inequality. small diagram list can invaluable .","code":"\ny <- dgeom(x = 1:4, #these are the particular values 1,2,3 and 4\n           prob = 1/4 ) #This is the probability of success\ny## [1] 0.18750000 0.14062500 0.10546875 0.07910156\n#You can output these as fractions using the MASS library\nMASS::fractions(y)## [1]    3/16    9/64  27/256 81/1024"},{"path":"drv.html","id":"mean-variance-and-moments","chapter":"3 Discrete Random Variables","heading":"3.4 Mean, variance and moments","text":"mean variance random variable essentially mirror definitions mean variance samples.mean expected value average value variable observed repeatedly. variance indicates likely spread values variable.Example 3.10  toss coin \\(2\\) times many heads expect turn ?solutionYour expect \\(1\\) intuitively. Let \\(X\\) number heads.\noutcomes \\((T,T),(H,T),(T,H),(H,H)\\). average number heads \\[ \\frac{0+1+1+2}{4} = 1\\]\ncan relate probability number heads. ,\\[\\text{P}(X=0) = \\frac{1}{4}\\]\n\\[\\text{P}(X=1) = \\frac{2}{4}\\]\n\\[\\text{P}(X=2) = \\frac{1}{4}\\]sum possible \\(x\\) values weighted probability :\n\\[0\\times \\frac{1}{4} + 1\\times \\frac{2}{4} + 2\\times \\frac{1}{4} = 1.\\]Definition 3.5  expectation, expected value random variable \\(X\\) defined sum possible values random variable weighted probability value.\\[ \\text{E}[X] = \\sum_x x\\times\\text{P}(X=x)\\]\njust number calculated called mean, written constant \\(\\text{E}[X]=\\mu\\) omit random quantity \\(X\\).expected value function discrete random variable \\(g(X)\\) defined similarly \n\\[ \\text{E}[X] = \\sum_x g(x)\\times\\text{P}(X=x)\\]Definition 3.6  variance random variable \\(X\\) defined :\\[ \\text{Var}[X] = \\text{E}[(X-\\mu)^2]\\]following useful practice actually computing variance.Theorem 3.1  Given random variable \\(X\\) variance equal difference expectation \\(X^2\\) squared expectation \\(X\\). ,\\[ \\text{Var}[X]=\\text{E}[X^2]-\\text{E}[X]^2 \\]omit proof now see examples, leaving interested reader.Proof. expectation sum, behaves linearly. definition,\\[\\text{Var}[X] = \\text{E}[(X-\\mu)^2]\\]\nExpanding bracket inside gives,\n\\[ = \\text{E}[X^2 - 2\\mu X +\\mu^2] \\]\nUsing linearity,\\[= \\text{E}[X^2]-2\\mu\\text{E}[X]+\\mu^2.\\]\n\\[= \\text{E}[X^2]-2\\mu^2+\\mu^2.\\]\nHence result.Example 3.11  discrete random variable \\(X\\) representing score loaded die following probability mass function.Calculate:\\(\\text{E}[X]\\)\\(\\text{E}[X]\\)\\(\\text{E}[X^2]\\)\\(\\text{E}[X^2]\\)\\(\\text{Var}[X]\\)\\(\\text{Var}[X]\\)\\(\\text{E}[e^X]\\)\\(\\text{E}[e^X]\\)solutionUsing definition expectation:\\[ \\text{E}[X] = 1\\times \\frac{1}{21}+2\\times \\frac{2}{21}+3\\times \\frac{3}{21}+4\\times \\frac{4}{21}+5\\times \\frac{5}{21}+6\\times \\frac{6}{21},\\]\n\\[ = 4.33 \\ \\ \\ (3 \\ \\text{s. f.})\\]\nCompared fair die, mean loaded die higher.\\[ \\text{E}[X^2] = 1^2\\times \\frac{1}{21}+2^2\\times \\frac{2}{21}+3^2\\times \\frac{3}{21}+4^2\\times \\frac{4}{21}+5^2\\times \\frac{5}{21}+6^2\\times \\frac{6}{21},\\]\\[ = 21\\]variance ,\\[\\text{Var}[X]=\\text{E}[X^2]-\\mu^2 = 21-(4.33\\dots)^2= 2.22 \\ \\ \\ (3 \\ \\text{s. f.})\\]\n4. \\(e^X\\) just function \\(X\\).\\[ \\text{E}[X] = e^1\\times \\frac{1}{21}+e^2\\times \\frac{2}{21}+e^3\\times \\frac{3}{21}+e^4\\times \\frac{4}{21}+e^5\\times \\frac{5}{21}+e^6\\times \\frac{6}{21},\\]\\[ = 164.622 \\ (3 \\ \\text{d. p.}) \\]Example 3.12  (expected profit) Consider following game. spinning wheel divided three equal sections numbered \\(1\\), \\(2\\) \\(3\\). pay £\\(1\\) play game, guess number show wheel spun. guess correctly, get £\\(2\\). get nothing. expected profit playing game?solutionThe profit winnings minus stake. Let profit random variable \\(X\\). distribution \\(X\\) :\\[\\text{E}[X] = -1 \\times \\frac{2}{3} + 1 \\times \\frac{1}{3} = -\\frac{1}{3}\\]\nexpect average make loss playing game. gambling game profitable house, necessary expectation players winnings negative.Example 3.13  Let \\(X\\) random variable whose value constant, particular values can take , \\(x=\\). Show \\(\\text{E}[X]=\\) \\(\\text{Var}[X]=0\\)solution\\[\\text{E}[X]=\\sum_{x}x\\times\\text{P}(X=x)= \\sum \\times\\text{P}(X=)=\\times \\sum \\text{P}(X=) = \\times 1 = \\]variance,\\[ \\text{Var}[X] = \\text{E}[(X-\\mu)^2]=\\text{E}[(-)^2]=0 \\]now proceed find mean variance Geometric distribution. need fact series first.Proposition 3.1  Suppose \\(|r|<1\\) recall infinite geometric series given following formula:\\[g(r) = \\sum_{k=0}^{\\infty}ar^{k} = \\frac{}{1-r}\\]\nconvergent series can differentiate term term respect \\(r\\), equate get differentiating RHS likewise. results following two formulae:\\[g'(r) = \\sum_{k=0}^{\\infty}akr^{k-1} = \\frac{}{(1-r)^2}\\]\\[g''(r) = \\sum_{k=0}^{\\infty}ak(k-1)r^{k-2} = \\frac{2a}{(1-r)^3}\\]Theorem 3.2  Let \\(X\\) random variable follows geometric distribution, \\(X \\thicksim \\text{Geom}(\\pi)\\), :\\[\\text{E}[X] = \\frac{1}{\\pi}\\]\n\n\\[ \\text{Var}[X]=\\frac{1-\\pi}{\\pi^2}\\]Proof. definition,\n\\[\\text{E}[X] = \\sum_{x=1}^{\\infty}x(1-\\pi)^{x-1}\\pi\\]\n\\[ = \\pi + 2\\pi(1-\\pi) + 3\\pi(1-\\pi)^2+4\\pi(1-\\pi)^3+ \\dots \\]\nlatter sum can seen \\(g'(1-\\pi)\\), \\(=\\pi\\). Using RHS result previous proposition ,\n\\[\\text{E}[X] = \\frac{\\pi}{[1-(1-\\pi)]^2} = \\frac{1}{\\pi}\\]\nvariance first find expectation function \\(X\\) called factorial moment.\\[\\text{E}[X(X-1)] = \\sum_{x=1}^{\\infty}x(x-1)\\pi(1-\\pi)^{x-1}\\]\n\\[ = (1-\\pi)\\sum_{x=2}^{\\infty}x(x-1)\\pi(1-\\pi)^{x-2}\\]\ninfinite series turns \\(g''(1-\\pi)\\) \\(=\\pi\\). Substituting gives,\\[\\text{E}[X(X-1)]=(1-\\pi)\\frac{2\\pi}{[1-(1-\\pi)]^3} = \\frac{2(1-\\pi)}{\\pi^2}.\\]\nNow can use find variance follows,\\[\\text{Var}[X] = \\text{E}[X^2]-\\text{E}[X]^2 \\]\n\\[ = \\text{E}[X(X-1)]+\\text{E}[X]-\\text{E}[X]^2 \\]\n\\[ = \\frac{2(1-\\pi)}{\\pi^2} + \\frac{1}{\\pi} - \\frac{1}{\\pi^2} \\]\n\\[ = \\frac{1-\\pi}{\\pi^2}\\]\nrequired.given two random variables \\(X\\) \\(Y\\) linear combination means expression form \\(aX+\\).Theorem 3.3  (Linear Combinations) random variables \\(X\\) \\(Y\\) constants \\(\\) \\(b\\) expectation linear combination linear combination expectations.\\[\\text{E}[aX\\pm ] = \\text{E}[X]\\pm b\\text{E}[Y]\\]\nHowever variance nonlinear sum variances.\\[\\text{Var}[aX\\pm ] = ^2\\text{Var}[X]+b^2\\text{Var}[Y] \\]Proof. omitted, follows properties summations mass functions.Example 3.14  Recall loaded die mass function given ,Suppose win \\(W\\) amount depending number roll loaded die.\\(W = 3X-10\\) find \\(\\text{E}[W]\\) \\(\\text{Var}[W]\\)solution\\[\\text{E}[W] = 3\\times (4.333\\dots) -10 = £3\\]\\[\\text{Var}[W] = 3^2\\times(2.22\\dots) = 19.99\\dots = 20.0 \\  (3 \\ \\text{s.f.})\\]","code":""},{"path":"drv.html","id":"exercises-week-3","chapter":"3 Discrete Random Variables","heading":"3.5 Exercises Week 3","text":"Exercise 3.1  urn contains two yellow balls three red balls. Three balls drawn random urn without replacement.Draw tree diagram represent sample space experiment find probabilities outcome.Draw tree diagram represent sample space experiment find probabilities outcome.Let random variable \\(X\\) denote number red balls drawn.Let random variable \\(X\\) denote number red balls drawn.Write probability distribtion \\(X\\).Write probability distribtion \\(X\\).Find mean variance \\(X\\).Exercise 3.2  Let \\(X\\) value observed rolling \\(8\\)-sided dieWhat probability distribution \\(X\\).probability distribution \\(X\\).Draw graph probability distribution.Draw graph probability distribution.Find mean variance \\(X\\).Find mean variance \\(X\\).Find expected value :Find expected value :\\(3X+5\\)\\(3X+5\\)\\(\\ln(X)\\)Exercise 3.3  game consists tossing coin first head appears. score recorded number tosses required.random variable \\(Y\\) number tosses, distribution \\(Y\\)?random variable \\(Y\\) number tosses, distribution \\(Y\\)?Write first \\(6\\) values probability distribution, draw sketch.Write first \\(6\\) values probability distribution, draw sketch.Find mean variance \\(Y\\).Find mean variance \\(Y\\).Exercise 3.4  Two fair dice rolled total score observed.Write probability distribution total score.Write probability distribution total score.Find mean variance total score.Find mean variance total score.Exercise 3.5  Two fair dice rolled maximum score observed.Write probability distribution maximum score.Write probability distribution maximum score.Find mean variance maximum score.Find mean variance maximum score.Exercise 3.6  fair coin tossed three times. Let \\(X\\) number heads tosses minus number tails.\n) Find probability distribution \\(X\\)Find mean variance \\(X\\).Exercise 3.7  game simple Chuck--luck played single player house. game conducted follows:player chooses number \\(1\\) \\(6\\) inclusive places bet £\\(1\\). banker rolls \\(2\\) fair dice. player’s number occurs \\(1\\) \\(2\\) times, wins £\\(1\\) £\\(2\\) respectively. player’s numberdoes appear dice, loses £\\(1\\) stake. Let random variable \\(X\\) denote player’s winnings game.Find probability mass function \\(X\\).Find probability mass function \\(X\\).Find expected value winnings, \\(\\text{E}[X]\\).Find expected value winnings, \\(\\text{E}[X]\\).Exercise 3.8  random variable \\(X\\) following probability mass function:Find value \\(c\\) makes valid probability mass function.Find value \\(c\\) makes valid probability mass function.Find \\(\\text{E}[X]\\) \\(\\text{Var}[X]\\).Find \\(\\text{E}[X]\\) \\(\\text{Var}[X]\\).Exercise 3.9  random variable \\(X\\) following probability mass function:\\(\\text{E}[Y]=\\frac{14}{3}\\)Find values \\(\\) \\(b\\).Find values \\(\\) \\(b\\).Find \\(\\text{Var}[Y]\\).Find \\(\\text{Var}[Y]\\).Exercise 3.10  fair six-sided die ‘\\(1\\)’ one face, ‘\\(2\\)’ two faces ‘\\(3\\)’ remaining three faces.Let \\(Y\\) denote score single roll die. Tabulate mass function calculate mean variance \\(Y\\).Let \\(Y\\) denote score single roll die. Tabulate mass function calculate mean variance \\(Y\\).Let \\(X\\) total score two rolls die. Tabulate mass function calculate mean variance \\(X\\).Let \\(X\\) total score two rolls die. Tabulate mass function calculate mean variance \\(X\\).Exercise 3.11  urn contains \\(n\\) balls numbered \\(1\\) \\(n\\) two balls drawn simultaneously. Find probability distribution \\(X\\), larger two numbers drawn. Calculate expected value \\(X\\).Exercise 3.12  \\(\\) \\(B\\) play game involves rolling fair die simultaneously. Let \\(X\\) absolute difference scores.Tabulate probability mass function \\(X\\).Tabulate probability mass function \\(X\\).Find mean variance \\(X\\).Find mean variance \\(X\\).value \\(X\\) \\(1\\) \\(2\\) \\(\\) wins. \\(X\\) \\(3\\),\\(4\\) \\(5\\) \\(B\\) wins. \\(X\\) zero roll . Find probability \\(\\) wins first go. Find probability \\(\\) wins second go. Find probability \\(\\) wins \\(r^{\\text{th}}\\) go.value \\(X\\) \\(1\\) \\(2\\) \\(\\) wins. \\(X\\) \\(3\\),\\(4\\) \\(5\\) \\(B\\) wins. \\(X\\) zero roll . Find probability \\(\\) wins first go. Find probability \\(\\) wins second go. Find probability \\(\\) wins \\(r^{\\text{th}}\\) go.Find probability \\(\\) wins.Find probability \\(\\) wins.Exercise 3.13  discrete random variable following mass function\\[\\begin{equation*}\n  f(y)=\\begin{cases}\n    \\pi \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  y = 1 \\\\\n    1-\\pi \\ \\  \\ y = 0 .\n  \\end{cases}\n\\end{equation*}\\]\\(0<\\pi<1\\).known Bernoulli distribution.Find \\(\\text{E}[Y]\\) \\(\\text{Var}[Y]\\)","code":""},{"path":"drv.html","id":"exercises-for-feedback-1","chapter":"3 Discrete Random Variables","heading":"3.5.1 Exercises for feedback","text":"Exercise 3.14  Scrabble tiles letters word EXERCISES bag.random tile drawn, probability letter E?random tile drawn, probability letter E?Given letter drawn bag vowel, probability E?Given letter drawn bag vowel, probability E?Explain two questions different words, compare size probabilities either part.Explain two questions different words, compare size probabilities either part.Exercise 3.15  \\(40\\) students Maths class, given number \\(1\\) \\(40\\). Separately numbers \\(1-40\\) placed hat mixed randomly. teacher give three random students prize. Three numbers selected hat without replacement. numbers drawn teacher guesses three numbers writes board.Work probability teacher matching \\(0\\), \\(1\\), \\(2\\) \\(3\\) numbers drawn hat.different occasion, teacher \\(5\\) students tutor group. wants give two prizes Maths students, one tutor group. draw two numbers hat, separately draw one numbers \\(1-5\\) shoe (one hat). writes prediction board selection.Work probability teacher predicting \\(0\\), \\(1\\) \\(2\\) Maths students, getting tutee correct, probability predicting \\(0\\), \\(1\\) \\(2\\) Maths students getting tutee correct.Exercise 3.16  fairground game played \\(5\\) dice. player pays £1 play, every \\(6\\) appears dice player rewarded £\\(6\\).Work probabilities getting \\(0\\),\\(1\\),\\(2\\),\\(\\dots\\),\\(5\\) sixes rolling five dice.Work probabilities getting \\(0\\),\\(1\\),\\(2\\),\\(\\dots\\),\\(5\\) sixes rolling five dice.\\(X\\) profit player game, work expected profit \\(\\text{E}[X]\\).\\(X\\) profit player game, work expected profit \\(\\text{E}[X]\\).Work also variance \\(\\text{Var}[X]\\).Work also variance \\(\\text{Var}[X]\\).Explain think good game .Explain think good game .Exercise 3.17  (Extension / Challenge) play game standard pack \\(52\\) cards. dealt hand \\(3\\) cards. hand contains pair, get \\(3\\) points. hand contains \\(3\\) kind, get \\(10\\) points. hand contains neither pair \\(3\\) kind lose point. expected number points score game?","code":""},{"path":"binpois.html","id":"binpois","chapter":"4 Special discrete random variables","heading":"4 Special discrete random variables","text":"chapter able recognise contexts Binomial distributions arise. Calculate binomial probabilities using formulae. Use binomial tables, calculators R look probabilities.","code":""},{"path":"binpois.html","id":"the-binomial-distribution","chapter":"4 Special discrete random variables","heading":"4.1 The Binomial Distribution","text":"binomial distribution one important discrete distributions finds application wide number areas.example mind following:Example 4.1  (coin tossing) Suppose toss coin \\(10\\) times count number heads observed.fixed number trials, \\(10\\), maximal number heads can observe.fixed number trials, \\(10\\), maximal number heads can observe.coin , probability heads throughout process. fair coin \\(\\frac{1}{2}\\).coin , probability heads throughout process. fair coin \\(\\frac{1}{2}\\).coin tosses independent. physical reason previous outcome may make heads less likely subsequent tosses.coin tosses independent. physical reason previous outcome may make heads less likely subsequent tosses.two outcomes coin toss: heads tails.two outcomes coin toss: heads tails.binomial distribution can used find probabilities whenever following conditions met:probability observing success single experiment fixed quantity, probability constant \\(\\text{P}(\\text{success}) = \\pi\\). (P constant probability)probability observing success single experiment fixed quantity, probability constant \\(\\text{P}(\\text{success}) = \\pi\\). (P constant probability)trials independent. ()trials independent. ()number experiments, trials, fixed number maximum value attainable. (N maximum number)number experiments, trials, fixed number maximum value attainable. (N maximum number)two outcomes.(T two outcomes)two outcomes.(T two outcomes)list assumptions underlying binomial model can summarised mnemonic PINT.Although can check mnemonic satisfied, may practicebe easier given situation make analogy coin tossing example. particular context number well vary, definition ‘success’. example, suppose considering many number men \\(50\\), suffer heart attack next year. ‘success’ heart attack!","code":""},{"path":"binpois.html","id":"the-binomial-mass-function","chapter":"4 Special discrete random variables","heading":"4.2 The binomial mass function","text":"Example 4.2  throw five drawing pins air note land pin pin . many ways can two pins land facing others land face ?Suppose probability single pin lands facing \\(0.3\\), probability exactly two land facing ?solutionConsider problem word UUDDD, many different words can obtained rearrangement? number ways rearranging \\(\\frac{5!}{2!}{3!} = 10\\).Note one choice numbers \\(^5C_2\\). choosing \\(5\\) things, two face remaining ones face .choice two pins calculation probability. , \\(0.3^2 \\times 0.7^3\\).Altogether probability \\(^5C_2 \\times 0.3^2 \\times 0.7^3\\).can derive binomial mass function similar way example.Theorem 4.1  Suppose random variable \\(X\\) satisfies conditions binomial random variable, \\(n\\) trials success probability \\(\\pi\\). mass function given :\n\\[\\text{P}(X=x) = {}^nC_x \\pi^{x}(1-\\pi)^{n-x}\\]Proof. \\(n\\) trials result \\(x\\) successes, probability \\(\\pi\\), must also \\(n-x\\) failures probability \\((1-\\pi)\\). Using independence, probability happening \\[\\pi ^x (1-\\pi)^{n-x} \\]\nnumber ways can happen, equal \\(^nC_x\\). Hence result.Example 4.3  Suppose fair die rolled four times. probability getting,exactly one six?exactly one six?\\(1\\) six?\\(1\\) six?solutionA common mistake \\(\\frac{1}{6}\\times \\left( \\frac{5}{6} \\right)^3\\). correct - ? can happen \\(^4C_1=4\\) ways,\\[4\\times \\frac{1}{6}\\times \\left( \\frac{5}{6} \\right)^3 = 0.386 \\text{ (3 s.f.)}\\]\\(X\\) number sixes, one means \\(X \\leq 1\\). work adding two cases \\(X=0\\) \\(X=1\\) together. One calculate directly mass function follows:\\[^4C_0 \\times \\left( \\frac{1}{6} \\right)^0 \\times \\left( \\frac{5}{6} \\right)^4+ ^4C_1 \\times \\left( \\frac{1}{6} \\right)^1 \\times \\left( \\frac{5}{6} \\right)^3\\]\nObtaining \\(0.868\\text{ (3 s.f.)}\\).examples binomial probability distributions given following figures.\nFigure 4.1: Probability mass function B(9,0.2)\n\nFigure 4.2: Probability mass function B(8,0.5)\ncan account seemingly different shape?success probability close \\(0.5\\) distribution symmetrical shape, otherwise skewed.Example 4.4  train station \\(5\\) self-service ticket machines. probability machine working time \\(0.15\\). Let \\(X\\) number machines working.Comment whether binomial distribution suitable model \\(X\\).Assuming binomial distribution X, evaluate probability following number machines working.exactly \\(2\\).exactly \\(2\\).least \\(4\\).least \\(4\\).\\(2\\).\\(2\\).solutionChecking mnemonic PINT works. ‘success’ ticket machine working. Independence might hold example one machine working caused others also fail somehow, probability time including time others failed.Checking mnemonic PINT works. ‘success’ ticket machine working. Independence might hold example one machine working caused others also fail somehow, probability time including time others failed.\\(\\text{P}(X=2) = ^5C_2 \\times 0.15^2 \\times (1-0.15)^{5-2} = 0.138\\).\\(\\text{P}(X=2) = ^5C_2 \\times 0.15^2 \\times (1-0.15)^{5-2} = 0.138\\).\\(\\text{P}(X\\geq 4) = \\text{P}(X=4) + \\text{P}(X=5)\\). Evaluating formulae gives:\\(\\text{P}(X\\geq 4) = \\text{P}(X=4) + \\text{P}(X=5)\\). Evaluating formulae gives:\\[= {}^5C_4 \\times 0.15^4 \\times (1-0.15)^{5-4}+ ^5C_5 \\times 0.15^5 \\times (1-0.15)^{5-5}\\]\n\\[= 0.0022\\]\\(\\text{P}(X\\leq 2) = \\text{P}(X=0) + \\text{P}(X=1) + \\text{P}(X=2)\\). evaluating formula term sum gives:\\[= {}^5C_0 \\times 0.15^0 \\times (1-0.15)^{5-0}+ {}^5C_1 \\times 0.15^1 \\times (1-0.15)^{5-1}+ {}^5C_2 \\times 0.15^2 \\times (1-0.15)^{5-2}\\]\n\\[ = 0.973 \\]Alternatively, number cases add large enough tedious hand calculation (need add cases together), one may consult statistical tables CDF.binomial distribution widely applied important, almost every book statistical tables contain pages binomial CDF. tables used MMU give probabilities selected values \\(n\\) \\(\\pi\\) form \\(\\text{P}(X\\leq x)\\). probability can calculated tables using rules like following:\\(\\text{P}(X\\leq x)\\), directly table.\\(\\text{P}(X\\leq x)\\), directly table.\\(\\text{P}(X\\geq x) = 1- \\text{P}(X\\leq x-1)\\), using complements.\\(\\text{P}(X\\geq x) = 1- \\text{P}(X\\leq x-1)\\), using complements.\\(\\text{P}(X = x) = \\text{P}(X\\leq x) - \\text{P}(X\\leq x-1)\\), getting mass function CDF usual way.\\(\\text{P}(X = x) = \\text{P}(X\\leq x) - \\text{P}(X\\leq x-1)\\), getting mass function CDF usual way.can probability \\(X\\) lying range , one must careful whether inequality strict .\\(\\text{P}(\\leq X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(\\leq X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(< X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq )\\)\\(\\text{P}(< X\\leq b) = \\text{P}(X\\leq b) - \\text{P}(X\\leq )\\)\\(\\text{P}(\\leq X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(\\leq X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq -1)\\)\\(\\text{P}(< X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq )\\)\\(\\text{P}(< X < b) = \\text{P}(X\\leq b-1) - \\text{P}(X\\leq )\\)Graphing inequality listing required values \\(X\\) helps improve accuracy , recommend learning just rules .modern times commonly consult calculator, tables recorded memory. example, R can calculation 4.3 using following commands.geometric distribution, binomial distribution function called R \\(\\texttt{dbinom()}\\), \\(\\texttt{d}\\) stands distribution \\(\\texttt{binom}\\) binomial distribution.","code":"\ny <- dbinom(x=0:1, size = 4, prob = 1/6 ) # putting x=0:1 makes y take the two values we want\nsum(y) # working out the sum is easy now## [1] 0.8680556"},{"path":"binpois.html","id":"mean-and-variance","chapter":"4 Special discrete random variables","heading":"4.3 Mean and variance","text":"goal find simple expressions mean variance binomial distribution. choose directly, though methods may see next year.Theorem 4.2  binomially distributed random variable \\(X\\sim \\text{Bin}(n,\\pi)\\) mean product number trials success probability. ,\\[\\text{E}[X] = n\\pi \\]variance \\(X\\) product mean failure probability. ,\\[ \\text{Var}[X] = n\\pi (1-\\pi)\\]Proof. Starting definition,\\[ \\text{E}[X] = \\sum_{x=0}^{n}x\\times \\text{P}(X=x)\\]\nCombining mass function gives\\[ \\text{E}[X] = \\sum_{x=0}^{n}x\\times ^{n}C_{x} \\pi^x (1-\\pi)^{n-x} \\]\ndefinition numbers \\(^{n}C_{x}\\),\\[ \\text{E}[X] = \\sum_{x=0}^{n}x\\times \\frac{n!}{x!\\times(n-x)!} \\pi^x (1-\\pi)^{n-x} \\]\nNow first term sum \\(x=0\\), \\(x\\) factor sum actually starts \\(x=1\\).\n\\[  = \\sum_{x=1}^{n} \\frac{n!}{(x-1)!\\times(n-x)!} \\pi^x (1-\\pi)^{n-x} \\]\n\\[  = n\\pi\\sum_{x=1}^{n} \\frac{(n-1)!}{(x-1)!\\times(n-x)!} \\pi^{x-1} (1-\\pi)^{n-x} \\]\nNow letting \\(m=n-1\\) \\(y=x-1\\) sum becomes,\\[  = n\\pi\\sum_{y=0}^{m} \\frac{m!}{y!\\times(m-y)!} \\pi^{y} (1-\\pi)^{m-y} \\]\nterm sum binomial probability \\(Y\\sim \\text{Bin}(m,\\pi)\\), altogether sum equal \\(1\\).Hence \\(\\text{E}[X] = n\\pi\\).variance omit proof longer instructive.interested reader consider \\(\\text{E}[X(X-1)]\\) \\(\\text{E}[X^2]\\), manipulations sums similar .","code":""},{"path":"binpois.html","id":"the-poisson-distribution","chapter":"4 Special discrete random variables","heading":"4.4 The Poisson distribution","text":"distribution invented French mathematician Simeon Poisson, distribution bears namesake appears capitalised unlike binomial distribution.Poisson distribution can applied remarkable number areas involving counting processes. examples include.number ‘goals’ scored sports game.number ‘goals’ scored sports game.number sales per week.number sales per week.number Website visitors per hour.number Website visitors per hour.number arrivals &E Manchester Royal Infirmary day.number arrivals &E Manchester Royal Infirmary day.number bacterial growths given area, Petri dish.number bacterial growths given area, Petri dish.Poisson distribution may applied whenever random variable interest counts number events given interval, number without bound (though larger counts less likely). events occur one time, independently randomly given interval. events occur uniformly given interval, mean number events proportional size interval - events occur constant average rate.mnemonic SIR/MR can used summarise paragraph.S - simultaneouslyI - IndependentR - RandomlyM - maximum number eventsR - constant average rateExample 4.5  (telephone calls) Let number telephone calls arriving switchboard minute random variable \\(X\\). \\(X\\) satisfies assumptions modelled Poisson distribution.Poisson distribution depends one parameter - mean rate \\(\\lambda\\). pictures Poisson distribution functions different values mean rate.\nFigure 4.3: Probability mass function Pois(3)\n\nFigure 4.4: Probability mass function Pois(6)\nDefinition 4.1  Given random variable following Poisson distribution \\(X\\sim \\text{Pois}(\\lambda)\\) mass function given :\\[\\text{P}(X=x) = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\]\n\\(x=0,1,2, \\dots\\), \\(\\lambda>0\\).Although probabilities attached higher values \\(x\\) positive, quickly become small. mean rate \\(\\lambda\\) need whole number, even though count given interval need whole number. binomial distribution, tables given CDF Poisson distribution.Example 4.6  company operates helpdesk hotline service. Incoming calls hotline arrive mean rate \\(3.5\\) per minute outgoing calls made rate \\(4.2\\) per minute. Find probability thatat least five calls arrive one minute.least five calls arrive one minute.exactly five calls arrive one minute.exactly five calls arrive one minute.7 calls outgoing one minute.7 calls outgoing one minute.\\(4\\) \\(9\\) calls inclusive outgoing one minute.\\(4\\) \\(9\\) calls inclusive outgoing one minute.solution\\(\\text{P}(X\\geq 5) = 1 - \\text{P}(X\\leq 4) = 1-0.7254 = 0.2746\\)\\(\\text{P}(X\\geq 5) = 1 - \\text{P}(X\\leq 4) = 1-0.7254 = 0.2746\\)\\(\\text{P}(X=5) = \\text{P}(X\\leq 5) - \\text{P}(X\\leq 4) = 0.8576 - 0.7254 = 0.1322\\)\\(\\text{P}(X=5) = \\text{P}(X\\leq 5) - \\text{P}(X\\leq 4) = 0.8576 - 0.7254 = 0.1322\\)\\(\\text{P}(Y\\leq 7) = 0.9361\\)\\(\\text{P}(Y\\leq 7) = 0.9361\\)\\(\\text{P}(4\\leq Y \\leq 9 ) = \\text{P}(Y\\leq 9) - \\text{P}(Y\\leq 3) = 0.9889 - 0.3954 = 0.5935\\).\\(\\text{P}(4\\leq Y \\leq 9 ) = \\text{P}(Y\\leq 9) - \\text{P}(Y\\leq 3) = 0.9889 - 0.3954 = 0.5935\\).","code":""},{"path":"binpois.html","id":"further-properties","chapter":"4 Special discrete random variables","heading":"4.4.1 Further properties","text":"important aspect Poisson model uniform average rate. means assume events occur rate interval. size interval changes, must change mean rate direct proportion change size.Example 4.7  (hotline continued) assume calls hotline incoming rate \\(3.5\\) per minute. Find probability thatat least \\(20\\) calls arrive exchange \\(4\\) minute period.least \\(20\\) calls arrive exchange \\(4\\) minute period.\\(1\\) call arrives \\(12\\) second period.\\(1\\) call arrives \\(12\\) second period.solutionIf \\(3.5\\) calls per minute, \\(4\\) minute period one expects rate \\(3.5\\times 4=14\\) calls.Let \\(W\\) number calls \\(4\\) minute period. \\(W\\sim\\text{Pois}(14)\\). ,\\[\\text{P}(W\\geq 20) = 1- \\text{P}(W\\leq 19) = 1-0.9235 = 0.0765.\\]\\(12\\) seconds one fifth minute, expect rate \\(3.5\\div 5 = 0.7\\) calls.Let \\(Z\\) number calls \\(12\\) second period. ,\\[\\text{P}(Z\\leq 1) = 0.8442\\]second useful property different Poisson variables can added together yield another Poisson distribution whose rate parameter sum individual rates.Theorem 4.3  , \\(X\\sim \\text{Pois}(\\lambda)\\) \\(Y\\sim \\text{Pois}(\\mu)\\) \n\\[X+Y \\sim \\text{Pois}(\\lambda+\\mu)\\]Proof. Omitted now. second year course learn moment generating functions makes proof easy.Example 4.8  Suppose game football home team scores goals rate \\(2\\) per match, away team scores goals rate \\(3\\) per match. expect total number goals two teams occur rate \\(5\\) per match.context particular pair teams may realistic model. ?","code":""},{"path":"binpois.html","id":"mean-and-variance-1","chapter":"4 Special discrete random variables","heading":"4.5 Mean and Variance","text":"section consider mean variance Poisson distribution.need Mathematical preliminaries Calculus.Proposition 4.1  (characterisations Euler's number) real number \\(x \\\\mathbb{R}\\) \\[e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}\\]\\[ \\lim_{n\\\\infty} \\left( 1+\\frac{x}{n} \\right)^n = e^x\\]Theorem 4.4  Let \\(X\\) Poisson distributed random variable rate \\(\\lambda\\), \\(X\\sim \\text{Pois}(\\lambda)\\). \\[\\text{E}[X]  = \\lambda\\]\n\n\\[\\text{Var}[X] = \\lambda\\]Proof. \\[\\text{E}[X] = \\sum_{x=0}^{\\infty}x\\frac{\\lambda^x e^{-\\lambda}}{x!}\\]\n\\[ =\\lambda e^{-\\lambda} \\sum_{x=1}^{\\infty}\\frac{\\lambda^{(x-1)}}{(x-1)!} \\]\n\\[=\\lambda e^{-\\lambda} \\sum_{y=0}^{\\infty}\\frac{\\lambda^{y}}{y!} \\]\n\\[=\\lambda e^{-\\lambda} e^{\\lambda}  \\]\n\\[ = \\lambda .\\]\nvariance consider\\[\\text{E}[X(X-1)] = \\sum_{x=0}^{\\infty}x(x-1)\\frac{\\lambda^x e^{-\\lambda}}{x!}\\]\n\\[ =\\lambda^2e^{-\\lambda} \\sum_{x=2}^{\\infty}\\frac{\\lambda^{x-2}}{(x-2)!}\\]\n\\[ =\\lambda^2e^{-\\lambda} \\sum_{y=0}^{\\infty}\\frac{\\lambda^y}{y!}\\]\n\\[ =\\lambda^2e^{-\\lambda} e^{\\lambda}\\]\n\\[ =\\lambda^2\\]\n\\(\\text{E}[X(X-1)] = \\text{E}[X^2] - \\text{E}[X]\\), can rearrange find \\[\\text{E}[X^2] = \\lambda^2 + \\lambda \\]variance \\(\\text{Var}[X] = \\text{E}[X^2] - \\text{E}[X]^2\\), :\\[\\text{Var}[X] = \\lambda^2 + \\lambda - \\lambda ^2 = \\lambda .\\]","code":""},{"path":"binpois.html","id":"deriving-the-poisson-mass-function","chapter":"4 Special discrete random variables","heading":"4.6 Deriving the Poisson mass function","text":"Poisson distribution intimately linked binomial distribution. aim section show mass function form given definition.Suppose events occur result Poisson process independently uniform rate \\(\\lambda\\) given time interval. Divide time period large number smaller intervals, \\(n\\) say, chance two events happening one interval negligible. probability event happening one small intervals \\(\\lambda / n\\).Letting \\(X\\) random variable representing number small intervals contain event, can see one hand binomially distributed fixed \\(n\\). \\[ \\text{P}(X=x) = {}^nC_{x} \\left(\\frac{\\lambda}{n}\\right)^x \\left( 1- \\frac{\\lambda}{n}\\right)^{n-x}\\]\\[ = \\lambda^{x} \\underbrace{\\frac{^nC_{x}}{n^x}}_{1} \\underbrace{\\left( 1- \\frac{\\lambda}{n}\\right)^{n}}_{2}\\underbrace{\\left( 1- \\frac{\\lambda}{n}\\right)^{-x}}_{3} \\]consider happens increase \\(n\\), consider term separately (allowed convergent sequences).term \\(2\\), \\(n\\) gets larger number inside bracket gets close \\(1\\), overall limit \\(1\\).term \\(3\\) can seen equal \\(e^{-\\lambda}\\) proposition (B).first term \\(1\\), can manipulated follows:\\[\\lim_{n\\\\infty}\\frac{^nC_{x}}{n^x} = \\lim_{n\\\\infty} \\frac{n!}{(n-x)!x!n^x}\\]\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{n(n-1)(n-2)\\dots(n-x+1)}{n^x}\\]\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{n}{n}\\frac{(n-1)}{n}\\frac{(n-2)}{n}\\dots \\frac{(n-x+1)}{n}\\]\n\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{n}{n}\\frac{(n-1)}{n}\\frac{(n-2)}{n}\\dots \\frac{(n-x+1)}{n}\\]\n\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\frac{(n-1)}{n}\\frac{(n-2)}{n}\\dots \\frac{(n-x+1)}{n}\\]\n\\[ =\\frac{1}{x!}  \\lim_{n\\\\infty} \\left(1 - \\frac{1}{n}\\right)\\lim_{n\\\\infty}\\left(1 - \\frac{2}{n}\\right)\\dots \\lim_{n\\\\infty} \\left(1 - \\frac{x-1}{n}\\right)\\]\nlimits \\(1\\).Altogether ,\\[lim_{n\\\\infty} {}^nC_{x} \\left(\\frac{\\lambda}{n}\\right)^x \\left( 1- \\frac{\\lambda}{n}\\right)^{n-x}  = \\lambda^x \\times \\frac{1}{x!} \\times e^{-\\lambda}\\times 1 = \\frac{\\lambda^xe^{-\\lambda}}{x!}.\\]\nprobability observing \\(x\\) events whole time interval.side relationship Poisson distribution can used approximate binomial distribution.Theorem 4.5  \\(\\pi\\) small \\(n\\) large , binomial distribution can approximated Poisson distribution rate parameter equal mean binomial distribution.\\[\\text{Binom}(n,\\pi) \\approx \\text{Pois} (\\lambda)\\]\nset \\(\\lambda = n\\pi.\\)proof\nOmitted.","code":""},{"path":"binpois.html","id":"exercises-week-4","chapter":"4 Special discrete random variables","heading":"4.7 Exercises week 4","text":"Exercise 4.1  Ropes tested certain breaking strain. According past experience quarter ropes break strain. \\(4\\) identical ropes tested, write probability distribution number ropes breaking.Exercise 4.2  estimated \\(20\\%\\) individuals carry anibodies particular virus. probability group \\(20\\) randomly selected individuals:\\(8\\) antibodies.\\(8\\) antibodies.Exactly \\(6\\) antibodies.Exactly \\(6\\) antibodies.Fewer \\(4\\) antibodies.Fewer \\(4\\) antibodies.\\(3\\) \\(6\\) inclusive antibodies.\\(3\\) \\(6\\) inclusive antibodies.Exercise 4.3  car salesperson knows past experience make sale \\(30\\%\\) customers. Find probability \\(20\\) randomly selected sales pitches makes sale toMore 4 customersMore 4 customersFewer \\(7\\) customersFewer \\(7\\) customersExactly \\(6\\) customersExactly \\(6\\) customersbetween \\(4\\) \\(10\\) exclusive.\\(4\\) \\(10\\) exclusive.Exercise 4.4  footballer takes free kick scores goal \\(10\\%\\) occasions. Find probability match \\(10\\) free kicks takenShe scores least two goalsShe scores least two goalsShe scores exactly two goalsShe scores exactly two goalsShe scores \\(3\\) goals fewer.scores \\(3\\) goals fewer.goals free kicks alone. assumptions need make, extent think reasonable?Exercise 4.5  statistics lecturer sets test involving \\(20\\) multiple choice questions, four possible answers question. want choose pass mark chance passing student guesses every question less \\(5\\%\\). pass mark ?Exercise 4.6  game advanced Chuck--luck extension simple game last week’s exercises. banker rolls \\(n\\) dice player wins £\\(x\\) number player guesses appears \\(x\\) \\(n\\) dice. loses £\\(1\\) stake number come dice.Write probability mass function \\(X\\).Write probability mass function \\(X\\).Show \\(\\text{E}[X] = \\frac{n}{6} - 1\\)Show \\(\\text{E}[X] = \\frac{n}{6} - 1\\)(Hint might want build part () particular picking values \\(n=1,2,3,\\dots\\) pattern spotting.)Exercise 4.7  biologist field trip studying biodiversity found number plant species \\(1 \\  \\text{m}^2\\) quadrat follows Poisson distribution mean \\(6\\).Find probability number plant species given \\(1 \\  \\text{m}^2\\) quadrat ;least 8at least 8less equal \\(8\\)less equal \\(8\\)exactly \\(8\\)exactly \\(8\\)\\(6\\) \\(12\\) inclusivebetween \\(6\\) \\(12\\) inclusiveFind probability quadrat area \\(0.5 \\  \\text{m}^2\\), number plant species isat least \\(3\\)least \\(3\\)fewer \\(5\\)fewer \\(5\\)exactly \\(4\\)exactly \\(4\\)\\(3\\) \\(6\\) inclusivebetween \\(3\\) \\(6\\) inclusiveExercise 4.8  car leaves production line carefully examined signs imperfection paintwork. Previous experience shown number blemishes per car follows Poisson distribution mean \\(0.4\\).\n) Find probability car hasat least one blemishat least one blemishmore one blemishmore one blemishexactly one blemishexactly one blemishno blemishesno blemishesIn \\(1\\) hour inspector can examine \\(20\\) cars. Assuming blemishes occur independently, find probability inspector findsfewer \\(5\\) blemishesfewer \\(5\\) blemishesexactly five blemishesexactly five blemishesat least one blemishat least one blemishExercise 4.9  traffic survey found buses pass checkpoint average rate \\(4.5\\) per hour. Lorries pass checkpoint rate \\(5\\) per hour coaches rate \\(1.5\\) per hour.Find probability \\(1\\) hour\\(5\\) buses pass checkpoint\\(5\\) buses pass checkpointbetween \\(10\\) \\(15\\) lorries inclusive pass checkpointbetween \\(10\\) \\(15\\) lorries inclusive pass checkpointfewer \\(3\\) buses pass checkpointfewer \\(3\\) buses pass checkpointAt least \\(8\\) buses coaches pass checkpoint hour\nleast \\(8\\) buses coaches pass checkpoint hourexactly \\(15\\) buses coaches pass checkpoint hourexactly \\(15\\) buses coaches pass checkpoint hourten fewer buses, lorries coaches pass checkpoint half hour.ten fewer buses, lorries coaches pass checkpoint half hour.Exercise 4.10  numbers emissions per minute two radioactive rocks \\(\\) \\(B\\) independent Poisson variables means \\(0.65\\) \\(0.45\\) respectively. Find probability thatIn period three minutes least three emissions \\(\\).period three minutes least three emissions \\(\\).period two minutes total less four emissions \\(\\) \\(B\\) combined.period two minutes total less four emissions \\(\\) \\(B\\) combined.Exercise 4.11  particular form cancer, deformed blood corpuscles occur random rate \\(10\\) per \\(1000\\) corpuscles.Use appropriate approximation determine probability random sample \\(200\\) corpuscles taken cancerous area contain deformed corpuscles.Use appropriate approximation determine probability random sample \\(200\\) corpuscles taken cancerous area contain deformed corpuscles.large sample taken order \\(99\\%\\) certain least one deformed corpuscle sample?large sample taken order \\(99\\%\\) certain least one deformed corpuscle sample?Exercise 4.12  (counting practice) box contains \\(12\\) golf balls, \\(3\\) substandard. random sample \\(4\\) balls selected, without replacement, box. random variable \\(R\\) denotes number balls sample substandard.Show probability mass function \\(R\\) satisfies\\[\\text{P}(R=r) = \\frac{{}^3C_r \\times {}^9C_{4-r}}{^{12}C_{4}} \\]\n(ii) Determine probability \\(R=0\\)Determine probability fewer two substandard balls.large bin contains \\(5000\\) used golf balls, \\(1500\\) defective. random variable \\(X\\) denotes number defective balls random sample 20balls selected, without replacement,bin. Explain \\(X\\) may approximated binomial variable parameters \\(20\\) \\(0.3\\). Using binomial model, calculate probability sample containsfewer \\(5\\) defective ballsfewer \\(5\\) defective ballsat least \\(7\\) defective ballsat least \\(7\\) defective ballsExercise 4.13  independent Poisson random variables \\(X\\) \\(Y\\)means \\(2.5\\) \\(1.5\\) respectively. Obtain mean variance random variables , hence give reason Poisson.\n) \\(X-Y\\)\nb) \\(2X+5\\)","code":""},{"path":"cont.html","id":"cont","chapter":"5 Continuous random variables","heading":"5 Continuous random variables","text":"chapter learn continuous random variables. random variable may arise measurement process.real life many observations assumed take real numbered values. principle observe value continuum. example:lifetime lithium-ion batteryThe lifetime lithium-ion batteryThe weight babyThe weight babyThe height random personThe height random personIn practice constrained accuracy measuring device (heights often quoted nearest inch, centimeter) distinction discrete continuous sometimes blurred.Example 5.1  Consider class undergraduates MMU. following measurement age:Age nearest decadeAge nearest decadeAge yearsAge yearsAge monthsAge monthsAge daysAge daysAge secondsAge secondsAlthough none variables strictly measured continuous scale, measure variables differently. decades take particular values modelled discrete, whereas age seconds take many different values ’s almost continuous.","code":""},{"path":"cont.html","id":"relation-to-histograms","chapter":"5 Continuous random variables","heading":"5.1 Relation to histograms","text":"Given actual continuous data, one make plot frequently data lies within certain intervals. resulting plot called histogram. intervals need equal, modern practice . computer implementations intervals called bins interval size bin width.classic example built R Old Faithful geyser data. waiting times eruptions duration eruption recorded Old Faithful geyser Yellowstone National Park, Wyoming, USA.Suppose want estimate proportion probability particularly long waiting time. instead bar height equal frequency can set area proportional frequency. can done way make total area histogram equal \\(1\\).\nFigure 5.1: Waiting time eruptions, one sees data precision smaller bin width\nfind proportion two values one total area bars. One can see limit idea, perhaps large sample smooth curve like plot titled ‘estimated density’, find area curve.","code":""},{"path":"cont.html","id":"two-students","chapter":"5 Continuous random variables","heading":"5.2 Two students","text":"Consider two students appointment tutor \\(12\\)-noon.first student makes effort get time, likely little late late, live far university. may late certainly \\(1\\) o’clock.\nsecond student forgotten appointment, lives close university, may arrive time \\(1\\) o’clock, soon remember.sample space ?Take \\(\\Omega = [0,1]\\) delay measured hours. event interval student arrives. example \\([0,\\frac{1}{2}]\\) event student half hour late.probability arriving given interval area curve \\[f(x) = 2-2x \\ ,\\ \\text{} x\\[0,1].\\]shown image :\nFigure 5.2: density function first student\nprobability student arriving first half hour, \\(12:00\\) \\(12:30\\), \\(\\frac{3}{4}\\), whereas probability arriving last half hour, \\(12:30\\) \\(13:00\\), \\(\\frac{1}{4}\\).time second student arrives may modelled function\\[f(x) = 1\\ ,\\ \\text{} x\\[0,1].\\]called uniform density reflects fact time equally likely.\nFigure 5.3: density function second student\nprobability related function \\(\\text{P}([,b]) = b-\\).Can find expression \\(\\text{P}([,b])\\) first student?","code":""},{"path":"cont.html","id":"the-probability-density-function","chapter":"5 Continuous random variables","heading":"5.3 The probability density function","text":"continuous random variables equivalent probability mass function called probability density function.discrete random variables makes sense ask probability \\(X\\) takes particular value \\(\\text{P}(X=x)\\), always zero continuous setting. Instead probability \\(X\\) lying interval \\(\\text{P}(<X<b)\\).Definition 5.1  probability density functionof continuous random variable \\(X\\) function thatThe function everywhere non-negative\n\\[f(x) \\geq 0 \\text{ } \\ x\\\\mathbb{R}\\]function everywhere non-negative\n\\[f(x) \\geq 0 \\text{ } \\ x\\\\mathbb{R}\\]probability \\(X\\) taking value interval \\((,b)\\) given corresponding integral curve respect \\(x\\).probability \\(X\\) taking value interval \\((,b)\\) given corresponding integral curve respect \\(x\\).\\[\\text{P}(<X<b) = \\int_{}^{b} f(x) \\  dx\\]total area graph domain \\(f(x)\\) unity. Let domain \\(f(x)\\) \\(x\\(c,d)\\).\\[ \\int_{c}^{d} f(x) \\  dx = 1\\]Example 5.2  continuous random variable \\(X\\) probability density function given \\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{2}x, &  0< x < 2\\\\\n    0 & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Calculate \\(\\text{P}(X>1)\\).solutionyou sketch get intuition whether probability half.use calculus , draw picture area required trapezium.area therefore \\(\\frac{(\\frac{1}{2}+1)\\times 1}{2}=\\frac{3}{4}\\).Example 5.3  continuous random variable probability density function \\(f(x) = kx^2\\) \\(0\\leq x\\leq 4\\).Find value constant \\(k\\)Find value constant \\(k\\)Find \\(\\text{P}(1\\leq X \\leq 3)\\)Find \\(\\text{P}(1\\leq X \\leq 3)\\)solutionWe need use calculus curve.find \\(k\\), use fact \\(f\\) integrates \\(1\\) domain.\\[ \\int_{0}^{4}kx^2 \\ dx = \\left[ \\frac{kx^3}{3}\\right]^{x=4}_{x=0}\\]\\[ 1= \\frac{k}{3} (64-0)\\]\n\\[ 1= \\frac{64k}{3} \\]\nHence \\(k=\\frac{3}{64}\\).\\[\\text{P}(1\\leq X \\leq 3) = \\int_{1}^{3} \\frac{3}{64}x^2 \\ dx\\]Evaluating numerically gives \\(0.406\\) \\(3\\) significant figures.Notice inequality \\(1<X<3\\) combination \\(<\\) \\(\\leq\\) calculation , need worry inequality strict continuous random variables.area single \\(x\\) value zero width, contribute integral.","code":""},{"path":"cont.html","id":"expectation-and-variance","chapter":"5 Continuous random variables","heading":"5.4 Expectation and variance","text":"expectation defined similarly case discrete random variables, use integral rather sum.Definition 5.2  expectation, expected value mean value continuous random variable \\(X\\) given \\[ \\text{E}[X] = \\int_{-\\infty}^{\\infty}x f(x) \\ dx\\]\nlimits indicate integral smallest largest attainable values \\(X\\). mean value often denotes \\(\\text{E}[X] = \\mu\\).generally define\\[ \\text{E}[g(X)] = \\int_{-\\infty}^{\\infty}g(x) f(x) \\ dx\\]Definition 5.3  variance continuous random variable given \\[\\text{Var}[X] = \\text{E}[(X-\\mu)^2] = \\text{E}[X^2]-\\mu^2\\]\nstandard deviation \\(\\sigma\\) \\(X\\) square root variance. \\[\\sigma = \\sqrt{\\text{Var}[X]}\\]Example 5.4  (marathon times) times excess \\(2\\) hours taken complete marathon road race modelled continuous random variable \\(T\\) hours, \\(T\\) probability density function\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n    \\frac{4}{27}t^2(3-t), &  0< x < 3\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Find mean standard deviation times taken complete race.solutionFor mean\\[ \\text{E}[T] = \\int_{0}^{3} t\\times \\frac{4}{27}t^2(3-t) \\ dt\\]can evaluated (example numerically) \\(\\frac{9}{5}\\). can interpreted \\(1\\) hour \\(48\\) minutes excess \\(2\\) hours, mean time \\(3\\) hours \\(48\\) minutes.variance use \\(\\text{Var}[T]=\\text{E}[X^2]-\\text{E}[X]^2 = \\frac{18}{5} - (\\frac{9}{5})^2 =\\frac{9}{25}\\). interpretation \\(21.6\\) minutes variance, \\(\\sigma = \\sqrt{21.6} = 4.65\\) minutes (\\(3\\) s.f.) standard deviation","code":""},{"path":"cont.html","id":"mode","chapter":"5 Continuous random variables","heading":"5.5 Mode","text":"probability density function unique maximum value \\(X\\) maximum called mode. locate mode good idea draw sketch. Sometimes mode can deduced immediately. times one may need differentiate.Example 5.5  Deduce mode following cases\\[f(x) = \\frac{1}{8}x , 0\\leq x \\leq 4\\]\\[f(x) = \\frac{1}{8}x , 0\\leq x \\leq 4\\]\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n \\frac{1}{4}x, &  0< x \\leq 2 \\\\\n 1-\\frac{1}{4}x & \\ \\  2< x \\leq 4 \\\\\n 0& \\ \\ \\ \\ \\  \\ \\ \\text{otherwise}\n  \\end{cases}\n\\end{equation*}\\]\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n \\frac{1}{4}x, &  0< x \\leq 2 \\\\\n 1-\\frac{1}{4}x & \\ \\  2< x \\leq 4 \\\\\n 0& \\ \\ \\ \\ \\  \\ \\ \\text{otherwise}\n  \\end{cases}\n\\end{equation*}\\]\\[f(x) = \\frac{3}{80}(2+x)(4-x) , \\ \\  0\\leq x \\leq 4.\\]\\[f(x) = \\frac{3}{80}(2+x)(4-x) , \\ \\  0\\leq x \\leq 4.\\]solutionmode 4mode 4mode 2mode 2One differentiate complete square show mode \\(1\\).One differentiate complete square show mode \\(1\\).Example 5.6  (marathon times) times excess \\(2\\) hours taken complete marathon road race modelled continuous random variable \\(T\\) hours, \\(T\\) probability density function\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n    \\frac{4}{27}t^2(3-t), &  0< t < 3\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Find modal time taken complete race.solutionDifferentiating gives\\[f'(t) = \\frac{4}{27}(2t \\times(3-t) + t^2\\times(-1)) = \\frac{4}{27}(6t -3t^2)\\]Setting \\(f'(t)=0\\) yields\\[0 = 3t(2 - t) \\]\neither\\(t=0\\) \\(2\\). modal excess \\(2\\) hours, modal total time \\(2+2=4\\) hours.","code":""},{"path":"cont.html","id":"cdf","chapter":"5 Continuous random variables","heading":"5.6 CDF","text":"cumulative distribution function can defined similar way discrete random variables.Definition 5.4  distribution function simply CDF continuous random variable function defined \\[F(x) = \\text{P}(X\\leq x) = \\text{P}(X< x).\\]function \\(F\\) related density via\\[F(x) = \\int_{-\\infty}^{x}f(u) \\ du\\]\nlower limit \\(-\\infty\\) practice lowest attainable value \\(X\\).hand,\\[ f(x) = \\frac{d}{dx} F(x)\\]facts CDF.Since always impossible value smaller \\(-\\infty\\) larger \\(\\infty\\) \\(F(-\\infty)=0\\) \\(F(\\infty)=1\\)Since always impossible value smaller \\(-\\infty\\) larger \\(\\infty\\) \\(F(-\\infty)=0\\) \\(F(\\infty)=1\\)\\(F\\) called monotonically increasing means either increases remains constant never decreases.\\(F\\) called monotonically increasing means either increases remains constant never decreases.\\(F\\) continuous function, even \\(f\\) .\\(F\\) continuous function, even \\(f\\) .Useful relations \n\\[\\text{P}(c<X<d) = F(d) - F(c)\\]Useful relations \n\\[\\text{P}(c<X<d) = F(d) - F(c)\\]\\[ \\text{P}(X>x) = 1-F(x)\\]Example 5.7  continuous random variable \\(X\\) density\\[f(x) = \\frac{1}{8}x, \\ 0\\leq x\\leq 4\\]\n) Find distribution function \\(F(x)\\) sketch .Evaluate \\(\\text{P}(0.3\\leq X\\leq 1.8)\\)solutionFor values \\(0\\) \\(4\\) \\[F(t) = \\int_{0}^{t} \\frac{1}{8}x \\ dx = \\left[ \\frac{x^2}{16}\\right]^{t}_{0}= \\frac{t^2}{16}\\]Altogether\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n        0 \\ \\ \\ \\ x\\leq 0 \\\\\n        \\frac{x^2}{16} \\ \\ \\   0\\leq x \\leq 4\\\\\n        1 \\ \\ \\ \\ x\\geq 4\n  \\end{cases}\n\\end{equation*}\\]Example 5.8  continuous random variable \\(X\\) density\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        \\frac{x}{3} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\leq x\\leq 2  \\\\\n        -\\frac{2}{3}x+2 \\ \\ \\   2\\leq x \\leq 3\\\\\n        0 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\text{otherwise}\n  \\end{cases}\n\\end{equation*}\\]Find CDF F(x) sketch .solutionThe CDF must found two stages \\(f\\) piecewise function.Integrating interval \\(0\\leq x\\leq 2\\) gives \\(\\frac{x^2}{6}\\)Integrating interval \\(2\\leq x \\leq 3\\), adding integral previous interval, gives \\(-\\frac{x^2}{3} +2x -2\\)Altogether\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n        \\frac{x^2}{6} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ 0\\leq x\\leq 2  \\\\\n        -\\frac{x^2}{3} +2x -2 \\ \\ \\   2\\leq x \\leq 3\\\\\n        1 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\  \\ \\ \\ x\\geq 3\n  \\end{cases}\n\\end{equation*}\\]Generally speaking plot sketch \\(F\\) look vaguely S-shaped.\nFigure 5.4: cumulative distribution function S shaped\ndiscrete random variables sometimes called \\(f\\) distribution function called \\(F\\) cumulative distribution function. However continuous random variables \\(f\\) never called distribution function, called density function, \\(F\\) called distribution function exclusively.","code":""},{"path":"cont.html","id":"median-quartiles-and-percentiles","chapter":"5 Continuous random variables","heading":"5.7 median, quartiles and percentiles","text":"median, quartiles percentiles best expressed terms CDF.median value \\(50\\%\\) way distribution. splits area curve \\(y=f(x)\\) two halves.Definition 5.5  median continuous random variable \\(X\\) value \\(m\\) satisfies either \\[F(m) = 0.5 , \\ \\ \\ \\ \\int_{-\\infty}^{m}f(x) \\ dx = 0.5\\]Definition 5.6  lower quartile \\(Q_1\\) satisfies \\(F(Q_1) = 0.25\\).\nupper quartile \\(Q_3\\) satisfies \\(F(Q_3) = 0.75\\).\nmedian second quartile \\(m=Q_2\\).Definition 5.7  generally one may define percentile \\(P_{\\alpha}\\) \\(\\alpha \\%\\) value \\(F(P_{\\alpha})= \\alpha \\%\\). median \\(50^{\\text{th}}\\) percentile \\(m = P_{50}\\), \\(Q_1 = P_{25}\\), \\(Q_3 = P_{75}\\)Definition 5.8  generally still quantile value \\(q\\) \\(F(q)=p\\) \\(p\\(0,1)\\)Example 5.9  Let’s find median marathon example.\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n    \\frac{4}{27}t^2(3-t), &  0< t < 3\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]First find CDF.range \\(0< t < 3\\)\n\\[F(t) = \\frac{4}{27}\\int_{0}^{t} u^2(3-u) \\ du\\]\\[= \\frac{4}{27}\\left[\\frac{3u^3}{3}-\\frac{u^4}{4}\\right]^{t}_{0} =\\frac{4}{27}\\left( t^3 - \\frac{t^4}{4} \\right)\\]solving \\(F(t)=0.5\\),\\[\\frac{4}{27}\\left(t^3 - \\frac{t^4}{4} \\right)= 0.5\\]\ncan evaluated numerically two values \\(t=3.74\\) \\(t= 1.84\\) first one outside range \\(0< t < 3\\) discarded. median time \\(2+1.84 = 3.84\\) hours complete marathon. just mean.marathon example shows mode, median mean number usually. mode \\(4\\), median \\(3.84\\) mean \\(3.8\\) hours.","code":""},{"path":"cont.html","id":"uniform-distribution","chapter":"5 Continuous random variables","heading":"5.8 Uniform distribution","text":"encountered uniform random variable example forgetful student. characteristic entire domain values \\(X\\) density constant.density constant interval, means \\(f(x) = k\\) \\(\\leq x \\leq b\\). value \\(k\\)?Definition 5.9  continuous random variable follows continuous uniform distribution (sometimes called rectangular) support \\([,b]\\), denoted \\(X\\sim U(,b)\\) probability density function given \\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{b-}, &  < x < b\\\\\n    0 & \\ \\ \\ \\  \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]uniform distribution symmetrical mean equal median, mode .Theorem 5.1  continuous uniform distribution \\(X\\sim U(,b)\\)\\[\\text{E}[X] = \\frac{+b}{2}\\]\\[\\text{Var}[X]= \\frac{(b-)^2}{12}\\]Proof. \\[\\text{E}[X] = \\int_a^b x \\times \\frac{1}{b-} dx  =\\frac{1}{b-} \\left[ \\frac{x^2}{2} \\right]^{b}_{}\\]Now\\[= \\frac{1}{b-} \\left( \\frac{b^2-^2}{2} \\right)\\]\nusing difference two squares\\[= \\frac{1}{b-} \\left( \\frac{(b-)(b+)}{2} \\right)\\]\nHence result, upon cancelling \\((b-)\\).variance consider\\[\\text{E}[X^2] = \\int_a^b x^2 \\times \\frac{1}{b-} dx  =\\frac{1}{b-} \\left[ \\frac{x^3}{3} \\right]^{b}_{}\\]\\[= \\frac{1}{b-} \\left( \\frac{b^3-^3}{3} \\right)\\]using difference cubes\\[= \\frac{1}{b-} \\left( \\frac{(b-)(b^2+ab+^2)}{3} \\right)\\]Hence \\(\\text{E}[X^2] = \\frac{b^2+ab+^2}{3}\\).Now\\[\\text{Var}[X] = \\text{E}[X^2] - \\text{E}[X]^2 = \\frac{b^2+ab+^2}{3} - \\left(\\frac{+b}{2} \\right)^2\\]\\[ = \\frac{4(b^2+ab+^2)- 3(^2 + 2ab +b^2)}{12}\\]\n\\[= \\frac{^2-2ab +b^2}{12}\\]\nHence result factorising numerator.CDF continuous uniform distribution can also found.Proposition 5.1  CDF continuous uniform distribution \\(X\\sim U(,b)\\) form\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n        0 & x \\leq \\\\\n    \\frac{x-}{b-}, &  < x < b\\\\\n    1 & \\ \\ x \\geq b.\n  \\end{cases}\n\\end{equation*}\\]proofFind equation line \\((,0)\\) \\((b,1)\\).","code":""},{"path":"cont.html","id":"exponential-distribution","chapter":"5 Continuous random variables","heading":"5.9 Exponential distribution","text":"exponential distribution like continuous version geometric distribution. Instead counting many attempts event happens, instead measure time event occurs ordinarily occur rate.Consider sequence independent events occuring random points time rate \\(\\lambda\\). learned last week number events occur modelled discrete random variable called Poisson distribution.Instead counting many events occur, consider measuring long wait next event.set starting time \\(x=0\\) denote random variable ‘time first event’ \\(X\\).\\[\\text{P}(X>x) = \\text{P}( \\{\\text{events occur time interval (0,x)}\\})\\]mean number events occur per unit interval \\(\\lambda\\). number events occur interval \\((0,x)\\) length \\(x-0 = x\\) scaled proportionally equals \\(\\lambda \\times x\\).probability obtaining \\(0\\) events Poisson distribution mean \\(\\lambda x\\) \\[\\frac{(\\lambda x)^0 e^{-\\lambda x}}{0!} = e^{-\\lambda x}\\]\n\\[\\text{P}(X>x) =  e^{-\\lambda x}\\]\ncumulative distribution equals\\[F(x) = 1-\\text{P(X>x)}=1-e^{-\\lambda x}\\]Differentiating respect \\(x\\) obtain\\[f(x) = \\lambda e^{-\\lambda x}\\]Definition 5.10  continuous random variable \\(X\\) said exponential distribution, denoted \\(X\\sim \\text{Exp}(\\lambda)\\) density function\\[f(x) = \\lambda e^{-\\lambda x} , x >0\\]Now consider shape exponential distribution.Theorem 5.2  exponential distribution \\(X\\sim \\text{Exp}(\\lambda)\\), \\[\\text{E}[X] = \\frac{1}{\\lambda}\\]\n\\[\\text{Var}[X] = \\frac{1}{\\lambda ^2}\\]Proof. can verified using integration.","code":""},{"path":"cont.html","id":"exercises-week-5","chapter":"5 Continuous random variables","heading":"5.10 Exercises week 5","text":"Exercise 5.1  random variable \\(Y\\) density function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        ky & 0 \\leq y \\leq 4 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show \\(k = \\frac{1}{8}\\) makes valid density functionShow \\(k = \\frac{1}{8}\\) makes valid density functionFind cumulative distribution function \\(F(y)\\)Find cumulative distribution function \\(F(y)\\)Sketch density \\(f\\) \\(F\\) axesSketch density \\(f\\) \\(F\\) axesCalculate \\(\\text{P}(1\\leq Y \\leq 3)\\) two ways, one \\(f\\) one \\(F\\).Calculate \\(\\text{P}(1\\leq Y \\leq 3)\\) two ways, one \\(f\\) one \\(F\\).Calculate mean \\(\\text{E}[Y]\\) variance \\(\\text{Var}[Y]\\) \\(Y\\).Calculate mean \\(\\text{E}[Y]\\) variance \\(\\text{Var}[Y]\\) \\(Y\\).Exercise 5.2  length time minutes serve customer fast food restaurant random variable \\(T\\) density\\[\\begin{equation*}\n  f(t)=\\begin{cases}\n        k(3t^2 + t) & 0 \\leq t \\leq 2 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show \\(k = \\frac{1}{10}\\) makes valid density functionShow \\(k = \\frac{1}{10}\\) makes valid density functionFind cumulative distribution function \\(F(t)\\)Find cumulative distribution function \\(F(t)\\)Sketch density \\(f\\) distribution \\(F\\).Sketch density \\(f\\) distribution \\(F\\).Use graph \\(F\\) find median.Use graph \\(F\\) find median.Calculate probability time serve customer one minute less.Calculate probability time serve customer one minute less.Calculate mean \\(\\text{E}[T]\\) variance \\(\\text{Var}[T]\\) serving times.Calculate mean \\(\\text{E}[T]\\) variance \\(\\text{Var}[T]\\) serving times.Exercise 5.3  Suppose profit certain contractor make one job, thousands pounds, random variable \\(X\\) density function given \\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        c(4x -x^3) & 0 \\leq x \\leq 2 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show \\(k =\\frac{1}{4}\\) makes valid density functionShow \\(k =\\frac{1}{4}\\) makes valid density functionFind expected profit variance profit per contract.Find expected profit variance profit per contract.Find cumulative distribution function \\(F(x)\\) hence median profit level.Find cumulative distribution function \\(F(x)\\) hence median profit level.probability contractor makes profit less £\\(600\\) contract?probability contractor makes profit less £\\(600\\) contract?Assuming profit levels contract independent, probability profit level less £\\(600\\) \n) next \\(10\\) jobs?\nii) exactly \\(4\\) next \\(10\\) jobs?Assuming profit levels contract independent, probability profit level less £\\(600\\) \n) next \\(10\\) jobs?\nii) exactly \\(4\\) next \\(10\\) jobs?(Hint: part (e) use answer (d) appropriate binomial distribution)Exercise 5.4  lifetime mobile phone batters (hundreds hours) random variable \\(X\\) density function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        2xe^{-x^2} &  x \\geq 0 \\\\\n        0 &  \\text{     Otherwise}\n  \\end{cases}\n\\end{equation*}\\]Show valid density function (integrate substitution)Show valid density function (integrate substitution)Find cumulative distribution function.Find cumulative distribution function.Find median lifetime batteryFind median lifetime batteryEvaluate \\(\\text{P}(X\\geq 2)\\)Evaluate \\(\\text{P}(X\\geq 2)\\)Exercise 5.5  Bacteria grow Petri dish circular disk. radius circle \\(R\\) can modelled uniform distribution interval \\(1\\) \\(3\\) cm.Write density distribution functions \\(R\\)Write density distribution functions \\(R\\)Work expected value R variance \\(R\\).Work expected value R variance \\(R\\).area circle random variable \\(\\), determine distribution function \\(\\).\n(Start considering \\(\\text{P}(\\leq )\\) means terms \\(R\\).)area circle random variable \\(\\), determine distribution function \\(\\).\n(Start considering \\(\\text{P}(\\leq )\\) means terms \\(R\\).)Determine density function \\(\\).Determine density function \\(\\).Calculate expected value area \\(\\).Calculate expected value area \\(\\).","code":""},{"path":"cont.html","id":"exercises-for-feedback-week-5","chapter":"5 Continuous random variables","heading":"5.10.1 Exercises for feedback week 5","text":"archer continues shoot target hits bullseye.Give reason may possible model X geometric\ndistribution.archer shoots target around \\(100\\) times \\(5\\%\\) shots hit bullseye.\nSuppose \\(X \\sim Geom(p)\\) \\(p =5\\%\\).Calculate probability shoots target least ten attempts.Calculate probability shoots target least ten attempts.Give reason geometric distribution may appropriate , improve model.Give reason geometric distribution may appropriate , improve model.continuous random variable \\(X\\) density function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n        kx(1-x^2) & 0\\leq x \\leq 1 \\\\\n        0 , &  \\text{   otherwise}\\\\\n  \\end{cases}\n\\end{equation*}\\]Find value constant \\(k\\)Find value constant \\(k\\)Calculate mean variance \\(X\\).Calculate mean variance \\(X\\).Find expression cumulative distribution \\(F_X(x)\\) sketch function.Find expression cumulative distribution \\(F_X(x)\\) sketch function.Hence otherwise calculate \\(\\text{P}(X\\leq \\frac{1}{3})\\).Hence otherwise calculate \\(\\text{P}(X\\leq \\frac{1}{3})\\).(counting practice)box contains \\(12\\) golf balls, \\(3\\) substandard. random sample \\(4\\) balls selected, without replacement, box. random variable \\(R\\) denotes number balls sample substandard.Show probability mass function \\(R\\) satisfies\\[\\text{P}(R=r) = \\frac{{}^3C_r \\times {}^9C_{4-r}}{^{12}C_{4}}\\](hint: count number choices total number ways. may find helpful cases \\(r=0,1,2,3\\) separately.)Determine probability \\(R=0\\)Determine probability \\(R=0\\)Determine probability fewer two substandard balls.Determine probability fewer two substandard balls.","code":""},{"path":"norm.html","id":"norm","chapter":"6 Normal distribution","heading":"6 Normal distribution","text":"already seen examples continuous random variables including uniform distribution exponential distribution. one point view, normal distribution just another example continuous random variable. However normal distribution important distribution probability statistics.","code":""},{"path":"norm.html","id":"relation-to-data","chapter":"6 Normal distribution","heading":"6.1 Relation to data","text":"Suppose weighed \\(1000\\) apples harvest. average weight may \\(100\\) grams, apples may relatively small spread value standard deviation \\(10\\) grams.know draw histogram data R. One can imagine larger sample histogram may resemble closely bell curve left plot.\nFigure 6.1: bell-shaped curve\n","code":""},{"path":"norm.html","id":"cauchy-density","chapter":"6 Normal distribution","heading":"6.2 Cauchy density","text":"study curves like normal distribution can useful consider kinds graphs produce curve single peak (unimodal) zero asymptotically.Consider curve\\[f(x) = \\frac{1}{x^2+1}\\]\nNote \\(f(0)=1\\), square ensures everywhere positive. Notice denominator zero, \\(x^2+1=0\\) real roots.\\(x\\\\infty\\), divide larger larger denominator \\(f(x)\\0\\). Similarly \\(x\\-\\infty\\).People thought curve looked like witch’s hat named Italian Mathematician Maria Agnesi. curve called ‘Witch Agnesi’. graph curve:\nFigure 6.2: Cauchy distribution\nHowever density need integral equal \\(1\\).can consider integral\\[\\int_{\\mathbb{R}}\\frac{1}{x^2+1} \\ dx\\]\ncan use trigonometric substitution , example \\(x=\\tan \\theta\\). \\[\\frac{dx}{d\\theta} = \\sec^2\\theta,\\]\n\\(1+x^2 = 1+\\tan^2\\theta = \\sec^2 \\theta\\).\\[\\int_{\\mathbb{R}}\\frac{1}{x^2+1} \\ dx = \\int_{-\\frac{\\pi}{2}}^{\\frac{\\pi}{2}}1 \\ d\\theta \\]\\[ = \\left[\\frac{\\pi}{2} - \\left(- \\frac{\\pi}{2}\\right)\\right] = \\pi\\]point example unexpectedly number \\(\\pi\\) crops must divide normalising constant function\\[f(x) = \\frac{1}{\\pi(x^2+1)} ,\\]\nvalid density function integral \\(1\\).","code":""},{"path":"norm.html","id":"normal-density","chapter":"6 Normal distribution","heading":"6.3 Normal density","text":"consider function similar shape , namely\\[f(x) = e^{-\\frac{1}{2}x^2} \\]\nturns \\[\\int _{-\\infty}^{\\infty} e^{-\\frac{1}{2}x^2} \\ dx = \\sqrt{2\\pi}\\]\nMathematical curiosity can integrate \\(e^{-\\frac{1}{2}x^2}\\) whole real line get result, exists closed form (without integrals) antiderivative.upshot integral involves \\(\\pi\\) make valid density must factor involving \\(1/{\\sqrt{\\pi}}.\\) give intuition following definition.Definition 6.1  continuous random variable \\(X\\) said normal distribution mean \\(\\mu\\) variance \\(\\sigma^2\\), written \\(X\\sim \\text{N}(\\mu,\\sigma^2)\\) density function given \\[ f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\text{exp}\\left\\{ -\\frac{(x-\\mu)^2}{2\\sigma^2}\\right\\}, \\]\n\\(x, \\mu\\\\mathbb{R}\\) \\(\\sigma^2 > 0\\).density \\(f(x)\\) valid density, fraction \\(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\) called normalising constant ensure integral \\(1\\) real line. mean \\(\\text{E}(X)\\) distribution \\(\\mu\\). variance \\(\\text{Var}(X)\\) \\(\\sigma^2\\). three facts can shown studying multi-variable calculus second year.density normal distribution bell-shaped curve symmetric mean value \\(\\mu\\). area curve concentrated mean value relatively small amount values long way \\(\\mu\\). general density looks like following picture, bell-shaped bump tails zero infinity either side. curve symmetrical line \\(x=\\mu\\).\nFigure 6.3: normal density curve bell shaped\nChanging value \\(\\mu\\), perform translation along \\(x\\) axis, thereby position centre curve.\nFigure 6.4: three normal densities standard deviation = 10, means 90, 100 115\nChanging value standard deviation, equivalently variance, parameter determines spread curve mean. smaller standard deviation results higher peak, model less spread mass around mean value.Conversely larger standard deviation results lower peak, mass spread mean value towards tails density.can view \nFigure 6.5: three normal densities mean, standard deviations equal 7.5, 10 15\nOne can access normal density R function \\(\\texttt{dnorm}()\\), see labs.","code":""},{"path":"norm.html","id":"standard-normal","chapter":"6 Normal distribution","heading":"6.4 Standard normal","text":"Definition 6.2  normal distribution \\(\\mu=0\\) \\(\\sigma =1\\) called standard normal distribution denoted letter \\(Z\\). Instead \\(f\\) density denoted letter \\(\\phi\\) \\[\\phi (z) = \\frac{1}{\\sqrt{2\\pi}} \\exp \\left( -\\frac{1}{2}z^2 \\right) , z\\\\mathbb{R}\\]cumulative distribution function normal distribution denoted capital \\(\\Phi(z) = \\text{P}(Z\\leq z)\\).graph density standard normal distribution \\(Z\\) given .\nFigure 6.6: standard normal density\nNotice majority area \\(-3\\) \\(3\\). distribution function standard normal given statistical tables. see problems involving normal distribution can recast terms standard normal distribution.","code":""},{"path":"norm.html","id":"evaluating-the-standard-normal-distribution","chapter":"6 Normal distribution","heading":"6.5 Evaluating the standard normal distribution","text":"MMU tables give areas, .e. probabilities, tail distribution \\(z>0\\). Tables vary, giving left tail \\(\\text{P}(Z\\leq z)\\) (cumulative distribution \\(\\Phi\\)), others give upper tail \\(\\text{P}(Z\\geq z)\\), using tables read carefully top-matter describes tabulation. tables display positive values \\(z\\) either format.However, using tables can find area observing:area whole graph 1. law complements applies \\(\\text{P}(Z\\geq z)= 1-\\text{P}(Z\\leq z)\\).area whole graph 1. law complements applies \\(\\text{P}(Z\\geq z)= 1-\\text{P}(Z\\leq z)\\).graph symmetric \\(0\\). Lower tail areas negative \\(z\\) value, equal corresponding upper tail area positive \\(z\\) value. particular implies areas \\(0\\) \\(0.5\\).graph symmetric \\(0\\). Lower tail areas negative \\(z\\) value, equal corresponding upper tail area positive \\(z\\) value. particular implies areas \\(0\\) \\(0.5\\).generally advised draw sketch density shows values required particular problem areas representing probabilities.Example 6.1  Use tables find following probabilities standard Normal random variable \\(Z\\).\\(\\text{P}(Z\\geq 2.45)\\)\\(\\text{P}(Z\\geq 2.45)\\)\\(\\text{P}(Z\\leq -2.45)\\)\\(\\text{P}(Z\\leq -2.45)\\)\\(\\text{P}(Z\\leq 1.73)\\)\\(\\text{P}(Z\\leq 1.73)\\)\\(\\text{P}(Z\\geq -0.5)\\)\\(\\text{P}(Z\\geq -0.5)\\)\\(\\text{P}(0.35\\leq Z\\leq 1.68)\\)\\(\\text{P}(0.35\\leq Z\\leq 1.68)\\)solutionsIf upper tail values tabulated, find directly.\n\\(\\text{P}(Z\\geq 2.45) = 0.0071\\)upper tail values tabulated, find directly.\n\\(\\text{P}(Z\\geq 2.45) = 0.0071\\)symmetry can argue previous value.\n\\(\\text{P}(Z\\geq 2.45) = 0.0071\\)symmetry can argue previous value.\n\\(\\text{P}(Z\\geq 2.45) = 0.0071\\)Using complements \\(\\text{P}(Z\\leq 1.73)= 1-\\text{P}(Z\\geq 1.73)\\). tables \\(\\text{P}(Z\\geq 1.73)= 0.0418\\), \\(\\text{P}(Z\\leq 1.73)= 1- 0.0418 = 0.9582\\).Using complements \\(\\text{P}(Z\\leq 1.73)= 1-\\text{P}(Z\\geq 1.73)\\). tables \\(\\text{P}(Z\\geq 1.73)= 0.0418\\), \\(\\text{P}(Z\\leq 1.73)= 1- 0.0418 = 0.9582\\).\\(\\text{P}(Z\\geq -0.5) = 1 - \\text{P}(Z\\leq -0.5)\\) complements. Now also \\(\\text{P}(Z\\leq -0.5) = \\text{P}(Z\\geq 0.5) = 0.3085\\) symmetry. Hence \\[\\text{P}(Z\\geq -0.5) = 1 - 0.3085 = 0.6915 \\]\\(\\text{P}(Z\\geq -0.5) = 1 - \\text{P}(Z\\leq -0.5)\\) complements. Now also \\(\\text{P}(Z\\leq -0.5) = \\text{P}(Z\\geq 0.5) = 0.3085\\) symmetry. Hence \\[\\text{P}(Z\\geq -0.5) = 1 - 0.3085 = 0.6915 \\]\\(\\text{P}(0.35\\leq Z\\leq 1.68) = \\text{P}(Z\\geq 0.35)-\\text{P}(Z\\geq 1.68)\\), looking latter two values gives \\(0.3632 - 0.0465 = 0.3167.\\)\\(\\text{P}(0.35\\leq Z\\leq 1.68) = \\text{P}(Z\\geq 0.35)-\\text{P}(Z\\geq 1.68)\\), looking latter two values gives \\(0.3632 - 0.0465 = 0.3167.\\)important skill able use statistical tables, familiarise format. may means getting numbers particular distributions, example using R calculator.However later course distributions appear tables expected use tables exam.","code":""},{"path":"norm.html","id":"standardising","chapter":"6 Normal distribution","heading":"6.6 Standardising","text":"previous section considered special case standard normal distribution (mean \\(0\\) variance \\(1\\)) evaluating probabilities. know normal distribution can defined general mean \\(\\mu\\) variance \\(\\sigma^2\\). possible produce table values every possible value \\(\\mu\\) \\(\\sigma\\). Fortunately also unnecessary.Theorem 6.1  Suppose \\(X\\) follows normal distribution mean variance, \\(X\\sim \\text{N}(\\mu,\\sigma^2)\\), subtracting mean dividing standard deviation results standard normal distrbution. ,\\[\\frac{X-\\mu}{\\sigma} \\sim \\text{N}(0,1) \\]\nresult write \\(Z=\\frac{X-\\mu}{\\sigma}\\).intuition\\[\\text{E}\\left(\\frac{X-\\mu}{\\sigma}\\right)=\\frac{1}{\\sigma}\\text{E}(X-\\mu) \\]\nlinearity expectation, ,\\[ = \\frac{1}{\\sigma}(\\text{E}(X) - \\text{E}(\\mu)) = \\frac{1}{\\sigma}(\\mu-\\mu)=0\\]\nexpectation contant just constant.variance,\\[ \\text{Var} \\left( \\frac{X-\\mu}{\\sigma} \\right) = \\frac{1}{\\sigma^2}\\text{Var}(X-\\mu)\\]\nrule \\(\\text{Var}(aX)=^2\\text{Var}(X)\\). Now variance constant zero ,\\[= \\frac{1}{\\sigma^2}\\left( \\text{Var}(X) - \\text{Var}(\\mu) \\right) = \\frac{1}{\\sigma^2}\\left( \\sigma^2 - 0\\right) = 1\\]\nHence \\(\\frac{X-\\mu}{\\sigma}\\) correct mean variance. remains formally show density function \\(Z\\), normal.important consequence theorem enables us work probability following corollary.Corollary 6.1  Suppose \\(X\\) follows normal distribution mean variance, \\(X\\sim \\text{N}(\\mu,\\sigma^2)\\) \\[\\text{P}(\\leq X \\leq b) = \\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{-\\mu}{\\sigma}\\right)\\]proof\n\\[\\text{P}(\\leq X \\leq b) = \\text{P}\\left(\\frac{-\\mu}{\\sigma} \\leq \\frac{X-\\mu}{\\sigma}  \\leq  \\frac{b-\\mu}{\\sigma}\\right) = \\text{P}\\left(\\frac{-\\mu}{\\sigma} \\leq Z  \\leq  \\frac{b-\\mu}{\\sigma}\\right) \\]\nlast equality theorem. Now recall \\(\\Phi\\) CDF \\(Z\\), result follows.formula simple geometric interpretation. Recall can represent probabilities continuous random variables area, specified limits, distribution curve. theorem just says area Normal curve limits \\(\\) \\(b\\) always area standard Normal\ncurve transformed limits \\(\\frac{-\\mu}{\\sigma}\\) \\(\\frac{b-\\mu}{\\sigma}\\).Example 6.2  Suppose weight particular grade apples Normally distributed mean 100g standard deviation 8g. Let \\(X\\) denote weight randomly selected apple, .e. \\(X\\sim\\text{N}(100,{8^2})\\), find:\\(P(X>115)\\)\\(P(X>115)\\)\\(P(X< 80)\\)\\(P(X< 80)\\)\\(P(105<X<112)\\)\\(P(105<X<112)\\)\\(P(95<X<112)\\)\\(P(95<X<112)\\)solution\\[P(X>115)  =  P\\left(Z>\\frac{115-100}{8}\\right)\n        =  P(Z>1.88)\\]quantity can found directly tables, .e.\n\\(P(Z>1.88)=0.0301\\).\\[P(X<80)  =  P\\left(Z<\\frac{80-100}{8}\\right)\n        =  P(Z<-2.5)\n        =  P(Z>2.5)\\]tables, \\(P(Z>2.5)=0.0062\\)\\[P(105<X<112)  =  P\\left(\\frac{105-100}{8}<Z<\\frac{112-100}{8}\\right)\\]\\[= P(0.63<Z<1.5)\\]\n\\[=P(Z>0.63)-P(Z>1.5)\\]\n\\[= 0.2643-0.0668=0.1975\\]\n4.\nseveral ways problem approached - sketch diagram help. ,\\[P(95<X<112) =  P\\left(\\frac{95-100}{8}<Z<\\frac{112-100}{8}\\right)\n          =  P(-0.63<Z<1.5)\\],\\[P(Z<-0.63)+P(-0.63<Z<1.5)+P(Z>1.5)=1\\]three areas comprise whole distribution. also ,\n\\[P(Z<-0.63)=P(Z>0.63)\\]\nsymmetry, \\[P(-0.63<Z<1.5) =  1-P(Z>0.63)-P(Z>1.5)\\]\\[=  1-0.2643-0.0668=0.6689\\]","code":""},{"path":"norm.html","id":"inverse-cdf","chapter":"6 Normal distribution","heading":"6.7 Inverse CDF","text":"saw solve problems involved finding probability Normally distributed\nrandom variable lay certain range. solution problem consisted two steps:standardising value original variable get standard Normal variable.using tables standard Normal distribution find required probability, recognising process \nstandardisation preserves areas, .e. probabilities.may think process follows:\n\\[ \\mbox{Original Value,\n}X\\stackrel{\\frac{x-\\mu}{\\sigma}}{\\longrightarrow} Z\n\\longrightarrow \\mbox{Probability ?}\n\\]\ninverse problem, name suggests, simply \nprocess applied backwards. start probability seek find\nvalue random variable corresponding probability. Thus, since\\[Z  =  \\frac{X-\\mu}{\\sigma} \\]\n\\[\\Rightarrow \\sigma Z = X-\\mu \\]\n\\[\\Rightarrow X  =  \\mu+\\sigma Z\\]inverse problem can thought working \nfollowing process,\n\\[ \\mbox{Original Value,\n}X\\mbox{? }\\stackrel{\\sigma Z+\\mu}{\\longleftarrow} Z\n\\longleftarrow \\mbox{Probability}\n\\]\nsimple sketch graph problem invaluable.Example 6.3  weights eggs laid particular breed hens \nNormally distributed mean \\(50\\)g standard deviation \\(5\\)g. \negg producer wants classify eggs heaviest \\(10\\)% \nclassified large lightest \\(30\\)% classified small. \nremaining \\(60\\)% classified medium. weights \nused distinguish three classes?let random variable \\(X\\) denote weight egg,\nneed find values \\(x_1\\) \\(x_2\\) indicated \nfollowing diagram,\nFigure 6.7: proportions eggs weight\nCommon sense, knowledge Normal distribution, tells us value \\(x_1\\) little mean value \\(50\\)g value \\(x_2\\) somewhat higher mean value \\(50\\)g. fact, can usually make reasonably accurate guess use result virtually curve (99.7%) contained within limits \\(\\pm\\) 3 standard deviations either side mean. case, virtually eggs lie range \\([50-3\\times 5,50+3\\times5]\\)=\\([35,65]\\)g.order solve problem, find values standard normal variable corresponding probabilities indicated diagram .\\(z\\) value exceeded probability 0.1 found 1.2816, .e. \\[P(Z\\geq 1.2816)=0.1\\].end distribution find probability \\(Z\\) value less 0.3 -0.5244, .e. \n\\[P(Z\\leq -0.5244)=0.3\\].Note last value found using symmetry distribution. check \\(z\\) values obtained working way round.Note , required probability inverse tables, use main table backwards. , look required probability (close can get ) body table, read corresponding \\(z\\)-value.example, scanning body table, find probability 0.1003 corresponds \\(z\\) value 1.28 probability 0.0985 corresponds z-value 1.29. Clearly, actual value corresponding probability 0.10 (know 1.2816) somewhere 1.28 1.29. practice, good estimate can found using interpolation.\nFigure 6.8: Standardised values egg weight distribution give area tails\nfinal stage problem apply inverse transformation get appropriate values original\nscale. Recall, inverse transformation , \\(X=\\sigma Z+\\mu\\).\nThus , ,weight exceeded largest 10% eggs given\n, \\(X = 5\\times 1.2816+50 = 56.41\\)g.weight exceeded largest 10% eggs given\n, \\(X = 5\\times 1.2816+50 = 56.41\\)g.weight smallest 30% eggs lie \ngiven , \\(X = 5\\times -0.5244+50 = 47.38\\)gThe weight smallest 30% eggs lie \ngiven , \\(X = 5\\times -0.5244+50 = 47.38\\)gExample 6.4  vending machine discharges hot chocolate. volume liquid machine discharges may modelled normal distribution. probability \\(5\\%\\), volume discharged greater \\(475\\)ml. probability volume less \\(460\\)ml one percent.Sketch picture show informationSketch picture show informationFind \\(\\mu\\) \\(\\sigma\\).Find \\(\\mu\\) \\(\\sigma\\).","code":""},{"path":"norm.html","id":"sampling-total","chapter":"6 Normal distribution","heading":"6.8 Sampling Total","text":"Suppose independent random sample size \\(n\\) Normal distribution,\ne.g. \\(X_1,\\ldots,X_n\\sim \\text{N}(\\mu,\\sigma^2)\\).Define random variable \\(T=\\sum_{=1}^n X_i\\), ,\n\\[ T \\sim \\text{N}(n\\mu,n\\sigma^2). \\], sampling distribution total, \\(T\\), also Normally distributed \\(\\text{E}(T)=n\\mu\\) \\(\\text{Var}(T)=n\\sigma^2\\).Example 6.5  (apples revisited) Earlier assumed weight \nindividual apples sold supermarket Normally distributed\nmean 100g standard deviation 8g, .e. random variable \\(X\\)\nrepresents weight \\(X \\sim \\text{N}(100,{8^2})\\).Let random variable \\(T\\) denote total weight carton 4 apples. Find probability total weight carton ,450gmore 450gbetween 375g 425gbetween 375g 425gsolutionHere \\(n=4\\), \\(\\mu=100\\) \\(\\sigma=8\\) , total weight,\n\\[ T\\sim \\text{N}({4\\times 100},{4\\times 8^2})\\sim \\text{N}({400},{16^2}) \\]\nanswer problem converting standard Normal ,,\\[P(T>450)  =  P\\left(Z>\\frac{450-400}{16}\\right)\\]\n\\[=  P(Z>3.13)\\]\n\\[ =  0.0009\\],\\[P(375<T<425)  =  P\\left(\\frac{375-400}{16}<Z<\\frac{425-400}{16}\\right) \\]\n\\[=  P(-1.56<Z<1.56)=1-2\\times P(Z>1.56)\\]\n\\[=  1-2\\times 0.0594=0.8812\\]","code":""},{"path":"norm.html","id":"sampling-distribution-of-the-mean","chapter":"6 Normal distribution","heading":"6.9 Sampling distribution of the mean","text":"problems considered far supposed single\nmeasurement randomly drawn population \npossible values measurement follow Normal distribution.\nnow consider happens ,Take random sample size \\(n\\) population whose\nvalues follow Normal distribution. denote random sample \nvalues \\(X_1,X_2,\\ldots,X_n\\). example, might\nrandomly select \\(n=10\\) people measure height.Take random sample size \\(n\\) population whose\nvalues follow Normal distribution. denote random sample \nvalues \\(X_1,X_2,\\ldots,X_n\\). example, might\nrandomly select \\(n=10\\) people measure height.Calculate mean value sample, .e. \n\\[\\bar{X}=\\frac{X_1+X_2+\\ldots+X_n}{n}=\\frac{1}{n}\\sum_i X_i\\]Calculate mean value sample, .e. \n\\[\\bar{X}=\\frac{X_1+X_2+\\ldots+X_n}{n}=\\frac{1}{n}\\sum_i X_i\\]Calculate total value sample, .e. \n\\[T = X_1+X_2+\\ldots+X_n =\\sum_i X_i\\]Calculate total value sample, .e. \n\\[T = X_1+X_2+\\ldots+X_n =\\sum_i X_i\\]Now, since member sample random variable, sample mean must also random variable.Example 6.6  heights two randomly selected MMU students \\(X_1\\) \\(X_2\\). Given particular sample, .e. two actual students say \\(x_1=170\\)cm \\(x_2=158\\)cm, can calculate mean \\(\\bar{x}=164\\)cm. However pick sample, quantity \\((X_1+X_2)/2\\) random. can treat mean random variable denote capital letter \\(\\bar{X}\\).Definition 6.3  statistic random variable whose particular values can calculated particular sample. example statistic \\(\\bar{X}\\) calculated \\(\\frac{X_1+X_2+\\ldots+X_n}{n}\\).Given random variable one can always ask ‘distribution?’.following result can quoted.Theorem 6.2  Suppose random variables \\(X_1,X_2,\\ldots,X_n\\) follow \nNormal distribution mean \\(\\mu\\) variance \\(\\sigma^2\\), .e.\n\\(X_i\\sim \\text{N}({\\mu},{\\sigma^2})\\). , sample mean \\(\\bar{X}\\), \nsampling distribution statistic \n\\[\\bar{X}\\sim \\text{N}(\\mu,\\frac{\\sigma^2}{n})\\]proof\nproof beyond scope course, however can check mean variance described.result says sample mean theoretical population mean, \\(\\mu\\), single value drawn population, variance reduced factor \\(n\\). Given knowledge role variance Normal distribution, result suggests sample mean lie closer true population mean \\(\\mu\\) sample size increases.Example 6.7  Suppose take \\(10\\) samples bamboo shoots measure lengths. length particular bamboo shoots normally distributed mean \\(74\\)mm standard deviation \\(5\\)mm.range values shoot lengths \\(68\\) \\(80\\). values statistic \\(\\bar{X}\\) vary noticably less, close original mean value \\(74\\)mm.Now two variances \\(\\sigma^2\\) \\(\\sigma^2/n\\) equivalently standard deviations \\(\\sigma\\) \\(\\sigma / \\sqrt{n}\\) need clear one talking .Definition 6.4  quantity \\(\\sigma/\\sqrt{n}\\) called standard error \nmean. standard deviation \\(\\bar{X}\\) - sampling distribution mean. essentially standard deviation single observation reflects fact variance \nmean depends sample size \\(n\\).\\(n\\) gets larger larger, distribution sample mean\ngets concentrated around value population\nmean \\(\\mu\\).practice, suggests , true\npopulation mean unknown, sample mean good\nestimate value.Example 6.8  Apple weights (revisited)\nRecall assumed weight individual apples sold supermarket Normally distributed\nmean 100g standard deviation 8g, .e. random variable \\(X\\)\nrepresents weight \\(X \\sim \\text{N}({100},{8^2})\\).supermarket also sells apples cartons four. \nprobability mean weight apples randomly\nselected carton ,105gless 98gbetween 98 102gsolution\n\\(n=4\\), \\(\\mu=100\\) \\(\\sigma=8\\). denote mean weight\napples carton \\(\\bar{X}\\), ,\n\\[ \\bar{X} \\sim \\text{N}({100},8^2/4) \\sim \\text{N}(100,16)\\]case standard error mean \n\\(8/\\sqrt{4}=\\sqrt{16}=4\\). calculated standard error, \nanswer problems way converting \nproblem one involving standard Normal distribution.\\[P(\\bar{X} \\geq 105)  =  P\\left ( Z \\geq \\dfrac{105-100}{4}\\right) \\]\n\\[=  P(Z\\geq 1.25)\\]\n\\[=  0.1056\\]\\[P(\\bar{X} \\geq 105)  =  P\\left ( Z \\geq \\dfrac{105-100}{4}\\right) \\]\n\\[=  P(Z\\geq 1.25)\\]\n\\[=  0.1056\\]\\[P(\\bar{X} \\leq 98)  =  P\\left ( Z \\leq \\dfrac{98-100}{4}\\right)\\]\\[=  P(Z\\leq -0.5)=P(Z\\geq 0.5)\\]\n\\[= 0.3085\\]\\[P(98\\leq \\bar{X} \\leq 102)  = P\\left (\\dfrac{98-100}{4} \\leq Z \\leq \\dfrac{102-100}{4}\\right)\\]\\[=  P(-0.5\\leq Z\\leq 0.5)=1-2\\times P(Z\\geq 0.5)\\]\n\\[=  0.3830\\]","code":""},{"path":"norm.html","id":"exercises-week-6","chapter":"6 Normal distribution","heading":"6.10 Exercises week 6","text":"Exercise 6.1  Suppose lifetime electrical component follows\nuniform distribution range \\([0,2000]\\) hours.Draw sketch distribution.Draw sketch distribution.Find probability lifetime ,Find probability lifetime ,least 1000 hoursless 250 hoursbetween 500 1500 hours(draw sketch distribution area \ndistribution representing probability)Exercise 6.2  time taken (minutes) serve customer fast food\nrestaurant continuous random variable, \\(X\\), probability\ndistribution,\n\\[ f(x) = \\left \\{\\begin{array}{ll}\n  \\dfrac{x}{2}& 0\\leq x \\leq 2 \\\\\n  0 & \\mbox{otherwise}\n\\end{array} \\right .\n\\]Sketch density.Show area distribution one.need use areas triangles answer \nquestions. Find probability time taken serve \ncustomer ,less one minutemore one minutemore 30 secondsbetween 30 seconds 1 minute.Exercise 6.3  Use standard Normal tables find following\nprobabilities, (draw sketch diagram case)\\(P(Z>1.7)\\)\\(P(Z>1.7)\\)\\(P(Z>2.35)\\)\\(P(Z>2.35)\\)\\(P(Z<-0.92)\\)\\(P(Z<-0.92)\\)\\(P(Z<-2.33)\\)\\(P(Z<-2.33)\\)\\(P(0.78<Z<2.56)\\)\\(P(0.78<Z<2.56)\\)\\(P(-1.99<Z<-0.34)\\)\\(P(-1.99<Z<-0.34)\\)\\(P(-1.67<Z<2.58)\\)\\(P(-1.67<Z<2.58)\\)Exercise 6.4  lifetime certain brand lightbulb Normally distributed \nmean 2000 hours standard deviation 75 hours. Find probability \nrandomly selected bulb lifetime,greater 2100 hoursgreater 2100 hoursgreater 2200 hoursgreater 2200 hoursless 2050 hoursless 2050 hoursless 1950 hoursless 1950 hoursbetween 1950 2100 hoursbetween 1950 2100 hoursbetween 2050 2200 hoursbetween 2050 2200 hoursbetween 1900 1950 hoursbetween 1900 1950 hoursExercise 6.5  Bags sugar packed machine mean weight 2kg \nstandard deviation 0.02kg. Find probability weight \nbag begreater 2.05kggreater 2.05kgless 1.96kgless 1.96kgbetween 1.95 2.05kgbetween 1.95 2.05kgless 2.03kgless 2.03kgbetween 1.95 1.98 kgbetween 1.95 1.98 kgbetween 2.01 2.05 kgbetween 2.01 2.05 kgExercise 6.6  type laboratory mouse weight Normally distributed mean\n30g standard deviation 2.5g. Find probability weight randomly\nselected mouse ,least 33gat least 33gless 33.5gless 33.5gmore 29gmore 29gless 28gless 28gbetween 27g 33gbetween 27g 33gbetween 31g 33.5gbetween 31g 33.5gExercise 6.7  Eggs classified standard, weigh less \n46.0g, medium weigh 46.0g 56.0g, large \nweigh 56.0g. Suppose eggs laid particular\nbreed hen weight Normally distributed mean\n50.0g standard deviation 5.0g. percentage eggs laid \nhens falls three classes?Exercise 6.8  manufactured item requires fuse can supplied one\ntwo suppliers. Supplier 1’s fuses lifetime Normally distributed\nmean 1000 hours standard deviation 30 hours. Supplier 2’s fuses \nlifetime Normally distributed mean 990 hours standard deviation\n10 hours. product specification requires fuses last least 980\nhours. two suppliers choose .Exercise 6.9  Marks statistics examination Normally\ndistributed mean 50 standard deviation 10. \nprobability thatthe mean mark group 5 students 60?mean mark group 5 students 60?mean mark group 20 students 44\n48?mean mark group 20 students 44\n48?Exercise 6.10  ski-lift designed load limit 18,000lbs claims \ncapacity 100 people. weight people using lift Normally\ndistributed mean 175lbs standard deviation 30lbs, \nprobability group 100 randomly selected people exceed load\nlimit lift? willing use lift?Exercise 6.11  Lengths bicycle chain links Normally distributed mean\n0.5cm standard deviation 0.04cm. finished chains must 49\n50cm long.chains made 100 links, proportion meets \nstandard?chains made 100 links, proportion meets \nstandard?chains made instead 99 links proportion meets \nstandard?chains made instead 99 links proportion meets \nstandard?Using 99 links, value must standard deviation reduced \norder following percentages meet standard?Using 99 links, value must standard deviation reduced \norder following percentages meet standard?90%90%95%99%Exercise 6.12  Bags sugar packed machine mean weight 2kg standard\ndeviation 0.02kg. weights willbe exceeded 15% bagsbe exceeded 15% bagsbe exceeded 90% bagsbe exceeded 90% bags20% bags contain less than20% bags contain less than90% bags between90% bags betweenA multipack contains 5 bags sugar. probability thatA multipack contains 5 bags sugar. probability thatAll bags contain less 1.992 kgAll bags contain less 1.992 kgExactly four bags contain less 1.992kg(Hint: Consider using normal distribution Binomial\nappropriate probability.)Exercise 6.13  weight child can modelled normally distributed mean \\(30\\)kg standard deviation \\(5\\)kg.fairground ride total carrying capacity \\(2.8\\) metric tons (thousand kilograms).\\(k\\) children admitted ride total weight \\(X_1+X_2+ \\ldots + X_k\\).maximum number children admitted ride, ensure total weight within carrying capacity probability \\(99\\%\\)?Exercise 6.14  masses penguins island found normally distributed mean \\(\\mu\\) standard deviation \\(\\sigma\\). Given \\(10\\%\\) penguins mass less \\(18\\)kg \\(5\\%\\) mass greater \\(30\\)kg,Sketch diagram represent informationSketch diagram represent informationFind \\(\\mu\\) \\(\\sigma\\).Find \\(\\mu\\) \\(\\sigma\\).","code":""},{"path":"sampling-and-confidence-intervals.html","id":"sampling-and-confidence-intervals","chapter":"7 Sampling and confidence intervals","heading":"7 Sampling and confidence intervals","text":"week begin Statistical applications theory learned far.learn basis (Frequentist) statistical inference. construct interpret confidence intervals mean proportion. introduce hypothesis testing.Mathematics deductive process, Statistics inferential one. Given imperfect information (usually data), make (sensible) inferences models real world.modelling situations involve estimating value population parameter characteristic, one main tasks Statistics estimate values parameters sample data.Example 7.1  Suppose interested average height adult man UK. population interest UK adult men (approximately \\(33\\) million). model height men may normal distribution:\\[X\\sim \\text{N}(\\mu,\\sigma^2),\\]\\(\\mu\\) \\(\\sigma^2\\) population parameters distribution.might possible measure height every UK man? Instead take smaller number men measure, say \\(100\\) \\(1000\\). called sample.sample can calculate sample mean \\(\\bar{x}\\) sample standard deviation \\(s\\).Population parameters like \\(\\mu\\) practice unknowable certainty. Typically statistics may specifically want toEstimate value \\(\\mu\\).Estimate value \\(\\mu\\).Determine range interval plausible values \\(\\mu\\).Determine range interval plausible values \\(\\mu\\).Decide whether particular value \\(\\mu\\) appears reasonable.Decide whether particular value \\(\\mu\\) appears reasonable.distinguish real world, population parameters, sample statistics following table:intuitively obvious can use sample mean estimate true value population mean. However must recognise drawing random sample, normal distribution case, statistic calculated sample also probability distribution.Recall Theorem 6.2 last week. sampling distribution mean \\(\\bar{X}\\) normally distributed mean variance divided factor given sample size \\(n\\). \\[\\overline{X} \\sim \\text{N} (\\mu, \\sigma^2/{n})\\]larger values \\(n\\) can compare proportion density mean.Example 7.2  Suppose assume percentage glucose bars toffee normally distributed mean \\(20\\%\\) standard deviation \\(2\\%\\). Find probability :One bar toffee selected random glucose level \\(19.5\\%\\) \\(20.5\\%\\).One bar toffee selected random glucose level \\(19.5\\%\\) \\(20.5\\%\\).mean percentage glucose \\(20\\) randomly selected toffee bars \\(19.5\\%\\) \\(20.5\\%\\).mean percentage glucose \\(20\\) randomly selected toffee bars \\(19.5\\%\\) \\(20.5\\%\\).mean percentage glucose \\(100\\) randomly selected toffee bars \\(19.5\\%\\) \\(20.5\\%\\).mean percentage glucose \\(100\\) randomly selected toffee bars \\(19.5\\%\\) \\(20.5\\%\\).solution\\[\\text{P}(19.5<X<20.5)= \\text{P}\\left(\\frac{19.5-20}{2}<Z<\\frac{20.5-20}{2}\\right)\\]\\[= \\text{P}(-0.25<Z<0.25)=1-2\\times\\text{P}(Z>0.25)\\]\\[=1-2\\times 0.4013=0.20\\]\\[\\text{P}(19.5<\\overline{X}<20.5)= \\text{P}\\left(\\frac{19.5-20}{\\sqrt{2^2 / 20}}<Z<\\frac{20.5-20}{\\sqrt{2^2 / 20}}\\right)\\]\\[= \\text{P}(-1.12<Z<1.12)=1-2\\times\\text{P}(Z>1.12)\\]\\[=1-2\\times 0.1314=0.74 \\approx 75\\%\\]\\[\\text{P}(19.5<\\overline{X}<20.5)= \\text{P}\\left(\\frac{19.5-20}{\\sqrt{2^2 / 100}}<Z<\\frac{20.5-20}{\\sqrt{2^2 / 100}}\\right)\\]\\[= \\text{P}(-2.5<Z<2.5)=1-2\\times\\text{P}(Z>2.5)\\]\\[=1-2\\times 0.0062=0.99\\ldots \\approx 99\\%\\]can summarise example following table:can use sampling distribution various ways make inferences true population mean glucose content. example, samle \\(100\\) toffee bars, assuming true mean \\(\\mu=20\\%\\), value \\(\\bar{x}\\) outside range \\(19.5 - 20.5\\%\\) appear unusual.","code":""},{"path":"sampling-and-confidence-intervals.html","id":"confidence-intervals","chapter":"7 Sampling and confidence intervals","heading":"7.1 Confidence Intervals","text":"specifies range plausible values parameter interest.Recall can find particular value \\(Z\\sim \\text{N}(0,1)\\) within distribution specified probability - using inverse CDF normal distribution.Example 7.3  Calculate \\(z\\)-value containing middle \\(95\\%\\) density. words find \\(z\\) \\(\\text{P}(|Z|\\leq z)=0.95\\).solutionRecall \\(|x|<1\\) means \\(-1<x<1\\).inequality \\(|Z|\\leq z\\) means \\(-z\\leq Z\\leq z\\).\\[\\text{P}(-z\\leq Z \\leq z)=0.95\\]\n\\[\\iff  \\text{P}(Z\\geq z) = P(Z\\leq -z) =0.025\\]\ntables:\\[\\Phi^{-1}(0.025) = -1.96\\]\nalternatively \\[\\Phi^{-1}(0.975) = 1.96\\]\\(z=1.96\\), \\(\\text{P}(|Z|<1.96) =0.95\\)Note \\(95\\% = 100(1-0.05)\\%\\). \\(z\\) value calculated corresponded \\(\\alpha / 2\\).Definition 7.1  confidence interval population mean \\(\\mu\\) level \\(100(1-\\alpha)\\%\\) given following expression.\\[\\left( \\bar{x}-z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt{n}},\\bar{x}+z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt{n}} \\right)\\]confidence interval derived standardisation sampling distribution mean. ,\\[\\overline{X} \\sim \\text{N} (\\mu, \\sigma^2/{n}),\\]\nimplies\\[Z = \\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\text{N}(0,1).\\]\\[\\text{P}\\left( |Z| <z_{\\frac{1}{2}\\alpha} \\right) = 1-\\alpha\\]Now standardisation replace \\(Z\\) expression involving \\(\\overline{X}\\).\\[\\text{P}\\left( \\left|\\frac{\\overline{X} - \\mu}{\\sigma / \\sqrt{n}} \\right| <z_{\\frac{1}{2}\\alpha} \\right) = 1-\\alpha\\]\ndenominator positive equivalent :\n\\[\\text{P}\\left( |\\overline{X} - \\mu| <z_{\\frac{1}{2}\\alpha} \\frac{\\sigma}{\\sqrt{n}}  \\right) = 1-\\alpha\\]\\[\\text{P}\\left( |\\mu - \\overline{X} | <z_{\\frac{1}{2}\\alpha} \\frac{\\sigma}{\\sqrt{n}}  \\right) = 1-\\alpha\\]\\[\\text{P}\\left(z_{\\frac{1}{2}\\alpha} \\frac{\\sigma}{\\sqrt{n}} < \\mu - \\overline{X} <z_{\\frac{1}{2}\\alpha} \\frac{\\sigma}{\\sqrt{n}}  \\right) =1-\\alpha\\]\n\\[\\text{P}\\left( \\overline{X}+ z_{\\frac{1}{2}\\alpha} \\frac{\\sigma}{\\sqrt{n}} < \\mu <\\overline{X} + z_{\\frac{1}{2}\\alpha} \\frac{\\sigma}{\\sqrt{n}}  \\right) =1-\\alpha\\]Example 7.4  milligrams fat sample hotdogs measured \n\\[25.2, \\ 21.3,\\ 22.8,\\ 17.0,\\ 29.8,\\ 21.0,\\ 25.5,\\ 16.0,\\ 20.9, \\ 19.5\\]\nSupposing fat content normally distributed, random sample hotdogs, population standard deviation \\(\\sigma = 5\\), calculate \\(90\\%\\) confidence interval mean fat content \\(\\mu\\).solutionWith \\(90\\%\\) centrally, must \\(5\\%\\) either tail. One can look \\(z\\) value \\(z_{0.95}= 1.6449\\).R get value quantile command \\(\\texttt{qnorm(0.95,mean=0,sd=1)}\\).,\n\\[\\bar{x} \\ \\pm \\ z\\frac{\\sigma}{\\sqrt{n}} = 21.9 \\ \\pm 1.6449\\times\\frac{5}{\\sqrt{10}}\\]\\[=[19.3 , 24.5] \\text{   (3 s.f.)}\\]Warning - many incorrect interpretations confidence intervals, contentious meaningful interval .Note \\(\\mu\\) unknown, constant rather random quantity. say “\\(95\\%\\) chance \\(\\mu\\) lie inside interval”, chance associated constant quantity.random part interval comes \\(\\overline{X}\\), rather must say repeated samples, long run, approximately \\(95\\%\\) intervals contain \\(\\mu\\).Another misconception say 100 intervals, exactly 95 contain interval, general error interpretation probability.R code simulate process.example turns \\(5\\%\\) intervals contain mean. However setting different seed shows fixed, just long term probability.many scientific studies data pooled single sample, one calculates single confidence interval. way knowing interval contains mean. ‘confidence’ really ?\\(\\bar{x}\\) single-valued point estimate, C.. just convention just interval estimate.","code":"\nlibrary(plotrix)## Warning: package 'plotrix' was built under R version 4.0.5\nz<-qnorm(0.975,0,1) # this is the z-value \nsigma <- 5\nx<- 1:100\n\nset.seed(1234) #ensures the code is reproducible\n\n#100 samples of 10 hotdogs each\nhotdogs <- replicate(100, rnorm(10,mean=20,sd=5))\n\n#Calculate the mean of each sample\nxbar <- vector(length = 100)\nfor (i in 1:100){\nxbar[i] <- mean(hotdogs[seq(10*(i-1),10*i,1)])\n}\n\n#lower end of interval L\nL <- xbar - z*sigma/sqrt(10)\n\n#upper end of interval U\nU <- xbar + z*sigma/sqrt(10)\n\nplotCI(x, xbar, ui=U, li=L,ylab=\"hotdog fat content\")\nabline(a=20, b=0,col=\"red\", lwd=3, lty=2)"},{"path":"sampling-and-confidence-intervals.html","id":"unknown-variance","chapter":"7 Sampling and confidence intervals","heading":"7.2 Unknown variance","text":"know \\(\\sigma\\)? Well estimate .","code":""},{"path":"sampling-and-confidence-intervals.html","id":"estimating-the-variance","chapter":"7 Sampling and confidence intervals","heading":"7.2.1 Estimating the variance","text":"Recall estimate population parameters \\(\\mu\\) statistics like \\(\\bar{X}\\).can ask expected value statistic \\[\\text{E}(\\overline{X})= \\text{E}\\left( \\frac{1}{n}\\sum_{=1}^{n}X_i \\right)\\]\\[=\\frac{1}{n}\\sum_{=1}^{n}\\text{E}(X_i) = \\frac{1}{n}\\sum_{=1}^{n}\\mu =\\frac{1}{n}n\\mu=\\mu\\]can see \\(\\text{E}(\\bar{X})=\\mu\\).Definition 7.2  statistic used estimate parameter, expectation estimator equal parameter, statistic called unbiased.Hence \\(\\bar{X}\\) unbiased estimator \\(\\mu\\).turns obvious choice estimate \\(\\sigma^2\\) unbiased.\\[\\text{E}\\left( \\frac{1}{n}\\sum_{=1}^{n}(X_i-\\bar{X})^2 \\right) = \\frac{1}{n}\\text{E}\\left( \\sum_{=1}^n (X_i^2-2\\bar{X} X_i +\\bar{X}^2)\\right) \\]\\[=\\frac{1}{n}\\text{E}\\left( \\sum_{=1}^n X_i^2 -2\\bar{X}\\sum_{=1}^n{X_i} +\\sum_{=1}^n \\bar{X}^2 \\right) \\]\\[=\\frac{1}{n}\\text{E}\\left( \\sum_{=1}^n X_i^2 -2n\\bar{X}^2 +n \\bar{X}^2 \\right) =\\frac{1}{n}\\text{E}\\left( \\sum_{=1}^n X_i^2 -n\\bar{X}^2  \\right)  \\]\\[=\\frac{1}{n}\\left( \\sum_{=1}^n \\text{E}(X_i^2) -n\\text{E}(\\bar{X}^2)  \\right) \\]\nUsing identity \\(\\text{Var}(X)= \\text{E}(X^2)=\\text{E}(X)^2\\) gives:\\[=\\frac{1}{n}\\left( \\sum_{=1}^n [\\text{Var}(X_i)+\\text{E}(X_i)^2] -n[\\text{Var}(\\bar{X})+\\text{E}(\\bar{X})^2]  \\right) \\]\nnow \\(\\text{Var}(X_i) = \\sigma^2\\), \\(\\text{E}(X_i)^2 = \\mu^2\\), \\(\\text{E}(\\bar{X}) = \\mu\\), \\(\\text{Var}(\\bar{X})=\\frac{\\sigma^2}{n}\\). Putting together gives.\\[=\\frac{1}{n}\\left( \\sum_{=1}^n [\\sigma^2+\\mu^2] -n\\left[\\frac{\\sigma^2}{n}+\\mu^2\\right]  \\right) =\\frac{1}{n}\\left( n\\sigma^2+n\\mu^2-n\\left[\\frac{\\sigma^2}{n}+\\mu^2\\right]\\right)\\]Altogether\\[\\text{E}\\left( \\frac{1}{n}\\sum_{=1}^{n}(X_i-\\bar{X})^2 \\right) = \\frac{(n-1)\\sigma^2}{n} \\]make statistic unbiased estimator \\(\\sigma^2\\), rescale multiplying \\(n\\) dividing \\((n-1)\\).variance \\(\\sigma\\) unknown, unbiased estimate \\(\\sigma\\) \\[s^2 = \\frac{1}{n-1}\\sum_{=1}^n (x_i-\\bar{x})^2\\]property \\(\\text{E}(S^2) = \\sigma^2\\).may practice easier compute:\\[s^2= \\frac{1}{n-1}\\left(\\sum_{=1}^n x_i^2 - n\\bar{x}^2\\right) = \\frac{1}{n-1}\\left(\\sum x_i^2 - \\frac{(\\sum x_i)^2}{n}\\right).\\]\nCheck appears formula booklet.","code":""},{"path":"sampling-and-confidence-intervals.html","id":"the-t-distribution","chapter":"7 Sampling and confidence intervals","heading":"7.2.2 The t distribution","text":"know population variance \\(\\sigma^2\\), uncertainty. data less uncertainty , small samples need account use distribution mass tails.deal use quantiles \\(t\\)-distribution instead quantiles \\(Z\\sim \\text{N}(0,1)\\). picture \\(t\\)-distribution,\nFigure 7.1: fat tails t-distribution\n\\(t\\)-distribution number degrees freedom account decreased uncertainty tails data. number degrees freedom increases can see distribution approaches standard normal density.\nFigure 7.2: t distributions 1, 5 20 degrees freedom\nDefinition 7.3  \\(t\\)-distribution, number degrees freedom \\(\\nu\\) one less number data points.\\[\\nu = n-1\\]Definition 7.4  Given random sample size \\(n\\) normally distributed population unknown population variance \\(100(1-\\alpha)\\%\\) confidence interval population mean \\(\\mu\\) given \\[\\left( \\bar{x} - t_{n-1,\\alpha /2} \\frac{s}{\\sqrt{n}}, \\bar{x} + t_{n-1,\\alpha /2} \\frac{s}{\\sqrt{n}}\\right)\\]\nquantiles \\(t\\)-distribution need obtained table formula booklet, R function \\(\\texttt{qt()}\\).Example 7.5  sample \\(6\\) trout taken fish farm caught lengths centimetres measured. lengths fish follows:\\[ 26.8, \\ 26.0, \\ 25.8, \\ 25.5, \\ 24.3, \\ 24.6 \\]Assuming lengths trout normally distributed:Calculate unbiased estimates mean variance.Calculate unbiased estimates mean variance.Find \\(90\\%\\) confidence interval mean length trout fish farm.Find \\(90\\%\\) confidence interval mean length trout fish farm.solution\nUsing calculator gives \\(\\bar{x}=25.5\\) \\(s^2 = 0.8560\\).\\(90\\%\\) confidence limits \\(\\bar{x}\\) :\\[\\bar{x} \\pm t_{5,5\\%}\\frac{s}{\\sqrt{n}} = 25.5 \\pm 2.015\\times \\frac{0.9252}{\\sqrt{6}}\\]\\[=(24.7,26.3)\\]Example 7.6  (exam-style) masses grams ten packets biscuits particular brand weighed. results summarised computerised weighing machine :\\[\\sum x_i = 3978.8 \\ , \\ \\sum x_i^2 = 1583098.3 \\]assumptions requirements necessary produce \nconfidence interval mean weight packet biscuits? Explain context.assumptions requirements necessary produce \nconfidence interval mean weight packet biscuits? Explain context.Calculate unbiased estimates mean variance.Calculate unbiased estimates mean variance.Calculate \\(95\\%\\) confidence interval.Calculate \\(95\\%\\) confidence interval.weight packet says \\(400\\)g, data support labelling?weight packet says \\(400\\)g, data support labelling?solutionThe sample assumed random. weights assumed follow normal distribution.sample assumed random. weights assumed follow normal distribution.\\[\\bar{x} = 3978.8/10 = 397.88\\text{g}\\]\n\\[s^2 = \\frac{1}{10-1}\\left(1583098.3-\\frac{3978.8^2}{10}\\right) =1.484\\text{g}\\]\\[\\bar{x} = 3978.8/10 = 397.88\\text{g}\\]\n\\[s^2 = \\frac{1}{10-1}\\left(1583098.3-\\frac{3978.8^2}{10}\\right) =1.484\\text{g}\\]required interval :required interval :\\[\\bar{x} \\pm t_{9}(2.5\\%)\\frac{s}{\\sqrt{n}} = 397.88 \\pm 2.2622\\times \\frac{\\sqrt{1.484}}{\\sqrt{10}}\\]\n\\[(397.0,398.8 ) \\]\\(400\\) lies outside interval, sample support labelling.","code":""},{"path":"sampling-and-confidence-intervals.html","id":"required-sample-sizes","chapter":"7 Sampling and confidence intervals","heading":"7.3 Required sample sizes","text":"Note width confidence interval determined required level confidence sample size long know can estimate standard deviation. can use decide advance many observations needed estimate mean given degree precision.Example 7.7  (Ikea) time time firm manufacturing pre-packed furniture needs check mean distance pairs holes drilled machine pieces chipboard ensure change occurred. known experience standard deviation distance \\(0.43\\)mm. first intends take random sample size \\(n\\), calculate \\(99\\%\\) confidence interval mean population. width interval must \\(0.60\\)mm. Calculate minimum value \\(n\\).solutionThe width difference end points interval, twice term added (subtracted) \\(\\bar{x}\\) formula.\\[2z\\frac{\\sigma}{\\sqrt{n}} <0.6\\]\n\\[2\\times 2.576\\times \\frac{0.43}{\\sqrt{n}}<0.6\\]\n\\[2\\times 2.576\\times {0.43}<0.6\\sqrt{n}\\]\n\\[\\frac{2\\times 2.576\\times {0.43}}{0.6}<\\sqrt{n}\\]\n\\[\\sqrt{n} > 3.69\\ldots \\]\n\\[n > 13.6\\ldots \\]\nsmallest value \\(n\\) therefore \\(14\\).","code":""},{"path":"sampling-and-confidence-intervals.html","id":"interval-for-a-population-variance","chapter":"7 Sampling and confidence intervals","heading":"7.4 Interval for a population variance","text":"shown earlier sampling distribution sample variance expectation \\(\\sigma^2\\). , random variable \\(S^2\\) given :\\[S^2 = \\frac{1}{n-1}\\sum_{=1}^n(X_i-\\overline{X})^2 ,\\],\\[\\text{E}(S^2) = \\sigma^2\\]\nyet know distribution \\(S^2\\).introduce relevant distributions, prove proposition derive use derive confidence interval variance.Definition 7.5  random variable \\(Y\\) said chi-squared distribution one degree freedom, written \\(Y\\sim\\chi^2(1)\\) density function:\\[f_Y(y) = \\frac{1}{\\sqrt{2\\pi y}}e^{-y/2} \\]Proposition 7.1  square standard normal distribution \\(Z^2\\) follows \\(\\chi^2(1)\\) distribution. , \\(Z\\sim N(0,1)\\) \\(Z^2\\sim \\chi^2(1)\\)proofRecall density distribution functions standard normal written greek letters \\(f_Z = \\phi\\) \\(F_Z = \\Phi\\). also need remember last week \\(\\phi\\) takes form\\[\\phi(z) =  \\frac{1}{\\sqrt{2\\pi}} \\exp \\left( -\\frac{1}{2}z^2 \\right)\\]Consider distribution function \\(Y=Z^2\\).\n\\[ F_Y(z) = \\text{P}(Z^2<z)\\]\n\\[= \\text{P}\\left(-\\sqrt{z}<Z<\\sqrt{z}\\right)\\]\n\\[=\\int_{-\\sqrt{z}}^{\\sqrt{z}}\\phi(x) \\ dx \\]\\[=\\int_{-\\infty}^{\\sqrt{z}}\\phi(x) \\ dx - \\int_{\\infty}^{-\\sqrt{z}}\\phi(x) \\ dx\\]\n\\[=\\Phi(\\sqrt{z})- \\Phi(-\\sqrt{z})\\]\n\\[=\\Phi(\\sqrt{z})-(1-\\Phi(\\sqrt{z})), \\text{ symmetry}\\]\\[=2\\Phi(\\sqrt{z})-1. \\]\\(F_Y(z) = 2\\Phi(\\sqrt{z})-1\\). can find density differentiating,\\[f_Y (z)= \\frac{d}{dz}F_Y(z)\\]\n\\[=\\frac{d}{dz}\\left[2\\Phi(\\sqrt{z})-1\\right] \\]\\[=2\\Phi'(\\sqrt{z})\\times\\frac{1}{2}z^{-\\frac{1}{2}} , \\text{chain rule}\\]\n\\[=\\Phi'(\\sqrt{z})\\times\\frac{1}{\\sqrt{z}}\\]\ndifferentiating distribution gives density, \\(\\Phi' = \\phi\\). Hence\\[=\\phi(\\sqrt{z})\\times\\frac{1}{\\sqrt{z}}\\]\n\\[=\\frac{1}{\\sqrt{2\\pi}} \\exp \\left( -\\frac{1}{2}(\\sqrt{z})^2 \\right) \\times \\frac{1}{\\sqrt{z}}\\]\n\\[=\\frac{1}{2\\pi z} e^{-z/2}. \\]\ndensity function \\(\\chi^2(1)\\), two random variables density must equal, must \n\\[Z^2 = \\chi^2(1).\\]\nresult hard believe followingProposition 7.2  \\(Z_1 ,Z_2, \\ldots, Z_k\\) independent standard normal random variables sum squares random variables chi-squared distribution \\(k\\) degrees freedom.\\[Z_1^2+Z_2^2+\\ldots+ Z_k^2 \\sim \\chi^2(k) \\]proof: omitted.Theorem 7.1  can scale sampling distribution sample variance chi-squared distribution \\(n-1\\) degrees freedom.\\[\\frac{(n-1)S^2}{\\sigma^2} \\sim\\chi^2_{n-1}\\]proof\\[S^2 =\\frac{1}{n-1}\\sum_{=1}^n(X_i-\\overline{X})^2 \\]\\[(n-1)S^2 =\\sum_{=1}^n(X_i-\\overline{X})^2 \\]\n\\[\\frac{(n-1)S^2}{\\sigma^2} =\\frac{1}{\\sigma^2}\\sum_{=1}^n(X_i-\\overline{X})^2 \\]\n\\[\\begin{equation}\n\\frac{(n-1)S^2}{\\sigma^2} =\\sum_{=1}^n\\left(\\frac{X_i-\\overline{X}}{\\sigma}\\right)^2\n\\tag{7.1}\n\\end{equation}\\]\n\\(\\bar{X}\\) \\(\\mu\\) view RHS sum squares standardised variables. Let \\(Q\\) expression wanted \\[Q = \\sum_{=1}^n\\left(\\frac{X_i-\\mu}{\\sigma}\\right)^2 \\]\\(Q\\sim \\chi^2(n)\\). Now can manipulate\\[Q=\\sum_{=1}^n\\left(\\frac{(X_i- \\bar{X}) + (\\bar{X}-\\mu)}{\\sigma}\\right)^2\\]\nSplitting gives:\n\\[=\\sum_{=1}^n\\left(\\frac{X_i - \\bar{X}}{\\sigma}\\right)^2+2\\left(\\frac{\\bar{X}-\\mu}{\\sigma}\\right)\\sum_{=1}^n \\left(\\frac{X_i-\\bar{X}}{\\sigma}\\right) + \\sum_{=1}^n\\left(\\frac{\\bar{X} - \\mu}{\\sigma}\\right)^2\\]\\[=\\underbrace{\\sum_{=1}^n\\left(\\frac{X_i - \\bar{X}}{\\sigma}\\right)^2}_{(7.1)}+2\\left(\\frac{\\bar{X}-\\mu}{\\sigma^2}\\right)\\underbrace{\\sum_{=1}^n \\left(X_i-\\bar{X}\\right)}_{=0} + n\\left(\\frac{\\bar{X} - \\mu}{\\sigma}\\right)^2\\]\n\\[\\begin{equation}\nQ =\\frac{(n-1)S^2}{\\sigma^2}+n\\left(\\frac{\\bar{X} - \\mu}{\\sigma}\\right)^2\n\\tag{7.2}\n\\end{equation}\\]now think latter term RHS. Last week learned \\[\\bar{X}\\sim N(\\mu,\\sigma^2/n)\\]\nequivalent \\[\\frac{\\bar{X}-\\mu}{\\sigma / \\sqrt{n}} \\sim \\text{N}(0,1),\\]\nsquaring gives\\[n\\left(\\frac{\\bar{X} - \\mu}{\\sigma}\\right)^2 \\sim\\chi^2(1) \\]equation (7.2) yields\\[\\chi^2(n) = \\frac{(n-1)S^2}{\\sigma^2}+\\chi^2(1)\\]\nresult shown.lot cleaner theory moment generating functions transformations random variables second year course. included derivation interested reader.Definition 7.6  \\(x_1,\\ldots,x_n\\) random sample observations normal distribution mean \\(\\mu\\) variance \\(\\sigma^2\\), unknown. confidence interval variance given \\[\\left[ \\frac{(n-1)s^2}{\\chi^2_{n-1,\\alpha / 2}},\\frac{(n-1)s^2}{\\chi^2_{n-1,1-\\alpha / 2}}\\right]\\]proof\\[\\text{P}\\left( \\chi^2(\\alpha / 2)<\\frac{(n-1)S^2}{\\sigma^2} < \\chi^2(1-\\alpha/2) \\right) = 1-\\alpha \\]\nRearranging inequality gives:\\[\\text{P}\\left( \\frac{(n-1)S^2}{\\chi^2_{n-1}(\\alpha / 2)}<\\sigma^2 < \\frac{(n-1)S^2}{\\chi^2_{n-1}(1-\\alpha / 2)} \\right) = 1-\\alpha \\]Example 7.8  order determine accuracy new rifle, \\(8\\) marksmen selected random fire \nrifle target. distances \\(x\\), mm, \\(8\\) shots centre target follows:\n\\[10, \\ \\ 14, \\ \\ 12,\\ \\ 8, \\\\ 6,  \\ \\ 11,  \\ \\ 18, \\ 14.\\]\nAssuming distances normally distributed, find 95% confidence interval variance.solutionCalculating unbiased estimators gives \\(\\bar{x}=11.625\\) \\(s^2 = 14.2679\\).\\(8\\) data, \\(\\nu = 7\\). \\(95\\%\\) middle, require\\[\\chi^2_7 (0.975) = 1.690 \\ \\ \\ ,\\ \\ \\ \\chi^2_7(0.025)=16.013\\]\nCalculating endpoints gives,\n\\[\\frac{(n-1)s^2}{\\chi^2_{n-1}(0.025)}= \\frac{7\\times 14.2679}{16.013} = 6.2371\\ldots\\],\\[\\frac{(n-1)s^2}{\\chi^2_{n-1}(0.025)}= \\frac{7\\times 14.2679}{1.690} = 59.097\\ldots\\]\n\\[(6.24,59.1)\\]\nget interval standard deviation may take square root end points.","code":""},{"path":"sampling-and-confidence-intervals.html","id":"interval-for-a-proportion","chapter":"7 Sampling and confidence intervals","heading":"7.5 Interval for a proportion","text":"derive approximate confidence interval unknown population proportion \\(\\pi\\) based using suitable normal distribution.","code":""},{"path":"sampling-and-confidence-intervals.html","id":"approximating-the-binomial-distribution.","chapter":"7 Sampling and confidence intervals","heading":"7.5.1 Approximating the binomial distribution.","text":"normal distribution really important statistics mild conditions distribution sample mean \\(\\overline{X}\\) normal distribution, distribution original \\(X_i\\) (particular, necessarily normal ). result called Central Limit Theorem (CLT).Due CLT normal distribution can used approximate various discrete distributions, important binomial distribution.result shows even world full chaotic randomness underlying statistical order.Theorem 7.2  \\(X\\sim \\text{Bin}(n,\\pi)\\) \\(X\\approx N(n\\pi,n\\pi(1-\\pi))\\).approximation better sufficiently large \\(n\\), \\(\\pi\\) close \\(\\frac{1}{2}\\).intuitive ideaRecall mean binomial distribution \\(\\text{E}(X)=n\\pi\\), variance \\(\\text{Var}(X)=n\\pi(1-\\pi)\\). theorem says one can approximate discrete distribution normal distribution mean variance.image one can see pmf \\(\\text{Bin}(20,0.5)\\) distribution (red) normal approximation (green). probabilities calculated area curve, adding probabilities corresponds adding areas rectangles. reason convention apply continuity correction using normal approximation calculate probabilities. red rectangles extend \\(0.5\\) either direction particular value \\(x\\).\nFigure 7.3: t distributions 1, 5 20 degrees freedom\nExample 7.9  Approximate probability getting \\(8\\) \\(12\\) heads tossing \\(20\\) fair coins.solution\n\\[Y \\sim \\text{Bin}(20,0.5) \\approx X\\sim \\text{N}(10,0.5)\\]exact probability \\(\\text{P}(Y\\leq 12) - \\text{P}(Y\\leq 7) = 0.7368\\)continuity correction:\\[\\text{P}(8\\leq X\\leq12) = \\text{P}\\left(\\frac{8-0.5-10}{\\sqrt{5}} \\leq Z \\leq \\frac{12+0.5-10}{\\sqrt{5}} \\right) \\]\n\\[=\\text{P}(-1.118\\leq Z \\leq 1.118)\\]\n\\[=0.7364\\]Example 7.10  galton board small ball bearings released internal cavity roll board. board small pins ball bearing hits pin, move left right pin. distribution pins base instrument can seen follow bell-curve empirically.","code":""},{"path":"sampling-and-confidence-intervals.html","id":"proportions","chapter":"7 Sampling and confidence intervals","heading":"7.5.2 Proportions","text":"Rather using normal approximation \\(X\\) directly, often want estimate proportion. number total number \\(\\frac{X}{n}\\).\\(X\\sim \\text{Bin}(n,\\pi)\\) approximated \\(\\text{N}(n\\pi,n\\pi(1-\\pi))\\), happens mean variance want approximation \\(X/n\\)?\\[\\text{E}\\left(\\frac{X}{n}\\right) = \\frac{1}{n}\\text{E}(X)=\\frac{1}{n}\\times n\\pi = \\pi\\]\\[\\text{Var}\\left(\\frac{X}{n}\\right) = \\frac{1}{n^2}\\text{Var}(X)\\]\\[= \\frac{1}{n^2}\\times n\\pi(1-\\pi) = \\frac{\\pi(1-\\pi)}{n}\\]\napproximate proportion use \\(\\text{N}(\\pi,\\frac{\\pi(1-\\pi)}{n})\\)Definition 7.7  confidence interval population proportion \\(\\pi\\) given following expression\\[\\left(p - z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}, p + z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\right)\\]\n\\(p\\) observed proportion.can seen asExample 7.11  importer ordered large consignment tomatoes. arrives examines randomly chosen sample \\(50\\) boxes finds \\(12\\) contain least one bad tomato. Assuming boxes may regarded random sample boxes consignment, obtain approximate \\(99\\%\\) confidence interval proportion boxes containing least one bad tomato, giving confidence limits three decimal places.solutionWe \\(p=0.24\\) \\(1-p = 0.76\\). relevant quantile \\(2.576\\), confidence interval \\[0.24 \\pm 2.576\\sqrt{\\frac{0.24\\times 0.76}{50}} = (0.084,0.396) \\]approximately \\(8\\%\\) \\(40\\%\\).","code":""},{"path":"sampling-and-confidence-intervals.html","id":"summary","chapter":"7 Sampling and confidence intervals","heading":"7.6 Summary","text":"confidence interval can constructed sample summary statistics. four types confidence interval considered week:confidence interval mean variance known.\n\\[\\left( \\bar{x}-z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt{n}},\\bar{x}+z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt{n}} \\right) \\]confidence interval mean variance known.\n\\[\\left( \\bar{x}-z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt{n}},\\bar{x}+z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt{n}} \\right) \\]confidence interval mean variance unknown.\n\\[\\left( \\bar{x} - t_{n-1,\\alpha /2} \\frac{s}{\\sqrt{n}}, \\bar{x} + t_{n-1,\\alpha /2} \\frac{s}{\\sqrt{n}}\\right)  \\]confidence interval mean variance unknown.\n\\[\\left( \\bar{x} - t_{n-1,\\alpha /2} \\frac{s}{\\sqrt{n}}, \\bar{x} + t_{n-1,\\alpha /2} \\frac{s}{\\sqrt{n}}\\right)  \\]confidence interval unknown variance.\n\\[\\left( \\frac{(n-1)s^2}{\\chi^2_{n-1,\\alpha / 2}} \\ , \\ \\frac{(n-1)s^2}{\\chi^2_{n-1,1-\\alpha / 2}}\\right) \\]confidence interval unknown variance.\n\\[\\left( \\frac{(n-1)s^2}{\\chi^2_{n-1,\\alpha / 2}} \\ , \\ \\frac{(n-1)s^2}{\\chi^2_{n-1,1-\\alpha / 2}}\\right) \\]can take square root endpoints standard deviation.confidence interval population proportion.\\[\\left(p - z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}, p + z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\right)\\]used unbiased estimates mean variance\\[\\bar{x} = \\frac{1}{n}\\sum_{=1}^n x_i\\]\\[\\bar{x} = \\frac{1}{n}\\sum_{=1}^n x_i\\]\\[s^2 = \\frac{1}{n-1}\\sum_{=1}^n (x_i - \\bar{x})^2 \\]\\[s^2 = \\frac{1}{n-1}\\sum_{=1}^n (x_i - \\bar{x})^2 \\]\\[=\\frac{1}{n-1}\\left\\{\\sum_{=1}^nx_i^2 - \\frac{\\left(\\sum_{=1}^n x_i\\right)^2}{n} \\right\\} \\]\n- binomial distribution \\(\\text{Bin}(n,p) \\approx \\text{N}(np, np(1-p))\\).","code":""},{"path":"sampling-and-confidence-intervals.html","id":"exercises-week-7","chapter":"7 Sampling and confidence intervals","heading":"7.7 Exercises week 7","text":"Exercise 7.1  random sample size \\(25\\) taken normal distribution standard deviation \\(4\\). sample mean \\(85\\).Find 90% confidence interval mean distribution.Find 90% confidence interval mean distribution.Find 95% confidence interval mean distribution.Find 95% confidence interval mean distribution.Find 99% confidence interval mean distribution.Find 99% confidence interval mean distribution.Compare intervals calculated -c.Compare intervals calculated -c.Exercise 7.2  random sample \\(20\\) lobster traps gave following results:Construct \\(95\\%\\) confidence interval mean weight catch.Construct \\(95\\%\\) confidence interval mean weight catch.assumptions necessary interval valid, one distributional one otherwise.assumptions necessary interval valid, one distributional one otherwise.Give example assumptions may valid context.Give example assumptions may valid context.government made policies reduce -fishing. Historical records mean catch \\(30.31\\)lb. evidence government policy effective?government made policies reduce -fishing. Historical records mean catch \\(30.31\\)lb. evidence government policy effective?Exercise 7.3  Human body temperature can modelled normal distibution mean \\(\\mu\\) variance \\(\\sigma^2\\). Emily, medical student measured body temperature random sample \\(20\\) patients hospital.calculated \\(90\\%\\) confidence interval \\((35.2,41.8)\\).Using Emily’s sample interval, calculate \\(99\\%\\) confidence interval.Exercise 7.4  random sample size \\(25\\) taken normal population standard deviation \\(2.5\\).\nmean sample \\(17.8\\).Find \\(99\\%\\) C.. population mean \\(\\mu\\).Find \\(99\\%\\) C.. population mean \\(\\mu\\).size sample required obtain \\(99\\%\\) C.. width \\(1.5\\)?size sample required obtain \\(99\\%\\) C.. width \\(1.5\\)?confidence level associated interval based sample \\(25\\) width \\(1.5\\), .e. \\((17.05, 18.55)\\)?confidence level associated interval based sample \\(25\\) width \\(1.5\\), .e. \\((17.05, 18.55)\\)?Exercise 7.5  masses (grams) \\(10\\) nails selected random bin \\(90\\) mm long nails :\n\\[9.7, \\ \\ 10.2, \\ \\  11.2, \\ \\  9.4, \\ \\  11.0, \\ \\  11.2, \\ \\  9.8, \\ \\  9.8, \\ \\  10.0, \\ \\  11.3\\]\n. Calculate 98% confidence interval mean mass nails bin.State one assumption made calculation.Exercise 7.6  random sample feet \\(8\\) adult males gave following summary\nstatistics length \\(x\\) (cm):\\[\\sum x = 224.1 , \\ \\ \\ \\ \\ \\ \\sum x^2 = 6337.39 \\]\nAssuming length men’s feet normally distributed, calculate \\(99\\%\\)\nconfidence interval mean length men’s feet based upon results.Exercise 7.7  random sample \\(50\\) one pound coins weighed Royal Mint. found weights grams summarised :\\[\\sum x = 474.51 , \\ \\ \\ \\ \\ \\ \\sum x^2 = 4503.8276 \\]\n) Calculate unbiased estimates mean variance.Find \\(t\\)-distribution value \\(z\\)-value. Compare .Find \\(t\\)-distribution value \\(z\\)-value. Compare .Calculate \\(90\\%\\) confidence interval mean weight pound coin.Calculate \\(90\\%\\) confidence interval mean weight pound coin.Estimate size random sample required give interval half width calculated previous question.Estimate size random sample required give interval half width calculated previous question.later found scales consistently underweighing \\(0.05\\) grams. results ), b) d) need amending, ? Calculate amended values.later found scales consistently underweighing \\(0.05\\) grams. results ), b) d) need amending, ? Calculate amended values.Exercise 7.8  new variety small daffodil grown trial ground nursery. flowering period, random sample \\(10\\) flowers taken lengths, millimetres, stalks measured. results follows:\n\\[266, \\ \\ 254, \\ \\  215, \\ \\  220, \\ \\  253, \\ \\  230, \\ \\  216, \\ \\  248,  \\ \\ 234, \\ \\  244\\]\nAssuming lengths normally distributed, calculate \\(95\\%\\) confidence interval variance lengths.Exercise 7.9  random sample \\(1000\\) voters interviewed, \\(349\\) state support Conservative party. Determine approximate \\(98\\%\\) confidence interval proportion Conservative supporters population.Exercise 7.10  market researcher performs survey order determine popularity washing powder brand “SUDZ”. visits every house large housing estate Manchester area asks question “use SUDZ washing powder?”. \\(235\\) people questioned, \\(75\\) responded positive.Calculate \\(95\\%\\) confidence interval proportion households Manchester area use SUDZ.Calculate \\(95\\%\\) confidence interval proportion households Manchester area use SUDZ.Comment sampling methodology, may impact validity interval.Comment sampling methodology, may impact validity interval.Comment whether interview question effective.Comment whether interview question effective.Exercise 7.11  biased cubical die rolled probability six obtained unknown constant \\(p\\). die rolled \\(40\\) times number \\(X\\) sixes obtained recorded. number \\(Y\\) sixes obtained die rolled \\(60\\) times also recorded.Show \\[T_1 = \\frac{3X+2Y}{240} \\ \\ \\ \\text{     } \\ \\ \\ \\ T_2 = \\frac{X+Y}{100} \\]\nunbiased estimators \\(p\\).\n(Hint: find \\(\\text{E}(T_1)\\) \\(\\text{E}(T_2)\\))Find terms \\(p\\) standard errors \\(T_1\\) \\(T_2\\)Find terms \\(p\\) standard errors \\(T_1\\) \\(T_2\\)Reflecting previous answer, estimators consider better?Reflecting previous answer, estimators consider better?","code":""},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"8 Hypothesis testing","heading":"8 Hypothesis testing","text":"week introduce main method statistical inference - hypothesis test. formulate hypothesis tests, interpret report results hypothesis tests mean variance.also understand test comparisons population parameters.","code":""},{"path":"hypothesis-testing.html","id":"one-sample-tests","chapter":"8 Hypothesis testing","heading":"8.1 One sample tests","text":"operation hypothesis tests can summarised following steps:Summarise competing ideas population parameters terms two hypotheses, called null alternative hypotheses. null hypothesis represents default position, alternative wish test.Summarise competing ideas population parameters terms two hypotheses, called null alternative hypotheses. null hypothesis represents default position, alternative wish test.Choose suitable test statistic, assuming null hypothesis known distribution. Calculate value test statistic, comparing critical value known distribution. calculate probability test statistic least extreme observed sample (p-value).Choose suitable test statistic, assuming null hypothesis known distribution. Calculate value test statistic, comparing critical value known distribution. calculate probability test statistic least extreme observed sample (p-value).basis probability, decide whether evidence reject null hypothesis.basis probability, decide whether evidence reject null hypothesis.step (2) conclusion hypothesis test never \\(100\\%\\) true. Statistical inference involve black white absolute truths, rather subtle.","code":""},{"path":"hypothesis-testing.html","id":"test-for-mean-known-variance","chapter":"8 Hypothesis testing","heading":"8.1.1 test for mean (known variance)","text":"section test hypotheses population mean \\(\\mu\\) normal distribution.implement test depends hypotheses testing.Example 8.1  year trainees throughout country sit test. period time established number marks can modelled normal distribution mean \\(70\\) standard deviation \\(6\\) marks.year thought trainees Greater Manchester performed better expected.random sample \\(25\\) trainees Manchester average mark \\(\\bar{x}=73.2\\).provide evidence, \\(5\\%\\) significance level, trainees Greater Manchester better national average?solutionState hypotheses\\[\\text{H}_0: \\ \\mu = 70 \\\\  \\text{H}_A: \\ \\mu > 70\\]Choose test statisticHere statistic \\(\\bar{X}\\) recall \\(\\bar{X}\\sim\\text{N}(\\mu,6^2/25)\\). Assuming \\(\\text{H}_{0}\\), \\(\\mu=70\\). distribution: \\[\\bar{X}\\sim\\text{N}(70,1.44)\\]calculate standardised value observed sample mean\\[\\frac{\\bar{x} - 70}{\\sigma /\\sqrt{ n}}=\\frac{73.2 - 70}{1.2} = 2.67\\]\ncompare \\(z\\)-value \\(5\\%\\) upper tail, can find inverse normal tables. (upper tail? \\(H_{}\\) \\(>\\) ). See picture .\nFigure 8.1: critical region\nDecision\nNow \\(2.6667 > 1.6449\\), value sample mean critical region. interpretation value extreme worse sufficiently unlikely (\\(<5\\%\\)), able reject \\(\\text{H}_{0}\\).important sample random, otherwise invalidates conclusion. example \\(25\\) particularly high attainers, representative distribution, \\(\\bar{x}\\) may smaller representative sample.example compare positive values, critical region left tail distribution.Definition 8.1  say hypothesis test right-tailed form:\n\\[\\text{H}_A: \\ \\mu > \\mu_0\\]\nhypothesis left-tailed form:\\[\\text{H}_A: \\ \\mu < \\mu_0\\]two-tailed form:\n\\[\\text{H}_A: \\ \\mu \\neq \\mu_0\\]table decision processExample 8.2  testing example suppose sample mean \\(\\bar{x}=69.5\\), wished test \\(5\\%\\) level mean different \\(70\\). :\\[\\text{H}_0: \\ \\mu = 70 \\\\  \\text{H}_A: \\ \\mu \\neq 70\\]\nsolutionWe calculate test statistic :\\[\\frac{\\bar{x}-\\mu_0}{\\sigma / \\sqrt{n}} =\\frac{69.5-70}{1.2}=-0.4167  \\]\nalternative hypothesis \\(\\neq\\) includes left \\(>\\) right \\(<\\) tails. Now \\(5\\%\\) tails, \\(5\\% / 2 =2.5\\%\\) either tail.Using tables find \\(z_{2.5\\%} = 1.960\\). reject test statistic greater \\(1.96\\) test statistic smaller \\(-1.96\\). Equivalently reject \\(\\text{H}_0\\) modulus exceeds 1.96, \\[|\\text{ test statistic}|>1.96.\\]\n\\[|-0.4167| = 0.4167 \\ngtr 1.96,\\]\ninsufficient evidence reject \\(\\text{H}_0\\).Recall interpretation conclusion never definitive. never accept null hypothesis, rather fail reject . may data pass threshold critical value able reject null hypothesis.two-sided alternative hypothesis similar confidence interval.confidence interval confidence level \\(c\\%\\) excludes population value interest, null hypothesis teh population parameter takes value rejected \\(100(1-c)\\%\\) level.Example 8.3  Suppose \\(95\\%\\) confidence interval mean \\(\\mu\\) \\((83.0,85.1)\\), null hypothesis \\(\\mu=85.2\\) rejected \\(5\\%\\) level since interval excludes \\(85.2\\). Indeed hypothesised value outside interval rejected \\(5\\%\\) level.","code":""},{"path":"hypothesis-testing.html","id":"test-for-mean-unknown-variance","chapter":"8 Hypothesis testing","heading":"8.1.2 test for mean (unknown variance)","text":"population variance (\\(\\sigma^2\\)), equivalently population standard deviation \\(\\sigma\\), unknown must estimate sample.small samples distribution test statistic follows \\(t\\)-distribution.null hypothesis given \\(\\text{H}_0: \\mu = \\mu_0\\), test statistic given \\[T = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\\sim t_{n-1}\\]\ndecision rules essentially \\(z_\\alpha\\) \\(z_{\\alpha/2}\\) replaced quantiles t-distribution \\(t_{n-1,\\alpha}\\) \\(t_{n-1,\\alpha}\\), respectively. \\(\\sigma\\) estimated \\(s\\).\\(t_{\\alpha}\\) \\(t_{\\alpha/2}\\) obtained \\(t\\)-tables degrees freedom \\(\\nu = n-1\\), sample variance given , example,\\[s^2 =\\frac{1}{n-1}\\sum_{=1}^{n}(x_i-\\bar{x})^2.\\]Example 8.4  shopkeeper sells jars jam. weights jars jam normally distributed mean \\(150\\)g. customer complains mean weight pack \\(8\\) jars bought \\(147\\)g. estimate standard deviation weights \\(8\\) jars jam calculated \\(8\\) observations \\(2\\)g.Test \\(5\\%\\) significance level whether \\(147\\)g significantly less quoted mean.Test \\(5\\%\\) significance level whether \\(147\\)g significantly less quoted mean.Discuss whether customer cause complaint.Discuss whether customer cause complaint.solution\\[H_{0}: \\mu = 150 \\\\ \\text{H}_A: \\mu<150\\]Significance level \\(=0.05\\), left-tailed test.Degrees freedom \\(\\nu = 8-1 = 7\\).tables \\(t_{7, \\ 5\\%} = -1.895\\)reject \\(H_0\\) statistic less \\(-1.895\\)\\[T =\\frac{\\bar{x}-\\mu}{s/\\sqrt{n}}=\\frac{147-150}{2/\\sqrt{8}}=-4.2426 \\]\nNow \\(-4.2426 < -1.895\\), result significant \\(H_0\\) rejected.evidence suggest mean weight less \\(150\\)g, supporting customer complaint. However one pack random sample, bad batch jars -filled.distribution \\(T\\) \\(t\\)-distribution assume normally distributed population.sample large degrees freedom increased, still need estimate calculate \\(s\\), often \\(z\\)-value can used practice. Strictly speaking \\(t\\)-value used place \\(z\\)-value whenever \\(s\\) used place \\(\\sigma\\) just \\(n\\) small.","code":""},{"path":"hypothesis-testing.html","id":"test-for-variance","chapter":"8 Hypothesis testing","heading":"8.1.3 test for variance","text":"random sample observations normal distribution mean \\(\\mu\\) standard deviation \\(\\sigma\\) unknown, sample variance given (example) formula\\[S^2 = \\frac{1}{n-1}\\sum_{=1}^{n}(x_i-\\bar{x})^2\\]Recall can shown \\[\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi^2_{n-1}\\]test null hypothesis variance particular value, \n\\[\\text{H}_0: \\sigma^2 = \\sigma_0^2\\]\ncan just compare expression \\(\\frac{(n-1)S^2}{\\sigma^2}\\), hypothesised population variance, relevant quantile chi-squared distribution. gives following decision rules:Example 8.5  bus company trying improve reliability, consistency respect schedule monitored. company wants arrival time standard deviation \\(2\\) minutes less. sample \\(10\\) arrival times shows sample variance \\(5\\). Using \\(5\\%\\) signifiance level, data suggest variance arrival times meeting company standard?solution\nhypotheses :\n\\[\\text{H}_0: \\sigma^2=4 \\ \\ \\ , \\ \\ \\ \\text{H}_A: \\sigma^2 >4\\]\ntest statistic :\n\\[\\frac{(n-1)S^2}{\\sigma^2}=\\frac{9\\times5}{4} = 11.25\\]\ncritical value \n\\[\\chi^2_{\\alpha,n-1}=\\chi^2_{0.05,9}=16.92\\]\nSince \\(11.25\\ngtr16.92\\) insufficient evidence reject \\(\\text{H}_0\\). Therefore unable conclude variance bus arrival times meeting company standard.","code":""},{"path":"hypothesis-testing.html","id":"p-value-approach","chapter":"8 Hypothesis testing","heading":"8.1.4 p-value approach","text":"two ways looking comparison involved reject null hypothesis, via critical region via p-values. critical region rather blunt uninformative - either reject reject null. However, p-value allows us quantify weight evidence null hypothesis given sample data. many tests exact p-values can calculated R.Definition 8.2  p-value probability observing value statistic least extreme particular value statistic observed sample.example sample gives sample mean \\(\\bar{x}=101.3\\) p-value \\[p  =\\text{P}(\\bar{X}\\geq101.3).\\]illustrate example right tailed test.Example 8.6  Suppose want test following:\n\\[\\text{H}_0:\\mu = 26.3 \\ \\ \\ , \\ \\ \\ \\text{H}_A: \\mu >26.3\\]:Perform testPerform testCalculate p-valueCalculate p-valueHere can work \\(z\\)-value tobe \\(1.6449\\). statistic \\[\\frac{27 - 26.3}{1.2/\\sqrt{10}} = 1.845\\]\nreject \\(\\text{H}_0\\) \\(1.845 > 1.6449\\).know null hypothesis \\(\\bar{X} \\sim \\text{N}(26.3, 1.2^2/10)\\).p-value probability observing particular value least extreme \\(\\bar{x}=27\\).use distribution \\(\\bar{X}\\) directly already standardised value find \\[p = \\text{P}(\\bar{X} >27) = \\text{P}(Z>1.845) = 0.0325 \\]example p-value \\(0.0325\\) significance level \\(5\\%\\). p-value can compared significance level directly conclude hypothesis test. p-value lower significance level, can reject null hypothesis.statistic greater critical value p-value (tail probability) less significance level. See following picture:\nFigure 8.2: critical region\ntests involving t-distribution chi-squared distribution, p-value practice obtained via software R, see labs week.Usually p-value compared \\(5\\%\\) however, standard interpretations p-values quantify evidence \\(\\text{H}_0\\).formal reports significant effect found, quantify effect confidence interval. Phrasing conclusions important, always set context (without jargon e.g. H\\(_0\\)).","code":""},{"path":"hypothesis-testing.html","id":"types-of-error","chapter":"8 Hypothesis testing","heading":"8.1.5 types of error","text":"decision relying imperfect information allow fact uncertainty decision certain. two types systematic uncertainty arise hypothesis testing, types error.Example 8.7  Suppose man court accused murder. decision judge jury come separate truth guilt innocence man.\\[\\ \\ \\ \\ \\text{H}_0: \\text{man innocent} \\\\ \\text{H}_1: \\text{man guilty}\\]\ntrial process like hypothesis test evidence presented equivalent data. possible decisions summarised table :undesirable sentence innocent man, find set guilty man loose.Definition 8.3  two types error systematic hypotheis testing.type error reject null hypothesis , fact true.type II error accept null hypothesis fact false.probabilities type error important, seek minimise possible.Definition 8.4  significance level test probability type error.\n\\[\\text{P}(\\text{Type error}) = \\text{P}(\\text{H}_0 \\text{ rejected} | \\text{H}_0 \\text{ true})\\]\ngiven significance level example \\(5\\%\\), probability type error. However may always stated question may work .Example 8.8  random variable normal distribution mean µ standard deviation \\(3\\).\nnull hypothesis \\(\\mu=20\\) tested alternative hypothesis \\(\\mu>20\\) using random sample \\(25\\).\ndecided null hypothesis rejected sample mean greater \\(21.4\\).\nCalculate probability making type error.solution\\[\\text{P}(\\text{Type error}) = \\text{P}(\\text{H}_0 \\text{ rejected} | \\text{H}_0 \\text{ true})\\]\n\\[=\\text{P}(\\bar{X} > 21.4 \\ | \\ \\mu = 20)\\]\ncan obtained, example standardising tables,\n\\[=\\text{P}\\left(\\frac{\\bar{X}-20}{3/\\sqrt{25}}>\\frac{21.4-20}{3/\\sqrt{25}} \\right)\\]\n\\[=\\text{P}(Z>2.33) = 9.9\\times 10^{-3} \\approx 1\\%\\]Example 8.9  weight jam jar, measured grams, distributed normally mean \\(150\\)g standard deviation \\(6\\)g. production process occasionally leads change mean weight jam per jar standard deviation remains unaltered. manager monitors production process every new batch takes random sample \\(25\\) jars weighs contents see reduction mean weight jam per jar.\nFind critical values test statistic \\(\\bar{X}\\), mean weight jam sample \\(25\\) jars, using5% level significance5% level significance1% level significance1% level significanceGiven true value µ new batch fact 147g. Find probability type II error critical regionsGiven true value µ new batch fact 147g. Find probability type II error critical regionssolution\n) \\(z_{5\\%} = -1.6449\\), reject \\(H_0\\) \\[\\frac{\\bar{x}-150}{6/\\sqrt{25}}<-1.6449 \\]\nRearranging inequality gives \\(\\bar{x} < 148.03\\)\\(z_{1\\%} = -2.326\\) , rearranging similar inequality gives \\(\\bar{x} < 147.208\\ldots\\)\\(z_{1\\%} = -2.326\\) , rearranging similar inequality gives \\(\\bar{x} < 147.208\\ldots\\)use distribution \\(\\bar{X}\\sim\\text{N}(147, 6^2/\\sqrt{25})\\). Type II error reject \\(H_0\\) reverse inequalities regions evaluate probabilities:use distribution \\(\\bar{X}\\sim\\text{N}(147, 6^2/\\sqrt{25})\\). Type II error reject \\(H_0\\) reverse inequalities regions evaluate probabilities:\\[\\text{P}(\\bar{x} \\geq 148.03 | \\ \\mu = 147) = 0.195 \\approx 20\\%\\]\\[\\text{P}(\\bar{x} \\geq 147.2 | \\ \\mu = 147) = 0.4309\\ldots \\approx 43\\%\\]reduce P(Type error) 5% 1%, P(Type II error) increased \\(\\approx 20\\%\\) \\(43\\%\\). just reducing probability one type error cure-.","code":""},{"path":"hypothesis-testing.html","id":"two-sample-tests","chapter":"8 Hypothesis testing","heading":"8.2 Two sample tests","text":"may wish use hypothesis testing compare two populations. two populations may distributions heights males females separately. may wish compare average weights babies born one region another.Supposing two distributions \\(X\\) \\(Y\\), write population parameters subscript indicate distribution correspond. basic setup followsThe main hypotheses interest whether means different. :\\[\\text{H}_0: \\mu_X = \\mu_Y \\ \\ \\ \\ \\ \\ , \\ \\ \\ \\ \\ \\text{H}_A:\\mu_X \\neq \\mu_Y\\]Though one-sided alternatives, specified differences can also used.assume populations normally distributed consider three different situations:population variances knownThe population variances knownThe population variances unknown, known assumed equal.population variances unknown, known assumed equal.population variances unknown assumed equal.population variances unknown assumed equal.","code":""},{"path":"hypothesis-testing.html","id":"known-variance","chapter":"8 Hypothesis testing","heading":"8.2.1 known variance","text":"Assume random sample \\(x_1,x_2,\\ldots,x_{n_1}\\) \\(n_1\\) observations first population, another random sample \\(y_1,y_2,\\ldots, y_{n_2}\\) \\(n_2\\) observations second population.test statistic \\(\\bar{X}-\\bar{Y}\\).Recall sampling distribution mean takes form:\n\\[\\bar{X} \\sim \\text{N}(\\mu_X, \\sigma^2_X / n_1) \\ \\ \\ \\ \\ \\ , \\ \\ \\ \\ \\bar{Y} \\sim \\text{N}(\\mu_Y, \\sigma^2_Y / n_2)\\]\n, difference normal distributions normal, linearity expectation variance sum variances :\\[\\bar{X}-\\bar{Y} \\sim \\text{N}\\left(\\mu_X-\\mu_Y , \\frac{\\sigma_X^2}{n_1} + \\frac{\\sigma_Y^2}{n_2}\\right)\\]\ntest statistic standardised value statistic:\\[Z = \\frac{\\bar{X} - \\bar{Y} - (\\mu_X-\\mu_Y)}{\\sqrt{\\frac{\\sigma_X^2}{n_1} + \\frac{\\sigma_Y^2}{n_2}}}\\]\n\\[\\sim\\text{N}(0,1).\\]\nNow null hypothesis \\(\\mu_X-\\mu_Y = 0\\), simplifies :\\[\\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{\\sigma_X^2}{n_1} + \\frac{\\sigma_Y^2}{n_2}}}\\]\ndecision rules .Example 8.10  weights boys girls particular age known normally distributed standard deviations \\(5\\)kg \\(8\\)kg respectively. particular school, random sample \\(25\\) boys mean weight \\(48\\)kg random sample \\(30\\) girls mean weight \\(45\\)kg.Test, \\(5\\%\\) significance level, whether evidence mean weight boys greater girls.solution\\[\\text{H}_0: \\mu_B = \\mu_G \\ \\ \\ \\ \\ \\ , \\ \\ \\ \\ \\ \\text{H}_A:\\mu_B > \\mu_G\\]\n\\[\\frac{\\bar{B}-\\bar{G}}{\\sqrt{\\frac{\\sigma_B^2}{n_1} + \\frac{\\sigma_G^2}{n_2}}}= \\frac{48-45}{\\sqrt{\\frac{5^2}{25}+\\frac{8^2}{30}}}= 1.69747\\ldots \\]\ncritical value \\(1.6449\\)\nHence reject null hypothesis conclude sufficient evidence say boys weigh girls average.","code":""},{"path":"hypothesis-testing.html","id":"unknown-equal-variance","chapter":"8 Hypothesis testing","heading":"8.2.2 unknown equal variance","text":"section know can assume variances equal. may know outright variances equal, even unknown. example, take sample men’s heights Manchester compare sample men’s heights London. may average height differences, UK adult men come containing population, can assumed just variable .case know \\(\\sigma_X^2\\) \\(\\sigma_Y^2\\), estimate actual data. can estimate \\[s_x^2 = \\frac{1}{n_1}\\sum_{=1}^n(x_i-\\bar{x})^2 \\ \\ \\ \\ , \\ \\ \\ \\ s_y^2 = \\frac{1}{n_2}\\sum_{j=1}^n(y_j-\\bar{y})^2 \\]now two estimates unknown population variances \\(\\sigma_x^2, \\ \\sigma_y^2\\). know, can assume, equal common population variance \\(\\sigma_x^2=\\sigma_y^2=\\sigma^2\\). solution ‘pool’ variance using formula:\\[s_p^2  = \\frac{(n_1-1)s_x^2+(n_2-1)s_y^2}{n_1+n_2-2}\\]\ntest statistic calculated ,\\[T = \\frac{\\bar{X}-\\bar{Y}}{s_p\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}} \\sim t_{n_1+n_2-2} \\]\nfollows t distribution \\(n_1+n_2-2\\) degrees freedom.Example 8.11  heights (measured nearest centimetre) random sample six policement certain force Wales found \n\\[176, \\ 180, \\ 179, \\ 181, \\ 183, \\ 179.\\]\nheights random sample \\(11\\) policemen Scotland gave following data\\[\\sum y =1991  \\ \\ \\ \\ , \\ \\ \\ \\sum(y-\\bar{y})^2 = 54\\]\n) Test \\(5\\%\\) level hypothesis Welsh policemen shorter Scottish policemen.assumptions necessary part ()?solutionThe hypotheses \n\\[\\text{H}_0: \\mu_{x} = \\mu_{y} \\ \\ \\ \\ , \\ \\ \\ \\text{H}_A: \\mu_{x}< \\mu_{y}\\]\nquestion:\\[\\bar{x}=179.66667, \\ \\ s^2_x =5.46667 \\]\\[\\bar{y}= 1991/11 = 181, \\ \\ \\ s^2_y = 54/10 = 5.4 \\]\nobserve 5.4 5.47 approximately equal, reasonable pool .\\[s^2_p = \\frac{(6-1)\\times5.46667 +(11-1)\\times5.4 }{6+11-2} =5.422\\ldots\\]\nGiving pooled standard deviation \\(\\sqrt{5.422} = 2.329\\).\n(want work bit accurately accuracy critical value comparing )Now evaluating test statistic:\\[\\frac{179.66 - 181}{2.329\\sqrt{\\frac{1}{6}+\\frac{1}{11}}} =  -1.128\\]\ncompare \\(t_{15, 0.05} = 1.7531\\)Comparison: \\(|-1.128|\\ngtr 1.7531\\)insufficient evidence based samples conclude population Welsh officers shorter population Scottish officers.","code":""},{"path":"hypothesis-testing.html","id":"testing-for-equal-variance","chapter":"8 Hypothesis testing","heading":"8.2.3 testing for equal variance","text":"situation two sample variances \\(S^2_x\\) \\(S^2_y\\), want determine means hypothesis test equal . course conclusion definite, practice informs whether pool variances .null hypothesis variances equal, usual alternatives.\\[\\text{H}_0: \\sigma^2_x = \\sigma^2_y\\ \\]First recap. know scaled, sample variances follow \\(\\chi^2\\)-distribution. ,\\[\\frac{(n_1-1)S^2_x}{\\sigma^2_x}\\sim \\chi^2_{n_1-1} \\ \\ \\ , \\ \\ \\  \\frac{(n_2-1)S^2_y}{\\sigma^2_y}\\sim \\chi^2_{n_2-1}\\]another distribution must define, last statistical tables.Definition 8.5  Let \\(X\\sim \\chi^2_n\\) \\(Y\\sim \\chi^2_m\\) following ratio defines F-distribution degrees freedom \\(n\\) \\(m\\). :\\[\\frac{\\left(\\frac{X}{n}\\right)}{\\left(\\frac{Y}{m}\\right)}\\sim \\text{F}_{n,m}\\]situation tells us null hypothesis \\[\\frac{S^2_x}{S^2_y}\\sim \\text{F}_{n_1 - 1,n_2-1} \\]\n:::{.example}\nmanufacturer wooden furniture stores wood outside inside special\nstore. believed wood stored inside less variable hardness properties stored outside. \\(25\\) pieces wood stored outside taken compared \\(21\\) similar pieces taken inside store, following results:Test \\(5\\%\\) significance level whether manufacturer’s belief correct.Test \\(5\\%\\) significance level whether manufacturer’s belief correct.State two assumptions necessary carry test.State two assumptions necessary carry test.solutionWe wish test\\[\\text{H}_0: \\sigma^2_x=\\sigma^2_y \\ \\ \\ , \\ \\ \\ \\text{H}_A: \\sigma^2_x>\\sigma^2_y\\]\nWorking sample variances gives\\[s^2_x = \\frac{5190}{25}=216.25, \\ \\ \\ s^2_y = \\frac{3972}{20} = 198.6\\]\ntest statistic \\[216.25/198.6 = 1.089,\\]\ncompare \\(\\text{F}_{24,20} = 2.08\\).Now, \\(1.089 < 2.08\\) insufficient evidence reject \\(\\text{H}_0\\). wood outside just variable wood inside.assumption populations normal, samples independent random.\n:::","code":""},{"path":"hypothesis-testing.html","id":"unknown-unequal-variances-non-examinable","chapter":"8 Hypothesis testing","heading":"8.2.4 unknown unequal variances (non-examinable)","text":"want carry \\(2\\) sample \\(t\\)-test without assuming equal population variances can use \\[T = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{S_X^2}{n_1} + \\frac{S_Y^2}{n_2}}}\\]However distribution quantity general convenient closed-form (analytic). actually famous unsolved problem generally, called Behrens–Fisher problem. However approximately \\(t_\\nu\\)-distribution degrees freedom \\(\\nu\\) given integer part following expression.\\[\\frac{\\left[\\frac{S^2_x}{n_1}+\\frac{S^2_y}{n_2} \\right]^2}{\\frac{1}{(n_1-1)}\\left[\\frac{S_x^2}{n_1}\\right]^2+\\frac{1}{(n_2-1)}\\left[\\frac{S_y^2}{n_2}\\right]^2} \\]expression known Welch approximation.Example 8.12  market inspector randomly samples produce two market stalls. sample \\(80\\) apples Rufus Russett’s stall masses (grams) sample mean \\(74.2\\) sample variance \\(43.23\\).\nindependent random sample \\(100\\) apples sold Granny Smith sample mean \\(68.6\\) sample variance \\(43.34\\).Test \\(5\\%\\) significance level evidence apples Smith’s stall lower average mass Russett’s stall.solutionWe testing\n\\[\\text{H}_0: \\mu_x = \\mu_y \\ \\ \\ , \\ \\ \\text{H}_A:\\mu_x>\\mu_y\\]\ntest statistic \\[ \\frac{74.2 - 68.8}{\\sqrt{\\frac{24.21}{80}+\\frac{43.23}{100}}} = 6.299\\]\nwant compare \\(t_\\nu\\). Let’s evaluate degrees freedom :\\[\\frac{\\left[\\frac{24.21}{80}+\\frac{43.23}{100} \\right]^2}{\\frac{1}{79}\\left[\\frac{24.21}{80}\\right]^2+\\frac{1}{99}\\left[\\frac{43.23}{100}\\right]^2} = 177.26 \\]\ninteger value \\(177\\), check critical value \\(t_177\\) distribution.However \\(177\\) large number degrees freedom, use \\(t_{\\infty}=1.6448\\) \\(z\\)-value essentially, null overwhelmingly rejected, \\(6.299 >1.6448\\).","code":""},{"path":"hypothesis-testing.html","id":"summary-1","chapter":"8 Hypothesis testing","heading":"8.2.5 Summary","text":"hypothesis test decision process population parameters.One sample tests learned include:one sample \\(z\\)-test mean, known variance\n\\[ \\frac{\\bar{x}-\\mu_0}{\\sigma/\\sqrt{n}}\\sim \\text{N}(0,1) \\]one sample \\(z\\)-test mean, known variance\n\\[ \\frac{\\bar{x}-\\mu_0}{\\sigma/\\sqrt{n}}\\sim \\text{N}(0,1) \\]one sample \\(t\\)-test, mean, unknown variance\n\\[T = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\\sim t_{n-1}\\]one sample \\(t\\)-test, mean, unknown variance\n\\[T = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\\sim t_{n-1}\\]one sample test varianceone sample test variance\\[\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi^2_{n-1} \\]two types systematic errors occur test hypotheses, typically limit type error setting significance level.can compare two independent samples :two sample \\(z\\)-test (known variances)\\[\\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{\\sigma_X^2}{n_1} + \\frac{\\sigma_Y^2}{n_2}}}\\sim \\text{N}(0,1)\\]two sample \\(t\\)-test (unknown equal variances) require pooled variance estimate:\\[T = \\frac{\\bar{X}-\\bar{Y}}{s_p\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}} \\sim t_{n_1+n_2-2}\\]\n\\[s_p = \\frac{(n_1-1)s_x^2+(n_2-1)s_y^2}{n_1+n_2-2}\\]can often assume variances equal. also test equality variances.","code":""},{"path":"hypothesis-testing.html","id":"exercises-week-8","chapter":"8 Hypothesis testing","heading":"8.3 Exercises week 8","text":"Exercise 8.1  Jars honey filled machine. lifetime machine, found quantity honey mean \\(460.3\\)g standard deviation \\(3.2\\)g. believed machine altered mean may changed. \\(60\\) jars taken mean quantity honey per jar found \\(461.2\\)gState suitable null alternative hypothesesState suitable null alternative hypothesesCarry test using \\(5\\%\\) level significance.Carry test using \\(5\\%\\) level significance.State two assumptions required test, give example may hold true.State two assumptions required test, give example may hold true.Exercise 8.2  distance driven long distance lorry driver week normally distributed variable mean \\(1130\\)km standard deviation \\(106\\)km. New driving regulations introduced , first \\(20\\) weeks drives total \\(21900\\)km. Assuming standard deviation changed since new regulations, test \\(10\\%\\) level significance whether mean weekly distance reduced. State clearly null alternative hypotheses.Exercise 8.3  nuclear accident,government scientists measured radiation levels \\(20\\) randomly chosen sites small area. measuring instrument used calibrated measure ratio present radiation previous known average radiation area. measurements summarised \\[\\sum x = 22.8 \\ \\ , \\ \\ \\sum x^2 = 27.55\\]\nMaking suitable assumptions test, \\(5\\%\\) level, hypothesis increase radiation level.Exercise 8.4  Bottles wine supposed contain \\(75\\)cl wine. inspector takes sample six bottles determines volumes contents, correct nearest half millilitre. results :\\[747.0, \\ \\  ,751.5, \\ \\ 752.0, \\  \\ 747.5, \\ \\ 748.0, \\ \\ 748.0 \\]\nDetermine whether results provide evidence \\(5\\%\\) significance level population mean less \\(75\\)cl.assumption distribution volumes necessary?distribution sample necessary?Exercise 8.5  given \\(X\\sim\\text{N}(\\mu,16)\\). desired test null hypothesis \\(\\mu=12\\) alternative \\(\\mu>12\\), probability type error \\(1\\%\\). random sample \\(15\\) observations \\(X\\) taken sample mean \\(\\bar{X}\\) taken test statistic.Find range values \\(\\bar{X}\\) lead torejecting null hypothesisnot rejecting null hypothesisGiven \\(\\mu = 15\\), calculate probability type II error.Exercise 8.6  mean random sample \\(10\\) observations population distributed \\(\\text{N}(\\mu_1,25)\\) \\(97.3\\). mean random sample \\(15\\) observations population distributed \\(\\text{N}(\\mu_2,36)\\) \\(101.2\\). Test \\(5\\%\\) levelWhether \\(\\mu_1 < \\mu_2\\)Whether \\(\\mu_1 < \\mu_2\\)Whether \\(\\mu_1\\neq\\mu_2\\)Whether \\(\\mu_1\\neq\\mu_2\\)Exercise 8.7  machine assesses life ball-point pen measuring length continuous line drawn using pen. random sample \\(80\\) pens brand total writing length \\(96.84\\)km. random sample \\(75\\) ens brand B total writing length \\(93.75\\)km.\nGiven standard deviation writing length single pen \\(0.15\\)km brands,test \\(5\\%\\) level, whether writing lengths two brands differ significantly.Exercise 8.8  random sample \\(10\\) yellow grapefruit weighed average weight found \\(\\bar{x}=201.4\\)g. value unbiased estimate population variance \\(s^2_x=234.1\\). corresponding figures random sample \\(8\\) pink grapefruit \\(\\bar{y}=221.8\\)g \\(s^2_y=281.9\\). Determine \\(1\\%\\) level significance, whether difference mean weights two kinds grapefruit.Exercise 8.9  volume beer random sample \\(7\\) pints bought ‘Sensible Statistician’ measured litres results summarised :\n\\[\\sum x = 4.15, \\ \\ \\sum x^2 = 2.4638\\]\nresults random sample \\(5\\) pints ‘Mad Mathematician’ summarised :\n\\[\\sum y = 2.79 , \\ \\ \\sum y^2 = 1.5585\\]Assuming population variances equal, find pooled estimate common variance.Assuming population variances equal, find pooled estimate common variance.Test \\(5\\%\\) significance level whether beer pint ‘Sensible Statistician’ ‘Mad Mathematician’.Test \\(5\\%\\) significance level whether beer pint ‘Sensible Statistician’ ‘Mad Mathematician’.Exercise 8.10  machine saws logs wood lengths supposed standard deviation \\(3\\)cm. machine goes wrong standard deviation increases. random sample \\(10\\) logs lengths cm follows:\\[997, \\ \\ , 1004, \\ \\ 1009, \\ \\ 999, \\ \\ 1006, \\ \\, 1014, \\ \\ 998, \\ \\ 999, \\ \\ 1001, \\ \\ 1000 \\]Determine whether evidence \\(1\\%\\) significance level machine gone wrong.Exercise 8.11  following observations taken normal distribution believed unit variance.\n\\[16.2, \\ \\ 14.4, \\ \\ 17.9, \\ \\ 11.6, \\ \\ 18.3, \\ \\ 15.5, \\ \\ 17.2, \\ \\ 16.6\\]Determine whether evidence population variance equal 1.Exercise 8.12  cellulose contents leaves tree determined random samples leaves taken two different locations. results shown :Location 1:\n\\[15.4, \\ \\ 13.9, \\ \\ 15.1, \\ \\ 14.8, \\ \\ 14.4, \\ \\ 14.8, \\ \\ 15.0, \\ \\  13.9, \\ \\ 15.4, \\ \\ 14.6, \\ \\ 14.8 \\]\nLocation 2:\n\\[13.8, \\ \\ 14.4, \\ \\ 13.0, \\ \\ 15.3, \\ \\ 14.7, \\ \\ 14.3, \\ \\ 14.1, \\ \\ 12.9, \\ \\ 14.9 \\]\nLet population variances two locations denoted \\(\\sigma_1^2\\) \\(\\sigma_2^2\\).Obtain unbiased estimates \\(\\sigma_1^2\\) \\(\\sigma_2^2\\).Obtain unbiased estimates \\(\\sigma_1^2\\) \\(\\sigma_2^2\\).Test hypothesis \\(\\sigma_1^2=\\sigma_2^2\\).Test hypothesis \\(\\sigma_1^2=\\sigma_2^2\\).","code":""},{"path":"goodness-of-fit-and-association.html","id":"goodness-of-fit-and-association","chapter":"9 Goodness of fit and association","heading":"9 Goodness of fit and association","text":"","code":""},{"path":"goodness-of-fit-and-association.html","id":"introduction","chapter":"9 Goodness of fit and association","heading":"9.1 Introduction","text":"week formulate hypothesis tests association evaluate model fit. interpret results test describe nature association two factors defining contingency table. recognise form multinomial distribution compare known discrete distributions. work carry chi-squared goodness fit test distributions learned previously.two main situations \\(\\chi^2\\) significance test used:\\(\\chi^2\\) goodness--fit testIn test may practical data want know well particular statistical distribution, binomial normal, models data. null hypothesis assume data follows particular distribution.\\(\\chi^2\\) test association (independence)used practical data concerning two variables want know whether independent whether association exists two. null hypothesis factors independent.Following process hypothesis tests previously established, assume null hypothesis calculate expected frequencies compared observed data. test statistic involving expected observed frequencies calculated compared appropriate critical value \\(\\chi^2\\) distribution.","code":""},{"path":"goodness-of-fit-and-association.html","id":"measuring-discrepancy","chapter":"9 Goodness of fit and association","heading":"9.1.1 Measuring discrepancy","text":"Suppose roll apparently normal fair six-sided die \\(60\\) times, obtain following frequencies:notice numbers?sample (possible results rolling die) seems rather large number \\(3\\)s \\(6\\)s. die fair biased?fair die probability outcome \\(\\frac{1}{6}\\). \\(60\\) tosses expected frequencies \\(\\frac{1}{6}\\times 60=10\\).question whether observed frequencies expected frequencies reasonably close unreasonably different. add differences table:larger magnitude differences, observed data differs expected model (fair die).Suppose now roll second die \\(660\\) times. expected ? Suppose obtain following results:time observed values seem remarkably close, yet difference \\(O-E\\) values .\njust sizeof \\(O-E\\) matters, also size relative expected frequency:\\[\\frac{O-E}{E}\\]\nCombining ideas absolute ‘difference’ ‘relative size’ matter suggests using product\\[(O-E)\\times\\frac{(O-E)}{E} = \\frac{(O-E)^2}{E}.\\]\naggregate measure goodness fit measure\\[X^2 = \\sum_{=1}^m \\frac{(O_i-E_i)^2}{E_i}\\]\\(m\\) number different outcomes.","code":""},{"path":"goodness-of-fit-and-association.html","id":"contingency-tables-and-association","chapter":"9 Goodness of fit and association","heading":"9.2 Contingency tables and association","text":"simplest form contingency table consists two-way table counts frequencies. rows columns table often referred factors. begin revising independent events two way tables.Example 9.1  taken random sample \\(310\\) graduates six months graduation information course (Bachelor Arts BA, Bachelor Science BSc) employment status presented .Work \\(\\text{P}(\\text{Full-time employed})\\)Work \\(\\text{P}(\\text{Full-time employed})\\)Work \\(\\text{P}(\\text{earned BSc})\\)Work \\(\\text{P}(\\text{earned BSc})\\)events \\(\\{\\text{Full-time employed}\\}\\) \\(\\{\\text{earned BSc} \\}\\) independent?events \\(\\{\\text{Full-time employed}\\}\\) \\(\\{\\text{earned BSc} \\}\\) independent?solution\\(190/310=0.613\\)\\(158/310 = 0.510\\)independence events \\(\\) \\(B\\) require\n\\[\\text{P}(\\cap B)=\\text{P}()\\times\\text{P}(B).\\]\nintersection probability \\(100/310 = 0.323\\). product answers () (b) give\n\\[\\frac{190}{310}\\times\\frac{158}{310}= 0.313\\].answer independent, quite close!Instead testing event columns independent event rows can test see column factor whole independent , associated , row factor.test statistic used situation known chi-squared statistic test hypotheses.\\[\\text{H}_0: \\text{ association employment status degree type}\\]\n\\[\\text{H}_A: \\text{association employment status degree type}\\]helpful consider table totals :need consider expect counts indeed association two factors. Recall following expected totals.Example 9.2  toss fair coin \\(100\\) times, many expect tails?solution\\(100 \\times 0.5=50\\)example ,\n\\[\\text{Expected number} = \\text{Total} \\times \\text{Probability}.\\]Suppose table like :events \\(\\{\\text{Full-time employed}\\}\\) \\(\\{\\text{earned BSc} \\}\\) independent can said \\(E\\)? Well, grand total multiplied probability cell. Assuming independence get:\\[E = \\text{Grand Total} \\times \\frac{\\text{Row Total}}{\\text{Grand Total}}\\times \\frac{\\text{Column Total}}{\\text{Grand Total}}\\]\n\\[= \\frac{\\text{Row Total}\\times\\text{Column Total}}{\\text{Grand Total}}\\]\nUsing formula can work expected (E) values every entry tableWe calculate statistic:\\[X^2 = \\frac{(100-96.84)^2}{96.84}+\\frac{(33-37.21)^2}{37.21} + \\frac{(25-23.95)^2}{23.95}+\\ldots+\\frac{(22-23.05)^2}{23.05}\\]\n\\[=0.103 + 0.476 + 0.046 + 0.107 + 0.494 + 0.047\\]\n\\[=1.273\\]\nneed compare test statistic \\(95^{\\text{th}}\\) percentile suitable \\(\\chi^2\\) distribution.column sums row sums constrained, number degrees freedom given , number columns minus one multiplied number rows minus one. \\[\\nu = (r-1)\\times(c-1)\\]\n\\(\\nu = (2-1)\\times(3-1) = 2\\). critical value \\(\\chi^2_{2, 95\\%}=5.99\\).\n\\(1.273 \\ngtr 5.99\\), insufficient evidence say association degree type employment status.","code":""},{"path":"goodness-of-fit-and-association.html","id":"goodness-of-fit","chapter":"9 Goodness of fit and association","heading":"9.3 Goodness of fit","text":"","code":""},{"path":"goodness-of-fit-and-association.html","id":"discrete-uniform-test","chapter":"9 Goodness of fit and association","heading":"9.3.1 Discrete uniform test","text":"can formally test outcomes equally likely using chi-squared test following example.Example 9.3  table shows number employees absent just one day particular period time large company.Calculate expected frequencies according hypothesis number absentees independent day week.Calculate expected frequencies according hypothesis number absentees independent day week.Test \\(5\\%\\) significance level whether teh differences observed expected data significant.Test \\(5\\%\\) significance level whether teh differences observed expected data significant.solutionThe hypotheses \\[\\text{H}_0: \\text{number absentees independent day week}\\]\n\\[\\text{H}_A: \\text{number absentees independent day week}\\]\n\\(\\text{H}_0\\), chance absent given weekday \\(\\frac{1}{5}\\). total number days absent table \\(500\\). Therefore expected number absentees given day \n\\[\\frac{1}{5}\\times 500 = 100.\\]\nb) number degrees freedom number classes minus number restrictions numbers table (one restriction \\(\\sum E= 500\\))\n\\[\\nu=5-1=4\\]\nget critical value \n\\[\\chi^2_{n-1, \\ 95\\%} =9.488\\]\nNow calculate test statistic \\(X^2\\), via tabulating contributions.\\[X^2 = 10.56\\]\n\\[X^2 = 10.56 > 9.488\\]\nReject \\(\\text{H}_0\\), conclude sufficient evidence number absentees day independent day week.Note test tell us nature failure independence.biggest contributions statistic, tell us?Notes:\n- \\(O_i\\) observed frequencies always whole numbers.\n- \\(E_i\\) usually whole numbers.\n- Rounding errors can accumulate advisable use decimal places usual \\(X^2\\) calculations.\n- \\(\\chi^2\\) test always right tailed. add positive contributions critical threshold, reject \\(\\text{H}_0\\).","code":""},{"path":"goodness-of-fit-and-association.html","id":"prescribed-probabilities","chapter":"9 Goodness of fit and association","heading":"9.3.2 Prescribed probabilities","text":"tested digits random, used discrete uniform probabilities calculate expected numbers. However, can perform chi-squared test probabilities specified number categories.Example 9.4  experiments pea breeding Gregor Mendel (father modern genetic theory) obtained following data relating \\(556\\) pea plants.According Mendel’s theory, expected figures ratio \\(9:3:3:1\\).Test \\(10\\%\\) significance level whether theory contradicted.solution\\[\\text{H}_0: \\text{different types peas occur ratio 9:3:3:1}\\]\n\\[\\text{H}_A: \\text{different types peas occur ratio}\\]Calculate tableThere four classes one restriction \n\\[\\nu = 4-1=3\\]\ncritical value \\[\\chi^2_{3, \\ 90\\%} = 6.251\\]\ntable contributions :total \\(X^2 = 0.470\\)\\[0.47 < 6.251\\]\nInsufficient evidence reject \\(\\text{H}_0\\), data consistent \\(\\text{H}_0\\). Therefore can conclude observed frequencies consistent ratio given genetic theory. calculated value \\(X^2\\) small indeed, suggesting little discrepancy.already seen labs can hypothesis tests easily R. can \\(\\chi^2\\) test R using command \\(\\texttt{chisq.test()}\\)result obtained previously. Recall reject p-value lower significance level. Note p-value (much) larger \\(5\\%\\), evidence null hypothesis.","code":"\npeas <- c(315, 101,108,32)\n\nchisq.test(peas, p=c(9/16,3/16,3/16,1/16))## \n##  Chi-squared test for given probabilities\n## \n## data:  peas\n## X-squared = 0.47002, df = 3, p-value = 0.9254"},{"path":"goodness-of-fit-and-association.html","id":"small-expected-values","chapter":"9 Goodness of fit and association","heading":"9.3.3 Small expected values","text":"distribution test statistic \\(X^2\\) discrete numbers table appear finite number ways constrained sum.Example 9.5  many ways can sum three whole numbers \\(n_1,n_2,n_3\\) whose sum \\(5\\)?solution\n\\((1,1,3)\\) \\(3\\) possible orders\n\\((1,2,2)\\) \\(3\\) possible orders\nAltogether \\(6\\) ways can happen.\\(\\chi^2\\) distribution continuous, approximation becomes less less accurate expected frequencies become smaller. rule often stated deciding whether approximation valid expected frequencies must greater equal 5. original chosen categories lead expected numbers less \\(5\\), necessary combine categories together. numerical data adjacent categories combined way.Example 9.6  test random number generator provided studying lengths ‘runs’ digits.Work probability run length \\(k\\) (.e. random particular digit followed exactly \\(k-1\\) digits ).Work probability run length \\(k\\) (.e. random particular digit followed exactly \\(k-1\\) digits ).\\(X\\) random variable equal length run, distribution \\(X\\) follow?\\(X\\) random variable equal length run, distribution \\(X\\) follow?sequence supposedly random numbers generated following table obtained:sequence supposedly random numbers generated following table obtained:Use \\(10\\%\\) significance level test whether results suggest anything wrong random number generator.solutionA run length \\(k\\), given digit must must followed \\(k-1\\) digits probability \\(0.1\\). final digit different previous \\(k\\), probability \\(0.9\\). Altogether\n\\[ \\text{P}(X=k) = 0.9\\times 0.1^{k-1}\\]run length \\(k\\), given digit must must followed \\(k-1\\) digits probability \\(0.1\\). final digit different previous \\(k\\), probability \\(0.9\\). Altogether\n\\[ \\text{P}(X=k) = 0.9\\times 0.1^{k-1}\\]geometric distribution success probability \\(0.1\\).geometric distribution success probability \\(0.1\\).need work probability category table first.need work probability category table first.\\[\\text{P}(X=1) = 0.9\\]\n\\[\\text{P}(X=2) = 0.9\\times0.1 = 0.09 \\]\n\\[\\text{P}(X=3) = 0.009\\]\n\\[\\text{P}(X=4) = 0.0009\\]\n\\[\\text{P}(X=5) = 0.00009\\]\n\\[\\text{P}(X\\geq 6) = 1- (0.9+0.09+0.009+0.0009+0.00009) = 1\\times10^{-5}\\]\ntotal frequency \\(8993\\). work expected multiply probability total frequency.last three categories must combined :Now use number categories combining \\(4\\), \\(\\nu = 4-1=3\\) use critical value\n\\[\\chi^2_{3 , \\ 90\\%}= 6.251\\]\ntable contributions :total \\(X^2 = 0.864\\)Comparison: \\(0.864\\ngtr 6.251\\).significant evidence rejecting null hypothesis .","code":""},{"path":"goodness-of-fit-and-association.html","id":"goodness-of-fit-tests-to-discrete-distributions","chapter":"9 Goodness of fit and association","heading":"9.3.4 Goodness of fit tests to discrete distributions","text":"already seen can test data fits distribution outcomes equally likely, discrete uniform distribution, data fits distribution outcomes likely others according mass function. test named distributions earlier sections.estimate parameter distribution constraint data, general subtract one degree freedom parameter estimate. estimate parameter, one less number categories (possibly combining expected less \\(5\\)).Example 9.7  Eggs packed boxes \\(6\\). arrival supermarket pack inspected robot lasers make sure eggs broken. robot records number broken eggs pack. examining \\(5000\\) egg packets data tabulated follows:Let \\(X\\) number broken eggs box. Explain may suitable model \\(X\\) binomial distribution.Let \\(X\\) number broken eggs box. Explain may suitable model \\(X\\) binomial distribution.Test whether results consistent data modelled binomial distribution \\(\\text{Bin}(6,p)\\) \\(p\\) estimated data.Test whether results consistent data modelled binomial distribution \\(\\text{Bin}(6,p)\\) \\(p\\) estimated data.solutionPINTPINTThe hypotheses \n\\[\\text{H}_0: \\text{Bin}(6,p) \\text{ good fit}\\]\n\\[\\text{H}_A: \\text{Bin}(6,p) \\text{ good fit}\\]hypotheses \n\\[\\text{H}_0: \\text{Bin}(6,p) \\text{ good fit}\\]\n\\[\\text{H}_A: \\text{Bin}(6,p) \\text{ good fit}\\]can estimate probability single egg broken two ways. One way note \\(5000\\times 6 = 30000\\) eggs \\(322\\) recorded broken, hence \\[\\hat{\\pi}=322/30000=0.01703\\ldots\\]Another way use null hypothesis, mean Binomial distribution \\(n\\pi = 6p\\) hand mean table \\(\\bar{x}= 0.0644\\), equating two gives:\\[6p=0.0644\\]\ngives answer. parameter \\(p\\) can evaluate \\(\\text{P}(X=0),\\text{P}(X=1)\\ldots ,\\text{P}(X=6)\\) using pmf binomial distribution.\\(X^2\\) calculations proceed usual. case last five categories combine ‘2 ’.Giving \\(X^2 = 28.841\\).\ncombining \\(3\\) categories. also estimated one parameter.degrees freedom \\(\\nu = 3-1-1 = 1\\).critical value \\(\\chi^2_1\\) distribution. can seen tables p-value less \\(0.1\\%\\). reject \\(H_0\\) conclude binomial distribution good fit data.contributions \\(X^2\\) statistic, can elaborate ?far expected packs containing two broken eggs, likely egg breakages independent, may caused whole packs dropped accidents.Example 9.8  analysis number goals scored local football team last \\(100\\) matches gave following results:State assumptions modelling data Poisson distributionState assumptions modelling data Poisson distributionCarry \\(\\chi^2\\) goodness fit test \\(10\\%\\) significance level determine whether distribution can reasonably modelled Poisson distribution parameter \\(2\\).Carry \\(\\chi^2\\) goodness fit test \\(10\\%\\) significance level determine whether distribution can reasonably modelled Poisson distribution parameter \\(2\\).SIR,MRSIR,MRIf \\(X\\) number goals scored match:\\[\\text{H}_0: \\text{Pois(2)} \\text{ good fit}\\]\n\\[\\text{H}_A: \\text{Pois(2)} \\text{ good fit}\\]\ncalculate probabilities \\(\\text{P}(X=x)\\) \\(x=0,1,2,\\ldots\\) can use PD function .Poisson distribution theoretical maximum number goals, even though \\(7\\) observed largest number, must account uncertainty tail distribution. Hence last one use CDF function calculate \\(\\text{P}(X\\geq 7)\\) (know use CDF \\(1-\\text{P}(X\\leq 6)\\)).table follows:must combine last three categories ‘\\(5\\) ’. revised table observed expected :Finding sum gives \\(X^2 = 9.529\\)\\(6\\) classes combining, degrees freedom \\(\\nu = 6-1 =5\\). critical value therefore \\(\\chi^2_{5, \\ 90\\%} = 9.236\\).\\(X^2 = 9.529 > 9.236\\), reject null hypothesis. conclude number goals per match modelled Poisson distribution parameter \\(2\\).far ? improve model?Example 9.9  Can data previous example modelled Poisson distrubtion appropriate parameter?Recall Poisson distribution mean equal rate parameter. \\(X\\sim \\text{Pois}(\\lambda)\\) \\(\\text{E}(X)=\\lambda\\). estimate mean \\(\\bar{x} = 2.3\\) table (can found putting original table calculator).\\[\\text{H}_0: \\text{Pois(2.3)} \\text{ good fit}\\]\n\\[\\text{H}_A: \\text{Pois(2.3)} \\text{ good fit}\\]\ntable probabilities expected values becomes:can combine last three classes, proceed calculate \\(X^2\\)sum \\(X^2 = 4.208\\).number classes combining \\(6\\) estimated \\(1\\) parameter number degrees freedom \\(\\nu=6-1-1 = 4\\).","code":""},{"path":"goodness-of-fit-and-association.html","id":"goodness-of-fit-tests-to-continuous-distributions","chapter":"9 Goodness of fit and association","heading":"9.3.5 Goodness of fit tests to continuous distributions","text":"chi-squared test uses counts, data must grouped order chi-squared test continuous distributions,.e. count many data items lie inside given interval. , loss accuracy, another course may learn better tests show data follow particular distribution.Suppose data like test data follows normal distribution. order summarise data need group somehow, example histogram counts number data values lie within interval. number steps follow:Calculate (estimate grouped data) sample mean \\(\\bar{x}\\) standard deviation \\(s_x\\) data. become estimated parameters normal distribution.Calculate (estimate grouped data) sample mean \\(\\bar{x}\\) standard deviation \\(s_x\\) data. become estimated parameters normal distribution.Standardise endpoints intervals.Standardise endpoints intervals.Evaluate probability lying within standardised intervals using ZEvaluate probability lying within standardised intervals using ZCalculate expected values multiplying total frequency probability lying within interval.Calculate expected values multiplying total frequency probability lying within interval.Perform chi-squared test valuesPerform chi-squared test valuesEnsure subtract 2 degrees freedom estimated two parameters normal distribution.Ensure subtract 2 degrees freedom estimated two parameters normal distribution.example R.Example 9.10  Recall body temperature data labs, recorded body temperature \\(223\\) individuals degrees Farenheit. Test \\(5\\%\\) level whether data can modelled suitable normal distribution.first calculate sample mean standard deviation hypothesise distribution.hypotheses \\[\\text{H}_0: \\text{N}(98.2,0.527^2) \\text{ good fit}, \\ \\ \\ \\ \\ \\text{H}_A: \\text{N}(98.2,0.527^2) \\text{ good fit}\\]intervals yet, can make getting R draw histogram. set intervals, use ones R gives us.can summarise histogram table:Now table distribution body temperatures question. want compare normal distribution, one way standardise intervals work areas standard normal standardised endpoints.However intervals either end must also account tail probabilities (just data ended , mean smaller larger value observed another sample, affects expected calculation).get following table probabilities:work expected numbers multiplying total frequency:combine categories expected less \\(5\\). may ‘manually’:Now redraw combined table observed numbers calculate test statistic \\(X^2\\).can calculation using vectors R. may also find using spreadsheet helps.\\(5\\) categories combining, estimated \\(2\\) parameters, degrees freedom given \\(\\nu = 5-1-2=2\\).\ncritical value \\(5.991465\\). test statistic value 3.071697, reject \\(\\text{H}_0\\) conclude data consistent \\(\\text{N}(98.2,0.527^2)\\) distribution.Note combine categories probability vector R can test quickly :good check test statistic, however R know combined categories df incorrect p-value.","code":"\ndata <- read.csv(\"Bodytemp.csv\")\n\nxbar <- mean(data$Body_temp)\nxbar## [1] 98.16502\nsx <- sd(data$Body_temp)\nsx## [1] 0.5273048\ndata <- read.csv(\"Bodytemp.csv\")\n\nh <- hist(data$Body_temp, \n          main = \"Histogram of human body temperatures\",\n          xlab = \"Temperature (°F)\")\n# These are the endpoints of the intervals\nh$breaks## [1]  96.5  97.0  97.5  98.0  98.5  99.0  99.5 100.0\n# These are the observed frequencies\nh$counts ## [1]  5 23 64 80 43  7  1\n#standardising the endpoints\nst_breaks <- (h$breaks - xbar)/sx\n\n# creating a vector to store the probabilities in\nprobs <- vector(length = length(st_breaks)-1)\n\n# A loop to calculate the probability between endpoints\nfor (i in 1:length(probs)){\nprobs[i] <- pnorm(st_breaks[i+1])-pnorm(st_breaks[i])\n}\n\n\n#changing the end probabilities to account for the tails\n#see comment below\nprobs[1] <- probs[1] + pnorm(st_breaks[1])\nprobs[length(probs)] <-  1 - pnorm(st_breaks[length(probs)])\n\nprobs## [1] 0.013573730 0.090049579 0.273534295 0.360214167 0.205972393 0.050980284\n## [7] 0.005675552\nE <- probs*sum(h$counts)\nE## [1]  3.026942 20.081056 60.998148 80.327759 45.931844 11.368603  1.265648\nE[2] <- E[1]+E[2] #combine 1st and 2nd expected no.s\n\nE[6] <- E[7]+E[6] #combine 6th and last expected no.s\n\n#Overwrite our E vector\nE <- E[-c(1,7)] #get rid of 1st & last entries\nE## [1] 23.10800 60.99815 80.32776 45.93184 12.63425\n# Do the same for the observed frequencies:\nO <- h$counts\n\n#same combining as for expected categories\nO[2] <- O[1]+O[2] #combine 1st and 2nd expected no.s\n\nO[6] <- O[7]+O[6] #combine 6th and last expected no.s\n\n#Overwrite our E vector\nO <- O[-c(1,7)] #get rid of 1st & last entries\nO## [1] 28 64 80 43  8\nX_sq <- sum((O-E)^2/E) \nX_sq## [1] 3.071697\nqchisq(0.95,df =2)## [1] 5.991465\n#same combining as for probability categories\nprobs[2] <- probs[1]+probs[2] #combine 1st and 2nd expected no.s\n\nprobs[6] <- probs[7]+probs[6] #combine 6th and last expected no.s\n\n#Overwrite our E vector\nprobs <- probs[-c(1,7)] #get rid of 1st & last entries\nprobs## [1] 0.10362331 0.27353429 0.36021417 0.20597239 0.05665584\nchisq.test(x = O, p = probs)## \n##  Chi-squared test for given probabilities\n## \n## data:  O\n## X-squared = 3.0717, df = 4, p-value = 0.5459"},{"path":"goodness-of-fit-and-association.html","id":"explanation-of-statistic-x2-non-examinable","chapter":"9 Goodness of fit and association","heading":"9.4 Explanation of Statistic \\(X^2\\) (non-examinable)","text":"section aims give intuition question: statistic \\(X^2 = \\sum_{=1}^m \\frac{(O_i-E_i)^2}{E_i}\\) \\(\\chi^2\\) distribution?Suppose simplest case just two outcomes observe rather many binomial distribution \\(Y_1 \\sim \\text{Bin}(n,\\pi_1)\\) \\(Y_2 = n - Y_1\\). Also \\(\\pi_2 = 1-\\pi_1\\).observed numbers two outcomes \\(Y_1\\) \\(Y_2\\), expected numbers \\(n\\pi_1\\) \\(n\\pi_2\\). consider quantity:\\[X^2 = \\frac{(Y_1-n\\pi_1)^2}{n\\pi_1} + \\frac{(Y_2-n\\pi_2)^2}{n\\pi_2}\\]\nUsing \\(Y_2 = n - Y_1\\) \\(\\pi_2 = 1-\\pi_1\\) gives:\\[= \\frac{(Y_1-n\\pi_1)^2}{n\\pi_1} + \\frac{(n-Y_1-n(1-\\pi_1))^2}{n(1-\\pi_1)}\\]\\[=\\frac{(Y_1-n\\pi_1)^2}{n\\pi_1} + \\frac{(Y_1-n\\pi_1)^2}{n(1-\\pi_1)}\\]\nCollecting single fraction:\n\\[=\\frac{(Y_1-n\\pi_1)^2(1-\\pi_1)+(Y_1-n\\pi_1)^2\\pi_1}{n\\pi_1(1-\\pi_1)}\\]\n\\[=\\frac{(Y_1-n\\pi_1)^2}{n\\pi_1(1-\\pi_1)}\\]\nNow \\[X^2 = \\left( \\frac{Y_1 - n\\pi_1}{\\sqrt{n\\pi_1(1-\\pi_1)}}\\right)^2\\]\nRecall binomial distribution mean \\(n\\pi\\) variance \\(n\\pi(1-\\pi)\\). means inside brackets standardised distribution - , subtracted mean divided standard deviation. Normal approximation binomial distribution, know approximately normal distribution, standardised \\(\\text{N}(0,1)\\).Also recall square standard normal \\(Z^2 \\sim \\chi^2_1\\). Therefore \\[X^2 = Z^2 \\sim \\chi^2_1\\]\ntwo outcomes statistic \\(X^2\\) followed \\(\\chi^2_1\\) distribution. distribution \\(k\\) categories, \\(k\\) outcomes, \\(X^2\\) follow \\(\\chi^2_{k-1}\\) distribution.","code":""},{"path":"goodness-of-fit-and-association.html","id":"summary-2","chapter":"9 Goodness of fit and association","heading":"9.5 Summary","text":"","code":""},{"path":"goodness-of-fit-and-association.html","id":"goodness-of-fit-tests","chapter":"9 Goodness of fit and association","heading":"9.5.1 Goodness of fit tests","text":"chi-squared test always right tailed testA chi-squared test always right tailed testThe null hypothesis always distribution good fitThe null hypothesis always distribution good fitWork expected numbers multiplying probability total frequency.Work expected numbers multiplying probability total frequency.\\[E = \\text{total}\\times \\text{P}(X=x)\\]combine categories expected numbers less \\(5\\).combine categories expected numbers less \\(5\\).number degrees freedom \\(\\nu = \\text{. categories combining} - 1\\)number degrees freedom \\(\\nu = \\text{. categories combining} - 1\\)estimate parameter need subtract one degrees freedom.estimate parameter need subtract one degrees freedom.\\[\\nu = \\text{. categories combining} - 1 - \\text{. parameters estimated}\\]","code":""},{"path":"goodness-of-fit-and-association.html","id":"contingency-tables","chapter":"9 Goodness of fit and association","heading":"9.5.2 Contingency tables","text":"null hypothesis association.null hypothesis association.degrees freedom one less number columns multiplied one less number rows, combining classes \\(E<5\\).\n\\[\\nu =  (c-1)(r-1)\\]degrees freedom one less number columns multiplied one less number rows, combining classes \\(E<5\\).\n\\[\\nu =  (c-1)(r-1)\\]work expected multiply row column totals divide grand total.work expected multiply row column totals divide grand total.","code":""},{"path":"goodness-of-fit-and-association.html","id":"exercises-week-9","chapter":"9 Goodness of fit and association","heading":"9.6 Exercises Week 9","text":"Exercise 9.1  tetrahedral die thrown \\(120\\) times number lands notedTest \\(5\\%\\) significance level whether die fair.Exercise 9.2  new Fly spray applied \\(50\\) samples five flies air-tight box, number living flies counted one hour. results :circumstances expect able model variable \\(X\\) binomial distribution?circumstances expect able model variable \\(X\\) binomial distribution?)mean Binomial distribution parameters \\(n\\) \\(p\\)?\nCalculate mean number living flies per sample.\n)mean Binomial distribution parameters \\(n\\) \\(p\\)?Calculate mean number living flies per sample.Calculate expected values perform \\(\\chi^2\\) test \\(5\\%\\) significance level.Calculate expected values perform \\(\\chi^2\\) test \\(5\\%\\) significance level.Exercise 9.3  group students performing experiment drop \\(20\\) drawing pins ground number landing pointing counted. experiment carried students \\(50\\) observations. results table:Calculate mean number landing point . Hence show estimate probability pin landing facing \\(0.35\\)Calculate mean number landing point . Hence show estimate probability pin landing facing \\(0.35\\)parameters appropriate binomial distribution data? Calculate probability exactly \\(8\\) landing point , hence work expected frequency.parameters appropriate binomial distribution data? Calculate probability exactly \\(8\\) landing point , hence work expected frequency.Calculate expected number times five fewer pins land point .Calculate expected number times five fewer pins land point .goodness fit test partially complete . grouping data appropriately, evaluate missing expected observed frequencies. Hence calculate value \\(X^2\\) data.goodness fit test partially complete . grouping data appropriately, evaluate missing expected observed frequencies. Hence calculate value \\(X^2\\) data.many degrees freedom test ? Carry test making findings clear.Exercise 9.4  local council record number children number households area. council calculates average number children per household \\(1.4\\). suggested number children per household may modelled Poisson distribution parameter \\(1.4\\). order test random sample \\(1000\\) households taken, giving following data.Calculate corresponding expected frequencies obtained Poisson distribution parameter \\(1.4\\).Calculate corresponding expected frequencies obtained Poisson distribution parameter \\(1.4\\).Carry \\(5\\%\\) significance test show proposed model accepted.Carry \\(5\\%\\) significance test show proposed model accepted.reference relevant figures, give reason context lack fit proposed model.reference relevant figures, give reason context lack fit proposed model.assumptions Poisson model may valid example?assumptions Poisson model may valid example?Exercise 9.5  number heavy rainstorms reported \\(330\\) weather stations US one-year period follows:Find expected frequencies rainstorms given Poisson distribution mean total observed data.Find expected frequencies rainstorms given Poisson distribution mean total observed data.Carry \\(\\chi^2\\) test adequacy Poisson distribution model data.Carry \\(\\chi^2\\) test adequacy Poisson distribution model data.Exercise 9.6  farmer’s cooperative decided test three new fertilisers , B C. allocated random \\(75\\) plots. yield crop classified high, medium low. results summarised :Test \\(5\\%\\) level significance whether evidence association brand fertiliser crop yield.Exercise 9.7  survey effectiveness three hospitals , B C treating particular illness revealed following:data reveal significant evidence differences effectiveness hospitals?","code":""},{"path":"linear-modelling-and-correlation.html","id":"linear-modelling-and-correlation","chapter":"10 Linear modelling and correlation","heading":"10 Linear modelling and correlation","text":"final week learning linear modelling via regression correlation. aims understand linear regression model identify response regressor variables, use model prediction potential limitations model. analyse residuals identify problems model viewpoint.Next understand concept correlation coefficient potential pitfalls use interpretation.","code":""},{"path":"linear-modelling-and-correlation.html","id":"linear-regression","chapter":"10 Linear modelling and correlation","heading":"10.1 Linear regression","text":"Regression concerned modelling relationship two () variables. concentrated principally developing methods single random variable, many data sets provide information several variables want study connections variables. concentrate quantitative variables \\(x\\) \\(y\\) observed pairs \\((x,y)\\).data may collected time. examples:However data may collected later time though link clear. study temporal aspect .cases variable \\(x\\) affects variable \\(y\\). cases may affected third unmeasured factor.Definition 10.1  variable \\(x\\) called explanatory independent variable. variable \\(y\\) called response dependent variable.Example 10.1  petrol consumption car related speed driven.Suggest likely average fuel consumption car travelling 42 mph.similar example fuel consumption weight car.another example political context.\nFigure 10.1: Regions lower percentage graduates higher proportion voting leave\nsimplest relationship consider \\(y\\) \\(x\\) straight line \\(y=+bx\\). points plotted often situation points lie exactly straight line.One needs account error observation.Definition 10.2  simple linear regression model equation\n\\[Y=+bX+\\varepsilon\\]\\(\\varepsilon\\) normally distributed random variable mean zero constant variance. ,\\[\\varepsilon \\sim \\text{N}(0,\\sigma^2)\\]\nparticular value \\(X=x_i\\) \\(Y = y_i\\), predict \\(+bx_i\\). Sometimes model summarised \\(\\text{E}(Y)=+bX\\).regression line line\n\\[y = +bx\\]fit model \\(y=+bx\\) points plotted \\(\\) \\(b\\) estimated eye. However subjective process. two independent variables becomes difficult fit eye, higher dimensions impossible . consider constrains line.Definition 10.3  Given observed datum \\((x_i,y_i)\\) fitted regression line \\(y=+bx\\), residual \\(r_i\\) difference observed value value predicted regression line. ,\\[r_i = y_i - (+bx_i)\\]Small residuals desirable. However, residuals can positive negative, depending whether point lies vertically regression line. Taken together, see minimising sum squared residuals achieve optimal linear model. , let\n\\[S = \\sum_{=1}^{n}r_i^2\\]\nregression line \\(y=+bx\\) minimises \\(S\\).\nFigure 10.2: Red residuals positive, blue residuals negative\nTheorem 10.1  Given \\(n\\) points \\((x_i,y_i)\\), \\(1\\leq \\leq n\\), regression line \\(y=+bx\\) \\[= \\bar{y}-b\\bar{x},\\]\n\\[b = \\frac{s_{xy}}{s_{xx}},\\]\n\n\\[s_{xx} = \\sum x_i^2 - \\frac{(\\sum x_i )^2}{n}\\]\n\n\\[s_{xy} = \\sum x_iy_i - \\frac{(\\sum x_i )(\\sum y_i )}{n} \\]proofConsider sum squared residuals\\[S = \\sum_{=1}^{n} r_i^2\\]\\(S=S(,b)\\) function \\(\\) \\(b\\).\\[S(,b)=\\sum_{=1}^{n} (y_i - (+bx_i))^2\\]\nExpanding gives\\[S(,b) = \\sum y_i^2 - 2a\\sum y_i - 2b\\sum x_i y_i + ^2n + 2ab\\sum x_i + b^2 \\sum x_i^2\\]Now can find minumum function (minimum sum squares) partially differentiating setting equal zero.\\[\\frac{\\partial S(,b)}{\\partial } =-2\\sum y_i+ 2an +2b\\sum x_i\\]\nSetting \\(\\frac{\\partial S(,b)}{\\partial }=0\\) implies,\\[0=-\\sum y_i+ +b\\sum x_i \\]\\[= \\frac{1}{n}\\left(\\sum y_i - b \\sum x_i\\right).\\]\nLikewise partially differentiating respect \\(b\\) gives:\n\\[ \\frac{\\partial S(,b)}{\\partial b} = -2\\sum x_i y_i+2a\\sum x_i + 2b\\sum x_i^2\\]\nsetting equal zero gives:\\[= -\\sum x_i y_i+\\sum x_i + b\\sum x_i^2 ,\\]\nimplies\\[b = \\frac{\\sum x_iy_i - \\sum x_i}{\\sum x_i^2}.\\]\nSubstituting result \\(\\) gives result.Example 10.2  Fit linear regression line following datasolutionThen\\[b = \\frac{\\sum xy - \\frac{\\sum x \\sum y}{n}}{\\sum x^2 - \\frac{(\\sum x)^2}{n}} \\]\n\\[=\\frac{158 - \\frac{17\\times32}{4}}{87 - \\frac{17^2}{4}} =1.4915\\]\\[= \\frac{1}{n}(\\sum y -b \\sum x) =\\frac{1}{4}(32 - 1.4915\\times 17) = 1.661\\]\nline \\[y = 1.66 + 1.49x\\]Example 10.3  car data example \\(10.1\\). \\(n=16\\) following:\n\\[\\sum x_i = 680 \\ , \\ \\sum x_i^2 = 29400\\]\n\\[\\sum y_i = 700.7 \\ , \\ \\sum y_i^2 = 30828.05\\]\nCalculate least squares estimates \\(\\) \\(b\\).answer\\[s_{xy} = 29518.5 - \\left(\\frac{680\\times700.7}{16}\\right) = -261.25\\]\n\\[s_{xx} = 29400 - \\left(\\frac{680^2}{16}\\right) = 500.00\\]\n\\[b = \\frac{s_{xy}}{s_{xx}} = \\frac{-261.25}{500.00}= -0.5225\\]\n\\[= \\bar{y}-b\\bar{x}=\\frac{1}{16}[700.7 - (0.5225\\times680)]= 66.0\\]\nHence line \n\\[y = 66.0 -0.5225x\\]\npredicted value \\(42\\)mph therefore\n\\[y = 66.0 -0.5225\\times 42 = 44.055\\approx 44\\]linear model can fitted R command \\(\\texttt{lm(formula = y}\\sim\\texttt{x)}\\).","code":"## Warning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\n## of ggplot2 3.3.4.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated."},{"path":"linear-modelling-and-correlation.html","id":"residual-analysis","chapter":"10 Linear modelling and correlation","heading":"10.2 Residual analysis","text":"residuals realisations modelled error term \\(\\varepsilon \\sim \\text{N}(0,\\sigma^2)\\). model appropriate expect residuals look approximately normal distribution. , small magnitude random. can investigated graphically.Example 10.4  residuals earlier example can plotted histogram, can plot quantile-quantile plot, series plots.\nFigure 10.3: Residuals plots fuel consumption vs weight car data\ngeneral, following may noted plots.quantile-quantile plot matches observed sample quantile quantiles theoretical normal distribution, good fit one expect straight line gradient \\(1\\).quantile-quantile plot matches observed sample quantile quantiles theoretical normal distribution, good fit one expect straight line gradient \\(1\\).Residuals series, consistent pattern time (.e. regular increase decrease) outliers.Residuals series, consistent pattern time (.e. regular increase decrease) outliers.histogram look unimodal symmetrical.histogram look unimodal symmetrical.residual fitted value scatter plot evident patterns.residual fitted value scatter plot evident patterns.Let’s see example work.Example 10.5  experiment using biological enzyme washing powder enzyme activity \\(y\\) measured different washing temperatures \\(x\\).data collected:new line fitted data?look residuals original line time see increasingly negative. suggests linear suitable model, non-linear model quadratic suitable. context may higher temperatures enzyme denatured increasingly less effective.","code":""},{"path":"linear-modelling-and-correlation.html","id":"analysis-of-variance","chapter":"10 Linear modelling and correlation","heading":"10.3 Analysis of Variance","text":"aim fitting regression model try explain variation response \\(Y\\) assuming generated linear model random error.\\[y= +bx+\\varepsilon\\]Anything left random variation. useful model explain significant proportion random variation. Thus,\\[\\text{Variation data} = \\text{ variation model} \\  + \\ \\text{unexplained variation}\\]\nlinear models variation measured sums squares (SS) follows:\\[SS_{T} =  SS_R + SS_E\\]\ntotal sum squares equals sum squares due regression add error sum squares.analysis usually set ANOVA table can used test significance slope parameter.\\[H_0 : b=0\\]\n:::{.definition}\n- total sum squares given \\[SS_T = \\sum (y-\\bar{y})^2= \\sum y^2 - \\frac{(\\sum y)^2}{n}\\]\n- regression sum squares given \\[SS_R = b^2\\sum(x-\\bar{x})^2 = b^2 \\left\\{ \\sum x^2 - \\frac{(\\sum x)^2}{n}\\right\\}\\]\n- error sum squares given \n\\[SS_E=SS_T-SS_R \\]\n:::Definition 10.4  regression Analysis Variance table written asThis given formula book. test \\(H_0 : b = 0\\), one compares ratio Mean sum squares (MS) F-distribution critical value. ,\\[F=\\frac{MS_R}{MS_E}\\sim F_{1,n-2} \\]Example 10.6  Sales major appliances vary new housing market. new home sales high, sales appliances dishwashers, washing machines, .Suppose calculated regression line \\(y=2.1549 + 1.3694x\\) summary statistics:\\[\\sum x = 18.6 \\ , \\ \\sum x^2 = 60.34\\]\n\\[\\sum y = 38.4 \\ , \\ \\sum y^2 = 251.38\\]\nCalculate ANOVA table test hypothesis \\(H_0 : b = 0\\).solutionWe round end need maintain accuracy compare critical value.\n\\[SS_T = 251.38 - \\frac{38.4^2}{6} = 5.62\\]\n\\[SS_R = (1.3694)^2 \\left( 60.34 - \\frac{18.6^2}{6} \\right) = 5.025\\ldots\\]\n\\[SS_E = SS_T - SS_R = 5.62 - 5.025\\ldots = 0.5943\\ldots \\]\\[MS_R = 5.02\\ldots /1 = 5.025 \\]\n\\[MS_E = 0.5843\\ldots / 4 = 0.1485\\ldots\\]can complete ANOVA table followsWe \\[F = \\frac{5.025687}{0.1485782}=33.825188\\]tables one can find \\(95^{\\text{th}}\\) percentile \\(F_{1,4}=7.71\\)Since \\(33.83 > 7.71\\) can reject \\(H_0\\).can evaluate tables manually, may required exam, can obtained statistical software , R. R ANOVA table can obtained combination commands \\(\\texttt{aov()}\\) \\(\\texttt{summary()}\\).Example 10.7  housing example can analysis R follows:","code":"\nx <- c(2.0,2.5,3.2,3.6,3.3,4.0)\ny <- c(5.0,5.5,6.0,7.0,7.2,7.7)\ndf <- as.data.frame(cbind(x,y))\n\naov(y~x,df) %>% summary()##             Df Sum Sq Mean Sq F value  Pr(>F)   \n## x            1  5.026   5.026   33.83 0.00435 **\n## Residuals    4  0.594   0.149                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"linear-modelling-and-correlation.html","id":"confidence-and-prediction-intervals","chapter":"10 Linear modelling and correlation","heading":"10.4 Confidence and prediction intervals","text":"section calculate two kinds intervals regression give range plausible values response \\(y\\). first confidence interval mean response \\(\\bar{Y}\\). second accounts variability \\(Y\\) called prediction interval.Definition 10.5  \\(100(1-\\alpha)\\%\\) confidence interval mean response particular regression point \\(x_0\\) given \\[+bx_0 \\pm t_{n-2}\\hat{\\sigma}\\sqrt{\\frac{1}{n}+ \\frac{(x_0-\\bar{x})^2}{\\sum(x-\\bar{x})^2}}\\]\n\\(\\hat{\\sigma}=\\sqrt{MS_E}\\) ANOVA table.Example 10.8  Calculate \\(95\\%\\) confidence interval mean response \\(x_0 = 3.9\\) housing example .solution\\[t_{4,0.0025}=2.7764\\]\n\\[\\bar{x} = 18.6/6\\]\n\\[+bx_0 = 2.1549 + 1.3694 \\times 3.9 = 7.49556\\]\ninterval given \\[7.49556 \\pm 2.7764\\times0.3854584\\sqrt{\\frac{1}{6}+\\frac{(3.9 - 3.1)^2}{2.68}}\\]\n\\[(6.81,8.18)\\] (3 s.f.).Definition 10.6  \\(100(1-\\alpha)\\%\\) prediction interval response \\(y_0\\) particular regression point \\(x_0\\) given \\[+bx_0 \\pm t_{n-2}\\hat{\\sigma}\\sqrt{1+\\frac{1}{n}+ \\frac{(x_0-\\bar{x})^2}{\\sum(x-\\bar{x})^2}}\\]Note formula except extra \\(1\\) square root.Example 10.9  \\(95\\%\\) prediction interval appliance sales housing starts equals \\(3900\\) given \\[7.49556 \\pm 2.7764\\times0.3854584\\sqrt{1+\\frac{1}{6}+\\frac{(3.9 - 3.1)^2}{2.68}}\\]\n\\[=7.49556\\pm 1.2687344\\]\ngives \\((6.23,8.76)\\) (3 d.p.).Prediction intervals confidence intervals can calculated point \\(x_0\\).\nFigure 10.4: Confidence intervals appear grey, prediction intervals appear pink.\nNotice prediction intervals generally wider confidence intervals. derive formulas, though expected know use , appear formula book.Note also width intervals increases near ends available data, suggesting uncertainty extremes. Notice fuel consumption never go zero, extrapolation data based model unreliable weights say \\(6000\\) lbs.","code":""},{"path":"linear-modelling-and-correlation.html","id":"pmcc","chapter":"10 Linear modelling and correlation","heading":"10.5 PMCC","text":"correlation coefficient measure strength (linear) relationship two variables.denote population correlation coefficient Greek letter r - \\(\\rho\\), sample correlation coefficient \\(r\\).Pearson product moment correlation coefficient (PMCC) closely related gradient simple linear regression line.Definition 10.7  Given \\(n\\) observations \\((x_i,y_i)\\) \\(1\\leq \\leq n\\), ****Pearson product moment correlation coefficient (PMCC)**** given \\[r = \\frac{s_{xy}}{\\sqrt{s_{xx}s_{yy}}}\\]\n\\[=\\frac{\\sum xy - n\\bar{x}\\bar{y}}{\\sqrt{(\\sum x^2 - n\\bar{x}^2)(\\sum y^2 - n\\bar{y}^2)}} \\]sign correlation determined numerator expression. denominator ensures coefficient always lies extremes \\(-1\\) \\(1\\). observations lie straight line PMCC equals \\(\\pm 1\\). real data, extremely unlikely due experimental error.Example 10.10  following data shows age \\(x\\) (years) second-hand price \\(y\\) (hundreds pounds) sample \\(11\\) cars advertised online.Calculate PMCC data interpret context.solutionOne can use formula another calculation method, find \\(r = -0.957\\). indicates strong negative correlation age value car. context means cars less old worth older cars worth less (worthless).","code":""},{"path":"linear-modelling-and-correlation.html","id":"pitfalls","chapter":"10 Linear modelling and correlation","heading":"10.5.1 Pitfalls","text":"Correlation imply causation. Even causal relationship exists, may reverse due third unrelated unmeasured factor. Ice cream sales deaths open water correlated - ? Tree movement rate wind speed causally related, response? seriously, issue appears often media (mis)reporting findings medical studies.Correlation imply causation. Even causal relationship exists, may reverse due third unrelated unmeasured factor. Ice cream sales deaths open water correlated - ? Tree movement rate wind speed causally related, response? seriously, issue appears often media (mis)reporting findings medical studies.Correlation measures linear relationships. Variables may perfectly related non-linear fashion e.g. exponential decay quadratic curve, zero linear correlation coefficient.Correlation measures linear relationships. Variables may perfectly related non-linear fashion e.g. exponential decay quadratic curve, zero linear correlation coefficient.Correlations may hidden exaggerated due clusters data behave distinctive ways. plot beak length birds may different trends different species.Correlations may hidden exaggerated due clusters data behave distinctive ways. plot beak length birds may different trends different species.correlation coefficient equal gradient regression line.correlation coefficient equal gradient regression line.","code":""},{"path":"linear-modelling-and-correlation.html","id":"hypothesis-tests-for-correlation","chapter":"10 Linear modelling and correlation","heading":"10.6 Hypothesis tests for correlation","text":"easy say correlation coefficient close \\(1\\) \\(-1\\) strong correlation - \\(r=0.6\\)? point say correlation, based number alone?answer can conduct hypothesis test, using \\(r\\) statistic. can test hypotheses:\\[\\text{H}_0 : \\rho = 0, \\ \\  \\ \\  \\text{H}_1: \\rho \\neq 0\\]\nsample correlation coefficient \\(r\\), absolute value, exceeds critical value tables, may reject null hypothesis.Example 10.11  following data refer average temperature (degrees Farenheit) average butterfat content herd cows (expressed percentage milk).Test \\(5\\%\\) significance level whether evidence correlation two variables.solutionOne calculates \\(r=-0.453\\).degrees freedom equal \\(n-2 = 18\\).Comparing tables level \\(5\\% /2 = 0.025\\) gives \\(0.444\\).Therefore \\(|r| = 0.453 > 0.444\\) can reject \\(H_0\\) conclude weakly negative correlation.Notes.Hypothesis testing PMCC assumes data random sample normal marginals \\(x\\) \\(y\\). data random sample normal population, analysis appropriate.Hypothesis testing PMCC assumes data random sample normal marginals \\(x\\) \\(y\\). data random sample normal population, analysis appropriate.circumstances wemay wish test one-sided alternative. correlation strictly positive negative. situation one look \\(5\\%\\) value rather \\(2.5\\%\\) value.circumstances wemay wish test one-sided alternative. correlation strictly positive negative. situation one look \\(5\\%\\) value rather \\(2.5\\%\\) value.","code":""},{"path":"linear-modelling-and-correlation.html","id":"summary-3","chapter":"10 Linear modelling and correlation","heading":"10.7 Summary","text":"linear model equation\\[y = +bx +\\varepsilon\\]formulas \\(\\) \\(b\\):\n\\[= \\bar{y}-b\\bar{x},\\]\\[b = \\frac{s_{xy}}{s_{xx}}\\]\n- Residuals difference point regression line. useful graphs can tell model good fit linear model.test significance coefficient \\(b\\) done via ANOVA F-test. table appears formula booklet.test significance coefficient \\(b\\) done via ANOVA F-test. table appears formula booklet.Confidence prediction intervals can calculated quantify uncertainty predicted value response.Confidence prediction intervals can calculated quantify uncertainty predicted value response.Sample correlation can calculated via\n\\[r = \\frac{s_{xy}}{\\sqrt{s_{xx}s_{yy}}}\\]Sample correlation can calculated via\n\\[r = \\frac{s_{xy}}{\\sqrt{s_{xx}s_{yy}}}\\]hypothesis test detect correlation .hypothesis test detect correlation .","code":""},{"path":"linear-modelling-and-correlation.html","id":"exercises-week-10","chapter":"10 Linear modelling and correlation","heading":"10.8 Exercises week 10","text":"Exercise 10.1  Eight pairs observations variables \\(x\\) \\(y\\) given .Calculate \\(\\sum x\\), \\(\\sum x^2\\), \\(\\sum y\\), \\(\\sum y^2\\), \\(\\sum xy\\).Calculate \\(\\sum x\\), \\(\\sum x^2\\), \\(\\sum y\\), \\(\\sum y^2\\), \\(\\sum xy\\).Find \\(\\bar{x}\\), \\(\\bar{y}\\), \\(s_{xx}\\), \\(s_{yy}\\) \\(s_{xy}\\)Find \\(\\bar{x}\\), \\(\\bar{y}\\), \\(s_{xx}\\), \\(s_{yy}\\) \\(s_{xy}\\)Find values \\(\\) \\(b\\) regression line \\(y=+bx\\).Find values \\(\\) \\(b\\) regression line \\(y=+bx\\).Exercise 10.2  Six pairs observations variables \\(x\\) \\(y\\) given .Calculate \\(\\sum x\\), \\(\\sum x^2\\), \\(\\sum y\\), \\(\\sum y^2\\), \\(\\sum xy\\).Calculate \\(\\sum x\\), \\(\\sum x^2\\), \\(\\sum y\\), \\(\\sum y^2\\), \\(\\sum xy\\).Find \\(\\bar{x}\\), \\(\\bar{y}\\).Find \\(\\bar{x}\\), \\(\\bar{y}\\).Find values \\(\\) \\(b\\) regression line \\(y=+bx\\).Find values \\(\\) \\(b\\) regression line \\(y=+bx\\).Exercise 10.3  Five pairs observations variables \\(x\\) \\(y\\) given .Calculate \\(\\sum x\\), \\(\\sum x^2\\), \\(\\sum y\\), \\(\\sum y^2\\), \\(\\sum xy\\).Calculate \\(\\sum x\\), \\(\\sum x^2\\), \\(\\sum y\\), \\(\\sum y^2\\), \\(\\sum xy\\).Find \\(\\bar{x}\\), \\(\\bar{y}\\).Find \\(\\bar{x}\\), \\(\\bar{y}\\).Find values \\(\\) \\(b\\) regression line \\(y=+bx\\).Find values \\(\\) \\(b\\) regression line \\(y=+bx\\).Estimate value \\(y\\) \\(x=0.0572\\).Estimate value \\(y\\) \\(x=0.0572\\).Exercise 10.4  car isdriven specified conditionsofload, tyre pressure surrounding temperature, temperature \\(T^{o}C\\), generated shoulder tyre varieswith speed \\(V \\ \\text{km}/\\text{h}\\), according linear model \\(T=+bV\\). Measurements \\(T\\) made eight different values \\(V\\) following results.Given following\\[\\sum v = 440, \\ \\sum v^2 = 28400, \\ \\sum t =606, \\ \\sum t^2 = 49278, \\ \\sum vt = 37000 \\]Calculate estimated regression line \\(T\\) \\(V\\).Calculate estimated regression line \\(T\\) \\(V\\).Estimate value \\(T\\) \\(V=60\\).Estimate value \\(T\\) \\(V=60\\).Calculate ANOVA table data.Calculate ANOVA table data.Test hypothesis \\(\\text{H}_0: b=0\\).Test hypothesis \\(\\text{H}_0: b=0\\).Exercise 10.5  anemometer used estimate wind speed observing rotational speed vanes. speed converted wind speed means equation obtained calibrating instrument wind tunnel. calibration wind speed fixed precisely resulting anemometer seed noted. particular anemometer process produced following set data.Obtain least squares regression line dataObtain least squares regression line dataCalculate ANOVA table dataCalculate ANOVA table dataTest hypothesis \\(\\text{H}_0: b=0\\).Test hypothesis \\(\\text{H}_0: b=0\\).Calculate \\(95\\%\\) prediction interval actual wind speed \\(1.65 m/s\\)Calculate \\(95\\%\\) prediction interval actual wind speed \\(1.65 m/s\\)Give example using relevant calculation regression line, unwise extrapolate outside range data.Give example using relevant calculation regression line, unwise extrapolate outside range data.Exercise 10.6  hospital doctor interested percentage certain drug absorbed patients. obtained following data \\(10\\) patients taking drug two separate days.Calculate product moment correlation coefficient \\(r\\) data.Calculate product moment correlation coefficient \\(r\\) data.Test \\(5\\%\\) significance level whether correlation. \\(H_0:\\rho = 0\\).Test \\(5\\%\\) significance level whether correlation. \\(H_0:\\rho = 0\\).examining plot data, doctor found one points surprising. result anomaly excluded analysis. \\(r\\) value remaining \\(9\\) points \\(0.863\\). point omitted?examining plot data, doctor found one points surprising. result anomaly excluded analysis. \\(r\\) value remaining \\(9\\) points \\(0.863\\). point omitted?","code":""}]
