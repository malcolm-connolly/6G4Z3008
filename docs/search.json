[{"path":"index.html","id":"intro","chapter":"1 Introduction to Probability","heading":"1 Introduction to Probability","text":"things happen entirely predictable. example, one drops ball height, know hit ground. Things happen like can decribed deterministic. may heard people talk things written stars, fate, destiny. opinion things pre-determined called determinism.However, even determinist, live uncertainty. everyday lives can think examples things happen predict; bus may late, may rain, one might win lottery. one living uncertainty, reasonable quantify uncertainty act assuming outcomes pre-determined. outcome pre-determined called random.Mathematics random phenomena called Probability Theory. people intuitive idea meant probability chance. Unfortunately Probability Theory subject endless examples seemingly simple questions turn complicated severely counter-intuitive answers.","code":""},{"path":"index.html","id":"frequentist-perspective","chapter":"1 Introduction to Probability","heading":"1.1 Frequentist perspective","text":"need start terminology.Definition 1.1  experiment procedure happens random least two different outcomes. example rolling die observing score statistical experiment. experiment repeatable repetition called run.calculating number times event occurs divided number runs one can estimate theoretical probability. idea relative cumulative frequency outcomes tend actual probability long run. perspective probability called Frequentist, incredibly useful practice.\nFigure 1.1: result simulating rolling die 6000 times, counting many times 6 occures. cumulative relative frequency tends theoretical 1/6 (red).\nrecreate plot like labs.Example 1.1  Suppose toss \\(10\\) coins \\(10\\) times results recorded table , draw graph relative frequency.cumulative relative frequencies calculated cumulative number flips divided cumulative number heads:course learn R programming. R free open-source software language suitable many probability statistical calculations. following R code make list two outcomes Heads Tails create sample \\(10\\) random outcomes.Definition 1.2  statistical experiment \\(n\\) runs, outcome \\(\\) happens cumulative number times depending \\(n\\) can call \\(a_n\\), frequentist probability outcome \\(\\), written \\(P()\\), limit:\\[P() = \\lim_{n\\\\infty} \\frac{a_n}{n}\\]possible repeatedly run experiment, frequentist methods useful finding approximation true theoretical probability.simple, consider following questions. probability life planets? probability Conservatives win next general election?events like flipping coin, possible find frequentist interpretation probability.","code":"\noutcomes <- c(\"Heads\",\"Tails\")\nsample(outcomes, 10, replace=TRUE)##  [1] \"Heads\" \"Tails\" \"Tails\" \"Tails\" \"Heads\" \"Tails\" \"Tails\" \"Tails\" \"Tails\"\n## [10] \"Heads\""},{"path":"index.html","id":"naive-probability","chapter":"1 Introduction to Probability","heading":"1.2 Naive probability","text":"may time resources many thousands runs. Therefore also need able evaluate theoretical probability directly exactly.Definition 1.3  sample space set whose elements outcomes experiment. sample space denoted greek letter \\(\\Omega\\).Example 1.2  pick person random street ask month birthday,\ncan let\n\\[\\Omega = \\{\\text{Jan}, \\ \\text{Feb}, \\ \\text{Mar},  \\ \\text{Apr}, \\ \\text{May}, \\ \\text{Jun}, \\ \\text{Jul}, \\ \\text{Aug}, \\ \\text{Sep}, \\ \\text{Oct}, \\ \\text{Nov}, \\ \\text{Dec} \\}.\\]Definition 1.4  event subset sample space \\(\\Omega\\).Example 1.3  example 1.2, let \\(\\text{L}\\) event month long month (.e. 31 days). \n\\[\\text{L} = \\{\\text{Jan}, \\ \\text{Mar}, \\ \\text{May},  \\ \\text{Jul}, \\ \\text{Aug},  \\ \\text{Oct}, \\ \\text{Dec} \\}.\\]Let \\(R\\) event letter r name month written fully. ,\\[\\text{R} = \\{\\text{Jan}, \\ \\text{Feb}, \\ \\text{Mar}, \\ \\text{Apr},  \\ \\text{Sep}, \\ \\text{Oct}, \\ \\text{Nov}, \\  \\text{Dec} \\}\\]Definition 1.5  Naively probability event \\(\\) number elements set \\(\\) divided size sample space \\(\\Omega\\).,\\(\\text{P} () = \\frac{||}{|\\Omega|}\\).example 1.3 :\\[\\text{P}(R) = \\frac{|R|}{|\\Omega|} = \\frac{8}{12} = \\frac{2}{3},\\],\\[\\text{P}(L) = \\frac{|L|}{|\\Omega|} =\\frac{7}{12}.\\]Example 1.4  (Coin Tossing) Toss fair coin twice record possible outcomes. Let\n\\[= \\{\\text{exactly one coin Heads}\\}\\]\n\n\\[B = \\{\\text{neither coin Heads}\\}\\]sample space \\(\\Omega = \\{HH, HT, TH, TT\\}\\).Events \\(\\) \\(B\\) correspond :\\[= \\{HT, TH\\}\\]\n\n\\[B = \\{ TT \\}\\]\nHence \\(\\text{P}() = \\frac{2}{4} = \\frac{1}{2}\\), \\(\\text{P}(B)=\\frac{1}{4}\\).Example 1.5  (Two dice) Two dice thrown, probability total number dots :equal \\(7\\)equal \\(3\\)greater \\(5\\)even numbersolutionThe sample space \\(\\Omega = \\{ (n_1,n_2) : n_1 , n_2 \\\\{1,2,3,4,5,6 \\} \\}\\). However, sums equally likely, best seen table.\\(\\frac{6}{36}\\)\\(\\frac{2}{36}\\)\\(\\frac{26}{36}\\)\\(\\frac{18}{36}\\)infinite sets problem naive definition 1.5. Consider following:Example 1.6  Suppose random unit vector rotated origin anticlockwise, making angle \\(\\theta\\) positive \\(x\\)-axis. probability angle acute?continuum infinitely many angles. naive definition says \\(\\frac{\\infty}{\\infty}\\), absurd.Intuitively, answer \\(\\frac{1}{4}\\).","code":""},{"path":"index.html","id":"complements-and-mutual-exclusivity","chapter":"1 Introduction to Probability","heading":"1.3 Complements and mutual exclusivity","text":"case, events subsets sample space \\(\\Omega\\) follow rules set theory, important know set notation, definitions results. recap important definitions.Definition 1.6  union \\(\\) \\(B\\) written:\\[\\cup B = \\{ x \\\\Omega :  x \\\\ \\text{} \\ x\\B \\}.\\]\nMathematics inclusive, means need say ``’’ included union.Definition 1.7  intersection \\(\\) \\(B\\) written:\n\\[\\cap B = \\{ x \\\\Omega:  x \\\\ \\text{} \\ x\\B \\}.\\]Definition 1.8  empty set \\(\\varnothing\\) set elements. sets \\(\\) \\(B\\) called disjoint elements common, ,\\(\\cap B = \\varnothing.\\)Probability Theory disjoint events called mutually exclusive.Definition 1.9  complement event \\(\\) event \\(^{c} = \\{x \\\\Omega : x\\notin \\}.\\)\nNote \\(\\cap ^{c} = \\varnothing\\). words means: event mutually exclusive complement.Example 1.7  Suppose event throwing die. event one throws even number. complement one throws odd number.Example 1.8  Suppose event random student siblings. complement one sibling. complement least one sibling.theorem prove De Morgan’s lawsTheorem 1.1  (DE MORGAN'S LAWS) complement union intersection complements:\n\\[(\\cup B)^{c} = ^{c} \\cap B^{c}\\]complement intersection union complements:\n\\[(\\cap B)^{c} = ^{c} \\cup B^{c}\\]way \\(P\\) `measure’ function maps subsets sample space interval \\(\\left[0,1\\right]\\).Definition 1.10  Probability function whose input subset sample space \\(\\subseteq \\Omega\\) whose range interval \\(\\left[0,1\\right]\\), following two axioms hold:probability whole set possible events unity. notation: \\(\\text{P}(\\Omega ) =1\\).probability whole set possible events unity. notation: \\(\\text{P}(\\Omega ) =1\\).(additivity) collection disjoint events \\(A_1 , A_2, A_3, \\dots\\) probability union sum probabilities. notation can written \\[\\text{P}(A_1 \\cup A_2 \\cup \\dots ) = \\text{P}(A_1) + \\text{P}(A_2)+\\dots .\\](additivity) collection disjoint events \\(A_1 , A_2, A_3, \\dots\\) probability union sum probabilities. notation can written \\[\\text{P}(A_1 \\cup A_2 \\cup \\dots ) = \\text{P}(A_1) + \\text{P}(A_2)+\\dots .\\]definition 1.10 due Russian Mathematician Kolmogorov. axioms help make sense infinite case.Using definition can prove following important results.Proposition 1.1  (PROBABILITY COMPLEMENT) event \\(\\) :\n\\[\\text{P}(^{c}) = 1 - \\text{P}().\\]Proof. Write \\(\\Omega = \\cup ^{c}\\), disjoint union. additivity,\n\\[\\text{P}(\\Omega) = \\text{P}() + \\text{P}(^{c}) \\]\nNow axiom () LHS \\(1\\).Theorem 1.2  (PROBABILITY UNION) Given two events \\(\\) \\(B\\) :\\[\\text{P}(\\cup B) = \\text{P}() + \\text{P}(B) - \\text{P}(\\cap B)\\]Proof. idea write \\(\\) disjoint union part intersection \\(B\\), : \\(=(\\cap B)\\cup(\\cap B^{c})\\). Hence,\\[\\text{P}() = \\text{P}(\\cap B) + \\text{P}(\\cap B^{c})\\]split \\(\\cup B\\) way, obtain \\((\\cup B)\\cap B\\) \\((\\cup B)\\cap B^{c}\\). former simply \\(B\\), latter \\(\\cap B^{c}\\). additivity,\\[\\text{P}(\\cup B) = P(B) + P(\\cap B^{c}).\\]\nEliminating \\(P(\\cap B^{c})\\) two equations proves rule.proving Theorems course, neither ask recount proof exam. however know use results applied problems.Example 1.9  (Multiple Choice) Suppose multiple choice test consists three questions two options, correct answer (C) wrong answer (W). probability student always randomly guesses answers gets least one correct?\\[\\begin{align}\n\\text{P(least one correct)} &= 1 - \\text{P(wrong)} \\\\\n&= 1- \\frac{1}{8}  \\\\\n&=\\frac{7}{8}\n\\end{align}\\]Example 1.10  (Mode travel) table shows type journey undertaken sample commuters classified live.individual selected random group, find probability , travel car live townsolution\\(\\text{P}(\\text{Car}\\cup \\text{Town}) = \\frac{25+40+30}{100}=0.95\\)\\(\\text{P}(\\text{Car})+ \\text{P}(\\text{Town})-\\text{P}(\\text{Car}\\cap \\text{Town})= \\frac{65}{100}+\\frac{70}{100}-\\frac{40}{100} =0.95\\)Example 1.11  particular city \\(60\\%\\) people watch news morning, \\(50\\%\\) people watch news evening \\(30\\%\\) watch . probability individual selected random watches either morning news evening news.solution\\(\\text{P}(M\\cup E) = 0.6 + 0.5 - 0.3 = 0.8\\)","code":""},{"path":"index.html","id":"outcomes-and-counting","chapter":"1 Introduction to Probability","heading":"1.4 Outcomes and counting","text":"One might imagine finite situation simple, even seen full picture. One simply counts many ways event can happen total number configurations. can actually quite complicated. learn formulae enable us count .","code":""},{"path":"index.html","id":"factorials","chapter":"1 Introduction to Probability","heading":"1.4.1 Factorials","text":"Example 1.12  (Three people line) many ways can three people \\(\\), \\(B\\) \\(C\\) stand line?solution\\(ABC, ACB, BAC, BCA, CAB,CBA\\) \\(6\\).Definition 1.11  non-negative integer, \\(n\\) say, define factorial \\(n\\), written \\(n!\\) equal product \\(n\\) numbers less \\(n\\) \\(1\\). ,\\[n! = n \\times (n-1) \\times (n-2) \\times \\dots 3 \\times 2 \\times 1\\]Definition 1.12  (Multiplication Rule) \\(n\\) ways operation happen, \\(m\\) ways something else happen, total number ways sequence occur \\(n \\times m\\).Example 1.13  MMU assigns student \\(8\\) digit ID number. many possible ID numbers ?solution\nfirst digit zero, \\(9\\) digits choose.\ndigits \\(10\\) choices \\(0,1,2,3,4,5,6,7,8,9\\).Total = \\(9 \\times 10^7\\).Example 1.14  (objects line) number ways arranging \\(n\\) distinct objects line \\(n!\\).\n\\(n\\) choices first number line, one fewer choice \\((n-1)\\) second, , last one line one choice remaining.Definition 1.13  (rule division) number ways arranging \\(n\\) objects line \\(p\\) \\(\\frac{n!}{p!}\\).Example 1.15  Suppose letters \\(,,,B\\) - many `words’ can made?Suppose letters \\(,,,B\\) - many `words’ can made?Suppose letters \\(,,,B,B\\) - many `words’ can made?Suppose letters \\(,,,B,B\\) - many `words’ can made?solution\n)\nAAAB, AABA, ABAA, BAAAThere 4. find number without write ?might think \\(4!\\) thinking different, overcounts word. factor overcount? Take one words ABAA number , one finds rearrangements 1,2,3:\\(A_1BA_2A_3, A_1BA_3A_2, A_2BA_1A_3, A_2BA_3A_1, A_3BA_1A_2, A_3BA_2A_1.\\)upshot need divide factorial number letters , \\(\\frac{4!}{3!} =4\\).\\(3\\) letter \\(\\), \\(2\\) letter \\(B\\). correct number \\[\\frac{5!}{3!\\times2!} = 10\\]words AAABB, AABBA, ABBAA, BBAAA, BABAA, ABABA, AABAB, BAABA, ABAAB, BAAAB. (can systematically list considering number ’s B’s).Definition 1.14  (rule sum) Given two disjoint events \\(\\) \\(B\\), size union sum sizes \\(\\) \\(B\\). ,\\[|\\cup B|=||+|B|\\]Example 1.16  many possible MMU IDs start \\(1\\) \\(3\\)?solutionThe IDs form 1******* 3*******. 1 choice first digit \\(10^7\\) choices next digits either case.total number starting \\(1\\times 10^7 + 1\\times 10^7 = 2\\times 10^7.\\)","code":""},{"path":"index.html","id":"permutations","chapter":"1 Introduction to Probability","heading":"1.4.2 Permutations","text":"Example 1.17  Consider number ways placing three letters \\(,B,C,D,E,F G\\) three empty spaces. first space can filled \\(7\\) ways, second \\(6\\) ways last \\(5\\) ways.total \\(7\\times 6\\times 5 = 120\\)number can written \n\\[\\frac{7\\times 6 \\times 5\\times 4\\times 3\\times 2\\times 1}{4\\times 3 \\times 2\\times 1}=\\frac{7!}{(7-3)!}\\]Definition 1.15  (Permutations) number ways choosing \\(k\\) distinct items \\(n\\) order relevant \n\\[^n\\text{P}_k = \\frac{n!}{(n-k)!}\\]\nway choosing \\(k\\) distinct items \\(n\\) order matters called permutation.Example 1.18  PIN \\(4\\) different digits. many different PINs ?solutionOrder matters - guess 1234 different 4321, example.\\[^{10}\\text{P}_4 = \\frac{10!}{(10-4)!} = \\frac{10\\times 9 \\times \\dots 2 \\times 1 }{6!} =10\\times 9 \\times 8 \\times 7 =5040\\]\nexpression \\(10\\times 9 \\times 8 \\times 7\\) can interpreted saying \\(10\\) choices first digit, \\(9\\) second, .Example 1.19  (Birthday Problem) Suppose \\(k\\) people room. probability least one birthday someone else room?solution\\[\\text{P}(\\text{least one birthday }) = 1 - \\text{P}(\\text{birthdays different})\\]first person born day \\(365\\) days, second person different birthday \\(364\\) \\(k^{th}\\) person.\\(\\text{P}(\\text{birthdays different}) = \\frac{^{365}\\text{P}_k}{365^k}\\)can evaluated computer different values \\(k\\).\\(k=23\\) one finds \\(\\text{P}(\\text{birthdays different}) = 0.493\\).implies \\(\\text{P}(\\text{least one birthday }) = 1- 0.493 > 0.5\\).greater evens chance two people birthday room \\(23\\) people.","code":""},{"path":"index.html","id":"combinations","chapter":"1 Introduction to Probability","heading":"1.4.3 Combinations","text":"Definition 1.16  (Combinations) number ways choosing \\(k\\) distinct items \\(n\\) order relevant :\\[{}^nC_k = \\frac{n!}{(n-k)!k!}\\]\nway choosing \\(k\\) distinct items \\(n\\) order matter called combination.Example 1.20  many ways can \\(4\\) cards dealt ordinary pack \\(52\\) playing cards?solutionSuppose one hand Ace spades, king clubs, three hearts Jack diamonds. matter card given first, hand matters play.`order matter’.number hands \\({}^{52}C_{4}=270725\\).Example 1.21  (National Lottery) main National Lottery draw, six numbers chosen \\(49\\).probability winning jackpot lottery (.e. \\(6\\) match)?probability winning jackpot lottery (.e. \\(6\\) match)?probability three winning numbers come lottery ticket?probability three winning numbers come lottery ticket?solutionsTotal number outcomes \\({}^{49}C_{6} = 13983816\\).probability \\(\\frac{1}{^{49}C_{6}}\\), \\(1\\) \\(14\\) million.three winning numbers can three six winning numbers \\(^6C_3\\) combinations. numbers ticket can three \\(43\\) losing numbers week. number ways choosing \\(^{43}C_3\\).Therefore probability three winning numbers \n\\[\\text{P}(\\text{three winning numbers}) = \\frac{^{43}C_3 \\times ^6C_3}{^{49}C_6} = 0.0177\\]\napproximately \\(1\\) \\(56\\).","code":""},{"path":"index.html","id":"exercises-week-1","chapter":"1 Introduction to Probability","heading":"1.5 Exercises Week 1","text":"","code":""},{"path":"index.html","id":"tutorial-exercises","chapter":"1 Introduction to Probability","heading":"1.5.1 Tutorial exercises","text":"Exercise 1.1  letter chosen random word STATISTICS.\n) probability vowel?\nb) complement event )?Exercise 1.2  Suppose eating restaurant two friends. agree pay bill follows. person tosses coin. person gets result different two pay bill. three tosses , bill shared equally. Find probability :pay billAll three share billDo think fair way split bill?Exercise 1.3  investment can either; increase value (), break even (B) make loss (L). Suppose outcome equally likely. two separate investments made,List sample space drawing tree diagram.List sample space drawing tree diagram.Find probability :Find probability :investments increase value.investments make loss.least one investments increases value.Suppose investments type company. might model unrealistic, improve ?big sample space three separate investments made?Exercise 1.4  set cards consists standard suits \\(\\clubsuit\\), \\(\\spadesuit\\), \\(\\diamondsuit\\), \\(\\heartsuit\\), \\(13\\) cards suit.\n) Suppose one card drawn random. Find probability :\n() Ace Hearts, \\(\\heartsuit\\)\n(ii) King Spades \\(K\\spadesuit\\).\n(iii) picture card.Suppose two cards drawn random, first replaced deck shuffled second drawn ( called sampling replacement). Find probability :cards King Hearts, \\(K\\heartsuit\\).cards Aces.Exercise 1.5  Fifty male fifty female students asked whether agreed statement “Statistics often misleading”. Seventy students, thirty male, agreed.\n) Summarise information two-way table.\nb) student selected random, find probability :\n() Agree\n(ii) female\n(iii) male\n(iv) male agree\n(v) female agreeExercise 1.6  Interviews \\(120\\) working people revealed \\(76\\) stressed, \\(20\\) managers \\(14\\) managers stressed.\n) Summarise information two-way table.\nb) Assuming individual drawn random, find probability thatthey \n() Stressed\n(ii) shopfloor worker\n(iii) manager stressed\n(iv) shopfloor worker stressed.Exercise 1.7  Evaluate ) \\(^5\\text{P}_3\\), b) \\(^7\\text{P}_4\\), c) \\(^6\\text{P}_4\\).Exercise 1.8  value \\(n\\) following equality true?\n\\[ ^{n+1}\\text{P}_3 = ^n\\text{P}_4 \\]Exercise 1.9  Three different Mathematics books \\(5\\) different statistics books arranged shelf. many ways can books arranged ,\n) books subject must stand together\nb) statistics books must stand togetherExercise 1.10  Four different Mathematics books, \\(5\\) different statistics books \\(3\\) different computing books arranged shelf. many ways can books arranged ,\n) books subject must stand together\nb) statistics books must stand togetherExercise 1.11  Evaluate ) \\(^7\\text{C}_6\\), b) \\(^5\\text{C}_3\\), c) \\(^9\\text{C}_5\\), \\(^9\\text{C}_4\\).Exercise 1.12  many different committees can formed \\(8\\) men \\(6\\) women committee consists :\n) \\(1\\) man \\(4\\) women\nb) \\(5\\) men \\(3\\) women\nc) \\(4\\) men \\(4\\) women\nd) equal number men women.Exercise 1.13  council consists \\(10\\) members, \\(6\\) Party X \\(4\\) Party \\(Y\\).\n) many ways can committee \\(4\\) formed?\nb) many ways can committee \\(4\\) formed :\n) Party X majority\nii) Party Y majority\niii) Neither party majorityExercise 1.14  Ten equally qualified assistant managersare lined promotion. Seven men three women. company promotes four ten random, probability exactly two four chosen women?Exercise 1.15  Suppose library bookshelf contains equal number, \\(n\\) say, Mathematics books Physics books. bookshelf emptied books placed back randomly, probability books subject separated?Exercise 1.16  miscellaneous questions permutations combinations:\n) group \\(20\\) employees, \\(4\\) chosen promotion. many ways can chosen?\nb) group \\(20\\) employees, \\(4\\) shosen promotion, different role. many ways can chosen?\nc) product code consists \\(4\\) letters followed \\(3\\) digits. many codes possible repetitions allowed?\nd) \\(7\\)-card hand dealt normal pack \\(52\\) cards. many hands contain \\(4\\) clubs \\(3\\) hearts?\ne) many ways can merit awards allocated group \\(15\\) students one first prize, one second prize \\(4\\) identical third prizes?\nf) Four students chosen group \\(10\\). exactly one first three students must chosen, many ways choosing four students?Exercise 1.17  game poker, five cards standard deck \\(52\\) cards dealt hand. Find probability hand contains,\n) royal flush (ace, king, queen, jack \\(10\\) suit)\nb) Four kind (e.g. four \\(5\\)s)\nc) Two pairs\nd) full house (.e. three one kind two another)\ne) One pairExercise 1.18  \\(\\text{P()}=0.6\\) \\(\\text{P(B)}=0.5\\), can B mutually exclusive?Exercise 1.19  medical records \\(100\\) male diabetic patients reported clinic family history diabetes (Yes ), together symptoms either mild severe. provided following classification.Suppose patient chosen random clinic events , B C defines follows:: severe diseaseB : \\(40\\)C : parents diabeticFind probabilities P(), P(B), P(\\(\\cap\\)B), P(B\\(\\cap\\)C), P(\\(\\cap\\)B\\(\\cap\\)C).Find probabilities P(), P(B), P(\\(\\cap\\)B), P(B\\(\\cap\\)C), P(\\(\\cap\\)B\\(\\cap\\)C).Describe following events words calculate : \\(^c\\cap\\)B\\(^c\\), \\(^c\\cup\\)C\\(^c\\), \\(^c\\cap\\)B\\(^c\\cap\\)C\\(^c\\).Describe following events words calculate : \\(^c\\cap\\)B\\(^c\\), \\(^c\\cup\\)C\\(^c\\), \\(^c\\cap\\)B\\(^c\\cap\\)C\\(^c\\).","code":""},{"path":"index.html","id":"exercises-for-feedback","chapter":"1 Introduction to Probability","heading":"1.5.2 Exercises for feedback","text":"remember phone number. contains following digits something like \\(132 \\ 747 \\ 6965\\).probability first number even?probability first number even?many ways can numbers rearranged?many ways can numbers rearranged?many ways can number rearranged start end odd number?many ways can number rearranged start end odd number?Suppose certain numbers blocks \\(132\\),\\(747\\) \\(6965\\), sure order within block.many ways can numbers rearranged numbers within block ?many ways can numbers rearranged numbers within block ?probability wrote correct number originally?probability wrote correct number originally?lottery, \\(6\\) numbers drawn numbers \\(1\\) \\(49\\). Calculate following probabilities.numbers \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\), \\(6\\) drawn.numbers \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\), \\(6\\) drawn.numbers \\(4\\), \\(23\\), \\(24\\), \\(35\\), \\(40\\), \\(45\\) drawn.numbers \\(4\\), \\(23\\), \\(24\\), \\(35\\), \\(40\\), \\(45\\) drawn.\\(44\\) one numbers drawn.\\(44\\) one numbers drawn.Three dice rolled. sum numbers dice score.Describe sample space.Describe sample space.many ways score equal \\(5\\)?many ways score equal \\(5\\)?likely score?likely score?Suppose finite set \\(S\\) size \\(n\\).\n(Hint: question general, check answers concrete example S = { ,b,c,d })many subsets \\(S\\)?many subsets \\(S\\)?many subsets S size \\(1\\)?many subsets S size \\(1\\)?many subsets S size \\(k\\), \\(1\\leq k\\leq n\\)many subsets S size \\(k\\), \\(1\\leq k\\leq n\\)Using ) c), describe words following equality holds.Using ) c), describe words following equality holds.\\[2^n = \\sum_{k=0}^n {^n}C_k\\]Five office workers write names piece paper, fold paper put hat. names mixed person selects piece paper hat. everyone selected piece paper hat, staff look names drawn. probability member staff selected name?","code":""},{"path":"cond.html","id":"cond","chapter":"2 Conditional Probability","heading":"2 Conditional Probability","text":"chapter learn conditional probability. probability event, context another event happened potentially happening.","code":""},{"path":"cond.html","id":"independence","chapter":"2 Conditional Probability","heading":"2.1 Independence","text":"Independence important concept Statistics, one sometimes misused assumed without justification. basic idea follows:Definition 2.1  (Independence) Two events \\(\\text{}\\) \\(\\text{B}\\) independent exactly \n\\[\\text{P}(\\text{}\\cap\\text{B}) = \\text{P}(\\text{})\\times \\text{P}(\\text{B}).\\]\nwords means probability \\(\\text{}\\) \\(\\text{B}\\) happen product individual probabilities \\(\\text{}\\) \\(\\text{B}\\) respectively.Example 2.1  events can modelled independent include:\n- Outcomes successive tosses coin die. happened previous throw affect happens subsequent throws.sex babies. sex baby determined random, notwithstanding sexes previous babies.Example 2.2  Suppose power plant two safety systems, primary system works probability \\(0.999\\), backup system works probability \\(0.89\\) Assuming two systems operate independently, reliability safety power plant.solutionWe can work \\(\\text{P}(\\text{plant safe})\\) using complement:\\[\\text{P}(\\text{plant safe}) = 1-\\text{P}(\\text{plant fails}).\\]Let \\(F\\) event plant fails, \\(F_1\\) event first system fails, \\(F_2\\) backup fails.\\(F = F_1 \\cap F_2\\).\\[\\begin{align}\n\\text{P}(F) &= \\text{P}(F_1 \\cap F_2) \\\\\n&= \\text{P}(F_1) \\times \\text{P}(F_2) \\\\\n&= (1-0.999)\\times (1-0.89) \\\\\n&= 0.00011\n\\end{align}\\]\\(1-0.00011 = 0.99989\\).Calculations often used arrive unrealistic figures safety complex operating processes, e.g. nuclear power plants. example, ’s easy check three backup systems reliability \\(0.99\\), probability failure assuming independence \\(1\\times 10^{-6}\\) - reassuringly small figure! However can make calculations can justify assumption independence. example ’s unusual find backup systems used often can unreliable supposed actually called upon.might give reason particular context good example assume independence. example exercise 1.3 part (c) asks two investments may independent. many reasonable answers. Similar companies dependent - companies bakeries, may affected price wheat. companies may competitors, case one company better may cause worse.Example 2.3  Suppose toss ten coins coin many Heads. throw simultaneously. throw one time, order. matter?solutionNo, independent coins. Let\n\\[A_i =\\{\\text{} \\ ^{\\text{th}} \\ \\text{coin Heads} \\}\\]probability simultaneously Heads product probabilities individual coin Heads.\nNotice order matter \n\\[\\text{P}(\\text{}_i)\\times \\text{P}(\\text{}_j) = \\text{P}(\\text{}_j)\\times \\text{P}(\\text{}_i).\\]Assuming independence allows us consider simultaneous events separately one another, complicated examples can analysed easily using tree diagrams. path tree diagram root leaf distinct outcome sample space.Example 2.4  Vehicles approaching crossroads must go one three directions - left, right straight . Observations traffic engineers showed vehicles approaching north, \\(45\\%\\) turn left, \\(20\\%\\) turn right \\(35\\%\\) go straight . Assuming driver vehicle chooses direction independently, probability next three vehicles approaching north:go straight onall go straight onall go directionall go directiontwo turn left one turns righttwo turn left one turns rightall go different directionsall go different directionsexactly two turn left.exactly two turn left.solution\nFigure 2.1: tree diagram representing choices three vehicles\n\\(0.35^3\\)\\(0.35^3\\)\\(0.45^3+0.2^3+0.35^3\\)\\(0.45^3+0.2^3+0.35^3\\)LLR can rearranged \\(3\\) ways: LLR, LRL, RLL. \\(3\\times 0.45^2 \\times 0.2\\).LLR can rearranged \\(3\\) ways: LLR, LRL, RLL. \\(3\\times 0.45^2 \\times 0.2\\).SRL can rearranged \\(3!\\) ways. \\(3!\\times 0.35 \\times 0.45 \\times 0.2\\).SRL can rearranged \\(3!\\) ways. \\(3!\\times 0.35 \\times 0.45 \\times 0.2\\).LLR LLS. can rearranged \\(3\\) ways, mutually exclusive outcomes can add probabilities. \\[3\\times 0.45^2 \\times 0.2 + 3\\times 0.45^2 \\times 0.35\\].LLR LLS. can rearranged \\(3\\) ways, mutually exclusive outcomes can add probabilities. \\[3\\times 0.45^2 \\times 0.2 + 3\\times 0.45^2 \\times 0.35\\].","code":""},{"path":"cond.html","id":"conditional-probability","chapter":"2 Conditional Probability","heading":"2.2 Conditional Probability","text":"consider following examples motivate definition conditional probability.Example 2.5  number insurance claims previous \\(12\\) months cross tabulated whether driver involved young driver.insurance company interested claim rate. Overall claim rate ,\\[\\text{P}(\\text{Claim})=\\frac{50}{1000} = 0.05\\]estimate probability driver claiming insurance \\(1\\) \\(20\\).However figure hides substantial difference claim rates young older drivers.consider \\(250\\) young drivers separately ,\\[\\text{P}(\\text{Claim}|\\text{}\\ 25)=\\frac{25}{250} = 0.1.\\]\nWhereas \\(750\\) older drivers ,\\[\\text{P}(\\text{Claim}| 25 \\ \\text{})=\\frac{25}{750} = 0.03.\\]notation \\(|\\) read ‘given ’ conditional statement. conditional probabilities show claim rate much higher younger drivers. One can compute ratio probabilities see many times higher , \\(0.1/0.03 \\approx 3.3\\), just three times higher. relative risk scoring common medical statistics.Example 2.6  Consider following data study male lung cancer patients carried \\(1950\\) UK. one earliest applications epidemiology - use statistics study disease patterns populations.Calculate relative risk lung cancer smoker compared non-smoker.solution\\[\\text{P}(\\text{Lung cancer}|\\text{Smoker}) = \\frac{647}{1267}\\]\\[\\text{P}(\\text{Lung cancer}|\\text{Non-smoker}) = \\frac{2}{29}\\]\\(\\approx 7.4\\) times higher relative risk lung cancer smokers.examples motivate definition conditional probability.Definition 2.2  (conditional probability) conditional probability \\(\\text{P}(|B)\\) event \\(\\) given another event non-zero probability \\(B\\) given ,\\[\\text{P}(|B) = \\frac{\\text{P}(\\cap B)}{\\text{P}(B)}.\\]One verify fraction left precisely conditional probability calculated previous two examples.Theorem 2.1  conditional probability \\(\\text{P}(|B)\\) satisfies Kolmogorov’s definition probability.Proof. lectured examined, completeness.Firstly need check \\(P(|B)\\[0,1]\\). \\(P(|B) \\geq 0\\) \\(P(\\cap B)\\geq0\\) \\(P(B)>0\\).intersection \\(B\\) another set contained \\(B\\), \\(\\cap B \\subseteq B\\), \n\\[P(\\cap B) \\leq P(B).\\]\ndividing \\(P(B)\\) gives \\(P(|B) \\leq 1\\).Secondly, \\[P(\\Omega|B) = \\frac{P(\\Omega \\cap B)}{P(B)} = \\frac{P(B)}{P(B)}=1.\\]Lastly, given two disjoint \\(A_1\\),\\(A_2\\) \\(A_1\\cap A_2 = \\varnothing\\).\\[\\begin{align}\nP(A_1\\cup A_2 |B) &= \\frac{P((A_1\\cup A_2)\\cap B)}{P(B)} \\\\\n&= \\frac{P((A_1\\cap B)\\cup (A_2\\cap B))}{P(B)} \\\\\n&= \\frac{P(A_1\\cap B)}{P(B)} + \\frac{P(A_2\\cap B)}{P(B)} \\\\\n&= P(A_1|B) + P(A_2|B)\n\\end{align}\\]Example 2.7  Note \\(P(|B) \\neq P(B|)\\). Revisiting driver’s example gives,\\[\\text{P}(\\text{Claim}|\\text{}\\ 25)=0.1.\\]\nHowever,\n\\[\\text{P}(\\text{}\\ 25|\\text{Claim})=\\frac{25}{50} = 0.5\\]Theorem 2.2  Two events \\(\\) \\(B\\) independent \n\\[\\text{P}(|B) = \\text{P}() \\ \\text{ } \\ \\text{P}(B|) = \\text{P}(B)\\]\nwords, conditioning either event affect probability event occurring.Proof. Using definition conditional probability,\n\\[\\text{P}(\\cap B) = \\text{P}(|B)\\text{P}(B)=\\text{P}(B|)\\text{P}()\\]\n\n\\[\\text{P}(|B) = \\text{P}() \\ \\text{ } \\ \\text{P}(B|) = \\text{P}(B),\\]\nsubstituting former yields\n\\[\\text{P}(\\cap B) = \\text{P}()\\text{P}(B), \\]\ndefinition independence.\nConversely two events independent, \n\\[\\text{P}(|B) = \\frac{\\text{P}(\\cap B)}{\\text{P}(B)} = \\frac{\\text{P}()\\text{P}(B)}{\\text{P}(B)} = \\text{P}(), \\]\nlikewise \\(\\text{P}(B|)\\).constructing tree diagrams probabilities involved usually conditional probabilities natural progression tree left right conditioning happened previously. diagram , events \\(\\) \\(B\\) may independent.\nFigure 2.2: second level branches represent conditional probabilities B given complement, may different numbers\nExample 2.8  Jon always goes campus bike takes tram. one day goes campus bike, probability goes campus tram next day \\(0.4\\). one day goes campus tram, probability goes campus bike next day \\(0.7\\).\nGiven Jon goes campus Monday tram, find probability takes tram campus Wednesday.solutionThis may solved considering tree diagram levels Tuesday Wednesday. probabilities question \\(\\text{P}(\\text{tram} \\ |\\ \\text{bike})=0.4\\) \\(\\text{P}(\\text{bike} \\ |\\ \\text{tram})=0.7\\).\nMonday’s journey done. Possible sequences ‘tram tram’, ‘bike tram’. mutually exclusive outcomes. calculation \\[0.3^2+0.7\\times 0.4 = 0.37\\].Surveys questions sensitive delicate nature often result respondents missing question lying answers. Conditional probability can used mask awkward question find proportion answer certain way.Example 2.9  company want find proportion employees ever called sick work, fact sick. boss asks employee toss coin hide result.result heads, employee answer question ‘age odd number?’.result tails, answer ‘ever taken day ?’.boss know question people answering, employees can answer truthfully.Suppose \\(40\\%\\) employees mark ‘yes’ answer. Let,\\[p= \\text{P}(\\text{taken day } \\ | \\ \\text{tails})\\]\nAssume ages randomly distributed chance even odd number years old \\(0.5\\). can find \\(p\\)?solutionOne can draw tree diagram.\nFigure 2.3: outcomes survey.\noverall probability answering ‘yes’ \\(0.25+0.5p\\), survey \\(40\\%\\) answered ‘yes’. \\[0.25+0.5p = 0.4, \\]\nhence \\(p=0.3\\). means can estimate \\(30\\%\\) employees taken day supposed .","code":""},{"path":"cond.html","id":"bayes-theorem","chapter":"2 Conditional Probability","heading":"2.3 Bayes Theorem","text":"Example 2.10  two coins bag. One coin fair, heads sides (double-header).coin selected bag random, selected coin flipped three times. Unfortunately coin selected unknown us.three flips coin comes heads.Without calculations, likely think unfair coin?solutionLet\n\\(=\\left\\{ \\text{double-header selected} \\right\\}\\) \n\\(B =\\left\\{ \\text{coin lands heads three times row} \\right\\}\\)\nFigure 2.4: tree diagram double headed coin example.\nOne can use tree diagram find \\(8/9\\).can generalise picture come formula conditional probability called Bayes’ formula.\nFigure 2.5: Tree showing Bayes’ formula\n\\[P(|B) = \\frac{P(\\cap B)}{P(B)} = \\frac{P()P(B|)}{P()P(B|)+P(^{\\mathsf{c}})P(B|^{\\mathsf{c}})}\\]Previously, \\(A_1=\\) \\(A_2 = ^{\\mathsf{c}}\\) disjoint union gives entire sample space. situation called partition.can extended partition \\(n\\) events \\(A_1,A_2, \\dots , A_n\\).Definition 2.3  collection events \\(A_1, A_2, \\dots , A_n\\) partition union entire sample space, exhaustive, mutually exclusive. \\(\\Omega = A_1 \\cup A_2 \\cup \\dots \\cup A_n\\).\\(\\Omega = A_1 \\cup A_2 \\cup \\dots \\cup A_n\\).\\(A_1 \\cap A_2 \\cap \\dots \\cap A_n = \\varnothing\\)\\(A_1 \\cap A_2 \\cap \\dots \\cap A_n = \\varnothing\\)event complement form partition.picture partition:\nFigure 2.6: example partition six sets.\ncan now extend concept conditional probability general situation condition event least one event partition.Theorem 2.3  (Law Total Probability) Suppose partition \\(A_1, A_2, \\dots , A_n\\) sample space \\(\\Omega\\). event \\(B \\subseteq \\Omega\\), \\[\\text{P}(B) =P(A_1)P(B|A_1)+ \\dots + P(A_n)P(B|A_n) \\]intuitive proof imagine tree diagram \\(n\\) branches \\(A_i\\) first layer, \\(B\\) \\(B^{\\mathsf{c}}\\) next layer. multiply along branches ways \\(B\\) can occur end sum RHS.Theorem 2.4  (Bayes' Theorem) Suppose partition \\(A_1, A_2, \\dots , A_n\\) sample space \\(\\Omega\\). conditional probability one event partition \\(A_k\\) \\(k\\), given event \\(B\\) can written ,\\[\\text{P}(A_k |B) = \\frac{\\text{P}(B|A_k)\\text{P}(A_k)}{\\sum^{n}_{=1}\\text{P}(B|A_i)P(A_i)}\\]Proof. Note \\(\\text{P}(A_k\\cap B) = \\text{P}(B|A_k)\\text{P}(A_k)\\),denominator $(B) using law total probability.Example 2.11  company produces electrical components using three shifts. first shift \\(50%\\) components produced, \\(20\\%\\) \\(30\\%\\) produced shifts \\(2\\) \\(3\\) respectively. proportion defective components produced shift \\(1\\) \\(6\\%\\). shifts \\(2\\) \\(3\\) proportions \\(8\\%\\) \\(12\\%\\) respectively.Find percentage defective components.Find percentage defective components.component defective, probability came shift \\(3\\)?component defective, probability came shift \\(3\\)?solutionLet \\(D\\) event component defective \\(S_1,S_2,S_3\\) denotethat produced shifts \\(1,2\\) \\(3\\) respectively.Use theorem total probability, follows:\n\\[\\begin{align}\n\\text{P}(D)  &= \\text{P}(D|S_1)P(S_1)+\\text{P}(D|S_2)\\text{P}(S_2)+\\text{P}(D|S_3)\\text{P}(S_3) \\\\\n&= 0.06\\times 0.5 + 0.08\\times 0.2 + 0.12\\times 0.3 \\\\\n&= 0.082\n\\end{align}\\]Use theorem total probability, follows:\n\\[\\begin{align}\n\\text{P}(D)  &= \\text{P}(D|S_1)P(S_1)+\\text{P}(D|S_2)\\text{P}(S_2)+\\text{P}(D|S_3)\\text{P}(S_3) \\\\\n&= 0.06\\times 0.5 + 0.08\\times 0.2 + 0.12\\times 0.3 \\\\\n&= 0.082\n\\end{align}\\]Using Bayes’ theorem,Using Bayes’ theorem,\\[\\text{P}(S_3|D) = \\frac{\\text{P}(D|S_3)\\text{P}(S_3)}{\\text{P}(D)}\\]\ndenominator worked part ), gives \\(\\frac{0.12\\times 0.3}{0.082}=0.439\\).Bayes’ theorem allows us update probability event light new evidence. fact main practical use theorem, leads whole branch Bayesian Statistics.Example 2.12  Gary suspected committing crime. evidence far points probability guilt \\(0.9\\). ‘prove innocence’ Gary undergoes lie detector test, \\(70\\%\\) accuracy rate. test say positive indicate guilt, negative indicate guilty. test \n\\[\\text{P}(\\text{Positive}|\\text{Guilty}) = 0.7\\]\n\\[\\text{P}(\\text{Negative}|\\text{Innocent})=0.7\\]Gary’s test comes back negative, probability guilt?solutionOne can directly apply Bayes’ theorem.\n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{\\text{P}(\\text{Negative}|\\text{Guilt})\\text{P}(\\text{Guilt})}{\\text{P}(\\text{Negative}|\\text{Guilt})\\text{P}(\\text{Guilt})+\\text{P}(\\text{Negative}|\\text{Innocent})\\text{P}(\\text{Innocent})}\\]\n\n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 0.9}{0.3\\times 0.9 \\ + \\ 0.7\\times 0.1}=0.794 \\ \\text{(3 d.p.)}\\]Beware extreme prior beliefs, evidence can change mind. Believing something true \\(100\\%\\) \\(0\\%\\), mean reason evidence change position.Example 2.13  (Cromwell's Rule) believe Gary \\(100\\%\\) guilty start \n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 1}{0.3\\times 1 \\ + \\ 0.7\\times 0}=1\\]\nstill believe Gary \\(100\\%\\) guilty.believe Gary \\(0\\%\\) guilty start \n\\[\\text{P}(\\text{Guilt}|\\text{Negative})=\\frac{0.3\\times 0}{0.3\\times 0 \\ + \\ 0.7\\times 1}=0\\]\nstill believe Gary \\(0\\%\\) guilty.educated people always consider opposing opinion update beliefs according evidence available. strong opinion something, consider change mind. Always leave room doubt , wrong.","code":""},{"path":"cond.html","id":"exercises-week-2","chapter":"2 Conditional Probability","heading":"2.4 Exercises Week 2","text":"Exercise 2.1  toss fair coin roll die.\n) events independent?probability obtain head \\(6\\)?Exercise 2.2  torch uses two batteries series. battery works probability \\(0.95\\), independently . Work probability :torch work.torch work.batteries failBoth batteries failOnly one batteries work.one batteries work.Exercise 2.3  Whether student gets time depends whether remembered set alarm night . \\(90\\%\\) time remembers, \\(10\\%\\) forgets. clock set, get time \\(95\\%\\) occasions. set, chance oversleep \\(35\\%\\). Use tree diagram find probability oversleep.Exercise 2.4  following data shows distribution male female students various degree courses university.Suppose student selected random. Find probability ,femalefemalestudying Economicsstudying Economicsmale studying Economicsmale studying Economicsmale given studying Economicsmale given studying Economicsfemale given studying Economicsfemale given studying Economicsstudying Economics given femalestudying Economics given femaleAre events ‘student male’ ‘studying Economics’ independent?Exercise 2.5  following table shows lung cancer data females \\(1950\\) study given example 2.6.Calculate relative risk female smokers compared non-smokers.Calculate relative risk female smokers compared non-smokers.Can suggest reason difference figures males females?Can suggest reason difference figures males females?Exercise 2.6  Two electrical components \\(X\\) \\(Y\\) probabilities working \\(\\frac{3}{4}\\) \\(\\frac{7}{8}\\), respectively. also function independently . Two devices \\(D_1\\) \\(D_2\\) constructed. \\(D_1\\), \\(X\\) \\(Y\\) series, \\(D_2\\) wired parallel.Find probability \\(D_1\\) works.\nFind probability \\(D_1\\) works.Find probability \\(D_2\\) works.Suppose \\(D_1\\) works, find probability ;\\(X\\) working.\\(X\\) working.\\(X\\) \\(Y\\) working.Suppose \\(D_2\\) works, find probability ;\\(X\\) working.\\(X\\) working.\\(X\\) \\(Y\\) working.Exercise 2.7  urn contains two green balls three red bals. Supose two balls drawn random one another without replacement. Draw tree diagram, find probability :green ball appears first draw.green ball appears first draw.green ball appears second draw.green ball appears second draw.Exercise 2.8  following table shows fear factor children attending dentist, cross tabulated School age child.child selected random define events; \\(= \\{ \\text{child afraid} \\}\\),\\(N\\) afraid, \\(\\),\\(P\\) \\(S\\) School age obvious fashion.Calculate following probabilities,\\(\\text{P}()\\), \\(\\text{P}(N)\\), \\(\\text{P}(\\cup )\\).\\(\\text{P}()\\), \\(\\text{P}(N)\\), \\(\\text{P}(\\cup )\\).\\(\\text{P}(| )\\) \\(\\text{P}(| )\\).\\(\\text{P}(| )\\) \\(\\text{P}(| )\\).\\(\\text{P}(| S)\\) \\(\\text{P}(N| S)\\) - notice two probabilities?\\(\\text{P}(| S)\\) \\(\\text{P}(N| S)\\) - notice two probabilities?\\(\\) \\(\\) independent?Exercise 2.9  survey electrical retailer determines \\(40\\%\\) customers seek advice sales staff appliance \\(20\\%\\) seek advice buy appliance. \\(30\\%\\) customers seek advice, probability customer entering warehouse buys appliance?Exercise 2.10  Four cards drawn random without replacement deck \\(52\\) cards. probability sequence :\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\clubsuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\clubsuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\spadesuit\\)\\(\\heartsuit\\) \\(\\heartsuit\\) \\(\\spadesuit\\) \\(\\spadesuit\\)Exercise 2.11  student comes back night pub bunch keys, one works. try one key random lock discard doesn’t fit.Suppose bunch contains \\(2\\) keys. Find probability open door onthe first attemptthe first attemptthe second attemptthe second attemptRepeat bunch three keys successul first, second third attempts.Repeat bunch three keys successul first, second third attempts.Suppose now bunch contains \\(n\\) keys. Find probability door opened \\(r^{\\text{th}}\\) attempt (\\(1\\leq r \\leq n\\)).Suppose now bunch contains \\(n\\) keys. Find probability door opened \\(r^{\\text{th}}\\) attempt (\\(1\\leq r \\leq n\\)).Exercise 2.12  ascertain proportion people sexually transmitted infection, following survey pocedure used \\(1000\\) individuals.asked think day week recent birthday fell .last birthday Monday, Tuesday Wednesday answer question ‘every sexually transmitted infection?’.last birthday day week, answer question ‘age even number?’.survey \\(290\\) people answered ‘yes’. Assuming ages birthdays uniformly distributed, can estimate proportion people sexually transmitted infection?Exercise 2.13  Suppose two events \\(\\) \\(B\\) independent. Show \\(\\) \\(B^{\\mathsf{c}}\\) also independent. Show also \\(^{\\mathsf{c}}\\) \\(B^{\\mathsf{c}}\\) independent.Exercise 2.14  Forty percent new employees hired large company degree. Seventy percent employees degrees promoted within two years.without degrees, \\(30\\%\\) arepromoted within two years.probability new empoyee promoted?probability new empoyee promoted?employee promoted, probability degree?employee promoted, probability degree?Exercise 2.15  bag contains \\(3\\) coins; two normal unbiased coins third double headed. coin chosen random bag tossed. coin tossed \\(4\\) times came heads time. probability double header?Exercise 2.16  Approximately \\(25\\%\\) males \\(50\\) form heart problem. clinic observed males heart problem three times likely smokers males heart problem. probability male \\(50\\) heart problem given smoker?Exercise 2.17  Cage contains five hens disease six hens without disease. Cage B contains two diseased hens five hens without disease. Two hens chosen random cage transferred cage B. hen now chosen random cage B found diseased. Find probability two hens transferred ,diseasedboth diseasedboth without disease.without disease.","code":""},{"path":"drv.html","id":"drv","chapter":"3 Discrete Random Variables","heading":"3 Discrete Random Variables","text":"practical situations encounter uncertainty, random outcome interest numerical quantity. number minutes end waiting bus, much win lottery week, even number times try catch fly chopsticks eventually manage .","code":""},{"path":"drv.html","id":"random-variables","chapter":"3 Discrete Random Variables","heading":"3.1 Random Variables","text":"chapter learn concept discrete random variable.Example 3.1  Suppose roll two dice find sum numbers two dice. Let \\(X\\) sum numbers two dice. know sample space :\n\\[\\Omega = \\{ (n_1,n_2) : n_1,n_2 \\\\mathbb{N}, \\ 1 \\leq n_1 , n_2 \\leq 6 \\},\\]\nGiven outcome \\((n_1,n_2)\\), ‘variable’ \\(X\\) takes particular whole numbered value \\(x=2, \\dots , 12\\). seen particular values equally likely.Definition 3.1  random variable \\(X\\) set function maps potential outcomes statistical experiment (subset ) real number line.random variable written capital letter (\\(X\\)), particular values takes written lowercase letter (\\(x\\)). probability \\(X\\) takes particular value written \\(\\text{P}(X=x)\\).Just data analysis difference discrete continuous random variables. One can think discrete random variables arising process involves counting can take integer values. continuous random variables can thought arising measuring process.Example 3.2  Let $R = $ result spinning roulette wheel. roulette wheel can take particular values\n\\[\\Omega = \\{0,1,2, \\dots,36\\}.\\]\nnumber ranges 1 10 19 28, odd numbers red even black. ranges 11 18 29 36, odd numbers black even red. green pocket numbered 0 (zero). \\(R\\) discrete random variable, takes particular discrete values.Let \\(T =\\) time spent waiting bus. \\(T\\) positive number arrive bus stop (time timetabled arrival time, negative early bus). \\(T\\) continuous random variable.consider discrete random variables first, study types course.","code":""},{"path":"drv.html","id":"discrete-probability-distributions","chapter":"3 Discrete Random Variables","heading":"3.2 Discrete probability distributions","text":"order understand random variable likely behave, thus able predict possible future values, clearly need consider probability take particular values. set probability values known probability distribution. develop theory examples.Definition 3.2  distribution function, also known probability mass function, random variable \\(X\\) function outputs probability \\(X\\) attaining particular value. ,\\[f(x) = \\text{P}(X=x)\\]\ntexts, two variables play, may also write variable subscript \\(f_X(x)\\) clear mass function referring.Example 3.3  (discrete uniform distribution) Consider rolling fair die let discrete random variable \\(X\\) score observed die. know probability getting particular values set \\(\\{1,2, \\dots 6\\}\\) \\(\\frac{1}{6}\\) probability distribution. may tabulate values followsAlternatively may use formula:\n\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\frac{1}{6}, & \\text{} x = 1, 2, \\dots , 6.\\\\\n    0 & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]graph:\nFigure 3.1: Probability mass function fair die\nClearly graph useful way visualise probability distributed. can also see called discrete uniform distribution - ’s values .questions consider:Suppose die \\(n\\) sides, \\(n\\) whole number greater \\(1\\), faces numbered \\(1,2,\\dots n\\). distribution look like now?Suppose die \\(n\\) sides, \\(n\\) whole number greater \\(1\\), faces numbered \\(1,2,\\dots n\\). distribution look like now?Can represent distribution three ways ?Can represent distribution three ways ?Example 3.4  (Urn problem) urn contains five balls numbered \\(1\\) \\(5\\). Two balls drawn simultaneously.Let \\(X\\) larger two numbers.Let \\(X\\) larger two numbers.Let \\(Y\\) sum two numbers.Let \\(Y\\) sum two numbers.Find probability distributions \\(X\\) \\(Y\\).solutionWe proceed follows enumerating possibilities noting \\(^5C_2=10\\) ways drawing balls urn. Note balls drawn simultaneously, order matter .find distribution \\(X\\) one can list outcomes systematically largest value.find distribution \\(Y\\) one can list outcomes systematically sum.either case check individual probability \\(0\\) \\(1\\) possible particular values sum \\(1\\).Example 3.5  (geometric distribution) archer hits target rather randomly. Let’s suppose time takes aim \\(\\text{P}(\\text{Hit})=\\frac{1}{4}\\), complement \\(\\text{P}(\\text{Miss})=\\frac{3}{4}\\). Let \\(Y\\) number attempts required hits target. Find distribution \\(Y\\).solutionWe can consider number attempts separately.\\(Y=1\\), first attempt hit, \\(\\text{P}(Y=1)=\\frac{1}{4}.\\)\\(Y=2\\), first attempt miss, second hit, \n\\[\\text{P}(Y=2)=\\frac{3}{4}\\times \\frac{1}{4} = \\frac{3}{16}.\\]\\(Y=3\\), first attempt miss, second miss, third hit \n\\[\\text{P}(Y=3)=\\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{1}{4} = \\frac{9}{64}.\\]\n\\(Y=4\\), sequence miss, miss, miss hit:\n\\[\\text{P}(Y=3)=\\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{3}{4}\\times \\frac{1}{4} = \\frac{27}{256}.\\]\n.Notice archer hit target \\(y^{\\text{th}}\\) attempt, must missed previous \\(y-1\\) attempts, formula mass function follows.\\[\\begin{equation*}\n  f(Y=y)=\\begin{cases}\n    \\left( \\frac{3}{4} \\right)^{y-1}\\frac{1}{4} \\ , & \\text{} y = 1, 2, 3, \\dots \\\\\n    \\ 0 \\ & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]Clearly probabilities quickly getting small - may recognise terms geometric sequence common ration \\(\\frac{3}{4}\\).graph distribution looks like:\nFigure 3.2: geometric distribution\nchoice \\(\\frac{1}{4}\\) infact arbitrary. general can ‘success’ probability \\(\\pi\\) ‘failure’ probability \\(1-\\pi\\).Definition 3.3  random variable \\(X\\) representing number independent trials first success follows geometric distribution success probability \\(\\pi\\), written \\(X \\sim \\text{Geom}(\\pi)\\), defined probability mass function\\[\\begin{equation*}\n  f(x)=\\begin{cases}\n    \\left( 1-\\pi \\right)^{x-1}\\pi , & x = 1, 2, 3, \\dots \\\\\n    \\ 0 \\ & \\text{otherwise}.\n  \\end{cases}\n\\end{equation*}\\]course trials archer arguably independent - ?","code":""},{"path":"drv.html","id":"properties-of-probability-mass-functions","chapter":"3 Discrete Random Variables","heading":"3.3 Properties of probability mass functions","text":"random variable \\(X\\) probability distribution \\(f(x)\\) following two properties:probability particular value \\(0\\) \\(1\\). ,\n\\[ 0 \\leq f(x) \\leq 1, \\ \\forall x\\]probability particular value \\(0\\) \\(1\\). ,\n\\[ 0 \\leq f(x) \\leq 1, \\ \\forall x\\]probabilities sum unity. ,probabilities sum unity. ,\\[ \\sum_{x} f(x)= 1\\]Probability distributions can represented variety different ways. practice use tables distributions use computer functions evaluate .R can use following functions evaluate probabilities example 3.5.important function \\(\\texttt{dgeom()}\\), \\(\\texttt{d}\\) stands distribution \\(\\texttt{geom}\\) geometric distribution.Another way represent probability distribution cumulative sum.Definition 3.4  (Cumulative distribution function) Given random variable \\(X\\) probability mass function \\(f(x)\\), cumulative distribution function (abbreviated CDF) denoted capital letter \\(F(x)\\) defined sum probabilities less equal value \\(x\\). ,\\[ F(x) = \\text{P}(X\\leq x) = \\sum_{t\\leq x}f(t)\\]Example 3.6  (another urn problem) Consider setup previously two balls numbered \\(1\\) \\(5\\) drawn maximum two numbers taken.\nfound probability distribution ,Work CDF \\(F(x)\\).solutionIf \\(x<2\\) \\(F(x)=0\\).\n\\(2\\leq x < 3\\) \\(F(x) = \\frac{1}{10}\\).\n\\(3\\leq x < 4\\) \\(F(x) = \\frac{1}{10} + \\frac{2}{10}\\).\n\\(4\\leq x < 5\\) \\[F(x) = \\frac{1}{10} + \\frac{2}{10} + \\frac{3}{10}.\\]\n\\(5\\leq x\\) \\[F(x) = \\frac{1}{10} + \\frac{2}{10} + \\frac{3}{10} + \\frac{4}{10}.\\]Altogether,\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n  0  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   x<2 \\\\\n  \\frac{1}{10} \\  \\  2\\leq x < 3 \\\\\n  \\frac{3}{10} \\ \\  3\\leq x < 4 \\\\\n  \\frac{6}{10} \\ \\ \\ 4\\leq x < 5 \\\\\n  1 \\ \\ \\  \\ \\ \\  5\\leq x\n  \\end{cases}\n\\end{equation*}\\]Example 3.7  CDF geometric distribution given \n\\[F(x) = 1- (1-\\pi)^{x}.\\]solution\\[F(x) = \\sum_{t\\leq x}f(t)\\]\nSum \\(t=1\\) \\(t=x\\).\\[  = \\pi + \\pi(1-\\pi) + \\pi(1-\\pi)^2 + \\dots +  \\pi(1-\\pi)^{x-1} \\]\nmight recognise geometric series , \\(=\\pi\\) \\(r=(1-\\pi)\\), can collected :\\[F(x) = \\frac{\\pi (1-(1-\\pi)^x)}{1-(1-\\pi)} \\]\nEvaluating denominator cancelling gives result.CDF useful mass function since given CDF can calculate mass function directly difference.\\[f(x) = F(x)-F(x-1)\\]Example 3.8  Calculate \\(f(4)\\) given CDF\\[\\begin{equation*}\n  F(x)=\\begin{cases}\n  0  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\   x<2 \\\\\n  \\frac{1}{10} \\  \\  2\\leq x < 3 \\\\\n  \\frac{3}{10} \\ \\  3\\leq x < 4 \\\\\n  \\frac{6}{10} \\ \\ \\ 4\\leq x < 5 \\\\\n  1 \\ \\ \\  \\ \\ \\  5\\leq x\n  \\end{cases}\n\\end{equation*}\\]solution\\(f(4) = F(4)-F(3) = \\frac{6}{10}-\\frac{3}{10} = \\frac{3}{10}\\)Due fact mass function can calculated CDF, statistical tables often prioritise tabulating CDF various different types distribution.finish section example theory may used applied calculations.Example 3.9  Assuming archer’s attempts hit target follows geometric distribution success parameter \\(\\frac{1}{4}\\) calculate probability heHits \\(10^{\\text{th}}\\) attempt.Hits \\(10^{\\text{th}}\\) attempt.Takes fewer \\(4\\) attempts hit target.Takes fewer \\(4\\) attempts hit target.Takes least \\(8\\) attempts hit target.Takes least \\(8\\) attempts hit target.Takes \\(4\\) \\(8\\) attempts inclusive.Takes \\(4\\) \\(8\\) attempts inclusive.solutionLet \\(Y\\) number attempts hit target. know \\[f(y) = \\left( \\frac{3}{4} \\right) ^{y-1}\\frac{1}{4}\\]\\[ F(y) = 1- \\left(1-\\frac{1}{4}\\right)^y = 1-\\left( \\frac{3}{4}\\right)^y.\\]\\(\\text{P}(Y=10) = f(10) = \\left( \\frac{3}{4}\\right)^9\\times \\frac{1}{4} = 0.0188\\) (\\(3\\) s.f.).\\(\\text{P}(Y=10) = f(10) = \\left( \\frac{3}{4}\\right)^9\\times \\frac{1}{4} = 0.0188\\) (\\(3\\) s.f.).\\(\\text{P}(Y<4) = \\text{P}(Y\\leq 3) = F(3) =1 - \\left( \\frac{3}{4}\\right)^3 = 0.578\\), (\\(3\\) s.f.).\\(\\text{P}(Y<4) = \\text{P}(Y\\leq 3) = F(3) =1 - \\left( \\frac{3}{4}\\right)^3 = 0.578\\), (\\(3\\) s.f.).Using complement, \\(\\text{P}(Y\\geq 8) = 1 - \\text{P}(Y\\leq 7)\\). Now using CDF:Using complement, \\(\\text{P}(Y\\geq 8) = 1 - \\text{P}(Y\\leq 7)\\). Now using CDF:\\[1-F(7) = 1- \\left( 1-\\left(\\frac{3}{4}\\right)^7\\right) = 0.134.\\]Rewrite required range difference two CDF values follows:\\[\\text{P}(4\\leq Y\\leq 8) = \\text{P}(Y\\leq 8) - \\text{P}(Y\\leq 3)\\]\\[ = F(8) - F(3)\\]\\[ = \\left[ 1-\\left(\\frac{3}{4}\\right)^8\\right] -  \\left[ 1-\\left(\\frac{3}{4}\\right)^3\\right]\\]\n\\[ = 0.322\\]\ncareful evaluating CDF ensure correct values given inequality. small diagram list can invaluable .","code":"\ny <- dgeom(x = 1:4, #these are the particular values 1,2,3 and 4\n           prob = 1/4 ) #This is the probability of success\ny## [1] 0.18750000 0.14062500 0.10546875 0.07910156\n#You can output these as fractions using the MASS library\nMASS::fractions(y)## [1]    3/16    9/64  27/256 81/1024"},{"path":"drv.html","id":"mean-variance-and-moments","chapter":"3 Discrete Random Variables","heading":"3.4 Mean, variance and moments","text":"mean variance random variable essentially mirror definitions mean variance samples.mean expected value average value variable observed repeatedly. variance indicates likely spread values variable.Example 3.10  toss coin \\(2\\) times many heads expect turn ?solutionYour expect \\(1\\) intuitively. Let \\(X\\) number heads.\noutcomes \\((T,T),(H,T),(T,H),(H,H)\\). average number heads \\[ \\frac{0+1+1+2}{4} = 1\\]\ncan relate probability number heads. ,\\[\\text{P}(X=0) = \\frac{1}{4}\\]\n\\[\\text{P}(X=1) = \\frac{2}{4}\\]\n\\[\\text{P}(X=2) = \\frac{1}{4}\\]sum possible \\(x\\) values weighted probability :\n\\[0\\times \\frac{1}{4} + 1\\times \\frac{2}{4} + 2\\times \\frac{1}{4} = 1.\\]Definition 3.5  expectation, expected value random variable \\(X\\) defined sum possible values random variable weighted probability value.\\[ \\text{E}[X] = \\sum_x x\\times\\text{P}(X=x)\\]\njust number calculated called mean, written constant \\(\\text{E}[X]=\\mu\\) omit random quantity \\(X\\).expected value function discrete random variable \\(g(X)\\) defined similarly \n\\[ \\text{E}[X] = \\sum_x g(x)\\times\\text{P}(X=x)\\]Definition 3.6  variance random variable \\(X\\) defined :\\[ \\text{Var}[X] = \\text{E}[(X-\\mu)^2]\\]following useful practice actually computing variance.Theorem 3.1  Given random variable \\(X\\) variance equal difference expectation \\(X^2\\) squared expectation \\(X\\). ,\\[ \\text{Var}[X]=\\text{E}[X^2]-\\text{E}[X]^2 \\]omit proof now see examples, leaving interested reader.Proof. expectation sum, behaves linearly. definition,\\[\\text{Var}[X] = \\text{E}[(X-\\mu)^2]\\]\nExpanding bracket inside gives,\n\\[ = \\text{E}[X^2 - 2\\mu X +\\mu^2] \\]\nUsing linearity,\\[= \\text{E}[X^2]-2\\mu\\text{E}[X]+\\mu^2.\\]\n\\[= \\text{E}[X^2]-2\\mu^2+\\mu^2.\\]\nHence result.Example 3.11  discrete random variable \\(X\\) representing score loaded die following probability mass function.Calculate:\\(\\text{E}[X]\\)\\(\\text{E}[X]\\)\\(\\text{E}[X^2]\\)\\(\\text{E}[X^2]\\)\\(\\text{Var}[X]\\)\\(\\text{Var}[X]\\)\\(\\text{E}[e^X]\\)\\(\\text{E}[e^X]\\)solutionUsing definition expectation:\\[ \\text{E}[X] = 1\\times \\frac{1}{21}+2\\times \\frac{2}{21}+3\\times \\frac{3}{21}+4\\times \\frac{4}{21}+5\\times \\frac{5}{21}+6\\times \\frac{6}{21},\\]\n\\[ = 4.33 \\ \\ \\ (3 \\ \\text{s. f.})\\]\nCompared fair die, mean loaded die higher.\\[ \\text{E}[X^2] = 1^2\\times \\frac{1}{21}+2^2\\times \\frac{2}{21}+3^2\\times \\frac{3}{21}+4^2\\times \\frac{4}{21}+5^2\\times \\frac{5}{21}+6^2\\times \\frac{6}{21},\\]\\[ = 21\\]variance ,\\[\\text{Var}[X]=\\text{E}[X^2]-\\mu^2 = 21-(4.33\\dots)^2= 2.22 \\ \\ \\ (3 \\ \\text{s. f.})\\]\n4. \\(e^X\\) just function \\(X\\).\\[ \\text{E}[X] = e^1\\times \\frac{1}{21}+e^2\\times \\frac{2}{21}+e^3\\times \\frac{3}{21}+e^4\\times \\frac{4}{21}+e^5\\times \\frac{5}{21}+e^6\\times \\frac{6}{21},\\]\\[ = 164.622 \\ (3 \\ \\text{d. p.}) \\]Example 3.12  (expected profit) Consider following game. spinning wheel divided three equal sections numbered \\(1\\), \\(2\\) \\(3\\). pay £\\(1\\) play game, guess number show wheel spun. guess correctly, get £\\(2\\). get nothing. expected profit playing game?solutionThe profit winnings minus stake. Let profit random variable \\(X\\). distribution \\(X\\) :\\[\\text{E}[X] = -1 \\times \\frac{2}{3} + 1 \\times \\frac{1}{3} = -\\frac{1}{3}\\]\nexpect average make loss playing game. gambling game profitable house, necessary expectation players winnings negative.Example 3.13  Let \\(X\\) random variable whose value constant, particular values can take , \\(x=\\). Show \\(\\text{E}[X]=\\) \\(\\text{Var}[X]=0\\)solution\\[\\text{E}[X]=\\sum_{x}x\\times\\text{P}(X=x)= \\sum \\times\\text{P}(X=)=\\times \\sum \\text{P}(X=) = \\times 1 = \\]variance,\\[ \\text{Var}[X] = \\text{E}[(X-\\mu)^2]=\\text{E}[(-)^2]=0 \\]now proceed find mean variance Geometric distribution. need fact series first.Proposition 3.1  Suppose \\(|r|<1\\) recall infinite geometric series given following formula:\\[g(r) = \\sum_{k=0}^{\\infty}ar^{k} = \\frac{}{1-r}\\]\nconvergent series can differentiate term term respect \\(r\\), equate get differentiating RHS likewise. results following two formulae:\\[g'(r) = \\sum_{k=0}^{\\infty}akr^{k-1} = \\frac{}{(1-r)^2}\\]\\[g''(r) = \\sum_{k=0}^{\\infty}ak(k-1)r^{k-2} = \\frac{2a}{(1-r)^3}\\]Theorem 3.2  Let \\(X\\) random variable follows geometric distribution, \\(X \\thicksim \\text{Geom}(\\pi)\\), :\\[\\text{E}[X] = \\frac{1}{\\pi}\\]\n\n\\[ \\text{Var}[X]=\\frac{1-\\pi}{\\pi^2}\\]Proof. definition,\n\\[\\text{E}[X] = \\sum_{x=1}^{\\infty}x(1-\\pi)^{x-1}\\pi\\]\n\\[ = \\pi + 2\\pi(1-\\pi) + 3\\pi(1-\\pi)^2+4\\pi(1-\\pi)^3+ \\dots \\]\nlatter sum can seen \\(g'(1-\\pi)\\), \\(=\\pi\\). Using RHS result previous proposition ,\n\\[\\text{E}[X] = \\frac{\\pi}{[1-(1-\\pi)]^2} = \\frac{1}{\\pi}\\]\nvariance first find expectation function \\(X\\) called factorial moment.\\[\\text{E}[X(X-1)] = \\sum_{x=1}^{\\infty}x(x-1)\\pi(1-\\pi)^{x-1}\\]\n\\[ = (1-\\pi)\\sum_{x=2}^{\\infty}x(x-1)\\pi(1-\\pi)^{x-2}\\]\ninfinite series turns \\(g''(1-\\pi)\\) \\(=\\pi\\). Substituting gives,\\[\\text{E}[X(X-1)]=(1-\\pi)\\frac{2\\pi}{[1-(1-\\pi)]^3} = \\frac{2(1-\\pi)}{\\pi^2}.\\]\nNow can use find variance follows,\\[\\text{Var}[X] = \\text{E}[X^2]-\\text{E}[X]^2 \\]\n\\[ = \\text{E}[X(X-1)]+\\text{E}[X]-\\text{E}[X]^2 \\]\n\\[ = \\frac{2(1-\\pi)}{\\pi^2} + \\frac{1}{\\pi} - \\frac{1}{\\pi^2} \\]\n\\[ = \\frac{1-\\pi}{\\pi^2}\\]\nrequired.given two random variables \\(X\\) \\(Y\\) linear combination means expression form \\(aX+\\).Theorem 3.3  (Linear Combinations) random variables \\(X\\) \\(Y\\) constants \\(\\) \\(b\\) expectation linear combination linear combination expectations.\\[\\text{E}[aX\\pm ] = \\text{E}[X]\\pm b\\text{E}[Y]\\]\nHowever variance nonlinear sum variances.\\[\\text{Var}[aX\\pm ] = ^2\\text{Var}[X]+b^2\\text{Var}[Y] \\]Proof. omitted, follows properties summations mass functions.Example 3.14  Recall loaded die mass function given ,Suppose win \\(W\\) amount depending number roll loaded die.\\(W = 3X-10\\) find \\(\\text{E}[W]\\) \\(\\text{Var}[W]\\)solution\\[\\text{E}[W] = 3\\times (4.333\\dots) -10 = £3\\]\\[\\text{Var}[W] = 3^2\\times(2.22\\dots) = 19.99\\dots = 20.0 \\  (3 \\ \\text{s.f.})\\]","code":""},{"path":"drv.html","id":"exercises-week-3","chapter":"3 Discrete Random Variables","heading":"3.5 Exercises Week 3","text":"Exercise 3.1  urn contains two yellow balls three red balls. Three balls drawn random urn without replacement.Draw tree diagram represent sample space experiment find probabilities outcome.Draw tree diagram represent sample space experiment find probabilities outcome.Let random variable \\(X\\) denote number red balls drawn.Let random variable \\(X\\) denote number red balls drawn.Write probability distribtion \\(X\\).Write probability distribtion \\(X\\).Find mean variance \\(X\\).Exercise 3.2  Let \\(X\\) value observed rolling \\(8\\)-sided dieWhat probability distribution \\(X\\).probability distribution \\(X\\).Draw graph probability distribution.Draw graph probability distribution.Find mean variance \\(X\\).Find mean variance \\(X\\).Find expected value :Find expected value :\\(3X+5\\)\\(3X+5\\)\\(\\ln(X)\\)Exercise 3.3  game consists tossing coin first head appears. score recorded number tosses required.random variable \\(Y\\) number tosses, distribution \\(Y\\)?random variable \\(Y\\) number tosses, distribution \\(Y\\)?Write first \\(6\\) values probability distribution, draw sketch.Write first \\(6\\) values probability distribution, draw sketch.Find mean variance \\(Y\\).Find mean variance \\(Y\\).Exercise 3.4  Two fair dice rolled total score observed.Write probability distribution total score.Write probability distribution total score.Find mean variance total score.Find mean variance total score.Exercise 3.5  Two fair dice rolled maximum score observed.Write probability distribution maximum score.Write probability distribution maximum score.Find mean variance maximum score.Find mean variance maximum score.Exercise 3.6  fair coin tossed three times. Let \\(X\\) number heads tosses minus number tails.\n) Find probability distribution \\(X\\)Find mean variance \\(X\\).Exercise 3.7  game simple Chuck--luck played single player house. game conducted follows:player chooses number \\(1\\) \\(6\\) inclusive places bet £\\(1\\). banker rolls \\(2\\) fair dice. player’s number occurs \\(1\\) \\(2\\) times, wins £\\(1\\) £\\(2\\) respectively. player’s numberdoes appear dice, loses £\\(1\\) stake. Let random variable \\(X\\) denote player’s winnings game.Find probability mass function \\(X\\).Find probability mass function \\(X\\).Find expected value winnings, \\(\\text{E}[X]\\).Find expected value winnings, \\(\\text{E}[X]\\).Exercise 3.8  random variable \\(X\\) following probability mass function:Find value \\(c\\) makes valid probability mass function.Find value \\(c\\) makes valid probability mass function.Find \\(\\text{E}[X]\\) \\(\\text{Var}[X]\\).Find \\(\\text{E}[X]\\) \\(\\text{Var}[X]\\).Exercise 3.9  random variable \\(X\\) following probability mass function:\\(\\text{E}[Y]=\\frac{14}{3}\\)Find values \\(\\) \\(b\\).Find values \\(\\) \\(b\\).Find \\(\\text{Var}[Y]\\).Find \\(\\text{Var}[Y]\\).Exercise 3.10  fair six-sided die ‘\\(1\\)’ one face, ‘\\(2\\)’ two faces ‘\\(3\\)’ remaining three faces.Let \\(Y\\) denote score single roll die. Tabulate mass function calculate mean variance \\(Y\\).Let \\(Y\\) denote score single roll die. Tabulate mass function calculate mean variance \\(Y\\).Let \\(X\\) total score two rolls die. Tabulate mass function calculate mean variance \\(X\\).Let \\(X\\) total score two rolls die. Tabulate mass function calculate mean variance \\(X\\).Exercise 3.11  urn contains \\(n\\) balls numbered \\(1\\) \\(n\\) two balls drawn simultaneously. Find probability distribution \\(X\\), larger two numbers drawn. Calculate expected value \\(X\\).Exercise 3.12  \\(\\) \\(B\\) play game involves rolling fair die simultaneously. Let \\(X\\) absolute difference scores.Tabulate probability mass function \\(X\\).Tabulate probability mass function \\(X\\).Find mean variance \\(X\\).Find mean variance \\(X\\).value \\(X\\) \\(1\\) \\(2\\) \\(\\) wins. \\(X\\) \\(3\\),\\(4\\) \\(5\\) \\(B\\) wins. \\(X\\) zero roll . Find probability \\(\\) wins first go. Find probability \\(\\) wins second go. Find probability \\(\\) wins \\(r^{\\text{th}}\\) go.value \\(X\\) \\(1\\) \\(2\\) \\(\\) wins. \\(X\\) \\(3\\),\\(4\\) \\(5\\) \\(B\\) wins. \\(X\\) zero roll . Find probability \\(\\) wins first go. Find probability \\(\\) wins second go. Find probability \\(\\) wins \\(r^{\\text{th}}\\) go.Find probability \\(\\) wins.Find probability \\(\\) wins.Exercise 3.13  discrete random variable following mass function\\[\\begin{equation*}\n  f(y)=\\begin{cases}\n    \\pi \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  y = 1 \\\\\n    1-\\pi \\ \\  \\ y = 0 .\n  \\end{cases}\n\\end{equation*}\\]\\(0<\\pi<1\\).known Bernoulli distribution.Find \\(\\text{E}[Y]\\) \\(\\text{Var}[Y]\\)","code":""},{"path":"drv.html","id":"exercises-for-feedback-1","chapter":"3 Discrete Random Variables","heading":"3.5.1 Exercises for feedback","text":"Exercise 3.14  Scrabble tiles letters word EXERCISES bag.random tile drawn, probability letter E?random tile drawn, probability letter E?Given letter drawn bag vowel, probability E?Given letter drawn bag vowel, probability E?Explain two questions different words, compare size probabilities either part.Explain two questions different words, compare size probabilities either part.Exercise 3.15  \\(40\\) students Maths class, given number \\(1\\) \\(40\\). Separately numbers \\(1-40\\) placed hat mixed randomly. teacher give three random students prize. Three numbers selected hat without replacement. numbers drawn teacher guesses three numbers writes board.Work probability teacher matching \\(0\\), \\(1\\), \\(2\\) \\(3\\) numbers drawn hat.different occasion, teacher \\(5\\) students tutor group. wants give two prizes Maths students, one tutor group. draw two numbers hat, separately draw one numbers \\(1-5\\) shoe (one hat). writes prediction board selection.Work probability teacher predicting \\(0\\), \\(1\\) \\(2\\) Maths students, getting tutee correct, probability predicting \\(0\\), \\(1\\) \\(2\\) Maths students getting tutee correct.Exercise 3.16  fairground game played \\(5\\) dice. player pays £1 play, every \\(6\\) appears dice player rewarded £\\(6\\).Work probabilities getting \\(0\\),\\(1\\),\\(2\\),\\(\\dots\\),\\(5\\) sixes rolling five dice.Work probabilities getting \\(0\\),\\(1\\),\\(2\\),\\(\\dots\\),\\(5\\) sixes rolling five dice.\\(X\\) profit player game, work expected profit \\(\\text{E}[X]\\).\\(X\\) profit player game, work expected profit \\(\\text{E}[X]\\).Work also variance \\(\\text{Var}[X]\\).Work also variance \\(\\text{Var}[X]\\).Explain think good game .Explain think good game .Exercise 3.17  (Extension / Challenge) play game standard pack \\(52\\) cards. dealt hand \\(3\\) cards. hand contains pair, get \\(3\\) points. hand contains \\(3\\) kind, get \\(10\\) points. hand contains neither pair \\(3\\) kind lose point. expected number points score game?","code":""}]
